<html>
<head><meta charset="utf-8"><title>wasmtime / issue #5243 Is there a performance bottleneck ... · git-wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/index.html">git-wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html">wasmtime / issue #5243 Is there a performance bottleneck ...</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="308930269"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308930269" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308930269">(Nov 10 2022 at 07:03)</a>:</h4>
<p>asurdo opened <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<h4>Question:</h4>
<p>I use wasmtime in c++ multithread program. I expected performance improvement when I use more threads, but it does not. Is there any bottleneck in wasmtime? And how can I avoid it?</p>
<h4>Hear is my performance test log.</h4>
<p>My machine environment is 24 core and 64GB memory.</p>
<p>1 thread: speed 8217/s, average time cost 120us<br>
2 thread: speed: 10137/s, average time cost: 196us<br>
10 thread: speed 11190/s, average time cost: 892us</p>
<h4>My code logic</h4>
<p>singleton for the engine and linker, creating a store on each call, use wasi and some host function.</p>
</blockquote>



<a name="308931342"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308931342" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308931342">(Nov 10 2022 at 07:14)</a>:</h4>
<p>asurdo <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1309865770">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<p>PS: I compile module only once，and instantiate every time.<br>
I seprate one call to three step, init store, instantiate and call instance func. The step where the time-consuming increases the most is in call instance func.</p>
</blockquote>



<a name="308951151"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308951151" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308951151">(Nov 10 2022 at 09:43)</a>:</h4>
<p>bjorn3 <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1310019615">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<p>The bottleneck is probably in the linux kernel. As I understand it changing memory mappings will acquire a process wide lock on the memory mappings and once it is done changing them every currently running thread of the process is interrupted to make sure that the cpu core knows about the changed memory mapping. Every time you instantiate a module, memory mappings are changed. This effectively means that the instantiation count per second across the whole process is limited by how fast a single core can handle memory mapping changes and in addition every instantiation pauses execution of other threads for a moment.</p>
</blockquote>



<a name="308951574"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308951574" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308951574">(Nov 10 2022 at 09:46)</a>:</h4>
<p>bjorn3 <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1310022747">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<p>I believe using the pooling allocation strategy (set using <code>config.allocation_strategy()</code>) is more performant than the default on demand strategy.</p>
</blockquote>



<a name="308978311"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308978311" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308978311">(Nov 10 2022 at 12:33)</a>:</h4>
<p>asurdo <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1310215861">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<blockquote>
<p>I believe using the pooling allocation strategy (set using <code>config.allocation_strategy()</code>) is more performant than the default on demand strategy.</p>
</blockquote>
<p>Is config.allocation_strategy() only for Rust? I can't find it in c-API. And in fact, I use jemalloc for my c++ program, malloc is in user mode.</p>
<p>I avoid this problem using multi-process(more memory cost for hundreds of modules), and it worked as I expected.</p>
</blockquote>



<a name="308980723"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/308980723" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#308980723">(Nov 10 2022 at 12:46)</a>:</h4>
<p>bjorn3 <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1310229725">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<blockquote>
<p>Is config.allocation_strategy() only for Rust?</p>
</blockquote>
<p>Looks like it. Seems to be an oversight.</p>
<blockquote>
<p>And in fact, I use jemalloc for my c++ program, malloc is in user mode.</p>
</blockquote>
<p>When instantiating wasmtime mmap's a (memfd) file containing the initial data of the linear memory of the wasm module. This allows the kernel to lazily load parts and copy only when the data is modified as opposed to having wasmtime write it all at once even if the vast majority isn't used at all or isn't modified. This is a necessity for fast instantiating.</p>
</blockquote>



<a name="309003116"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/309003116" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#309003116">(Nov 10 2022 at 14:42)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/5243#issuecomment-1310396452">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<p>I believe that this is largely the same issue as <a href="https://github.com/bytecodealliance/wasmtime/issues/4637">https://github.com/bytecodealliance/wasmtime/issues/4637</a>, so I'm going to close in favor of that.</p>
<p>The pooling allocator is known to help here. New <code>*_keep_resident</code> configuration options are also known to help. Very-recent Linux kernels are also known to help. This is an ongoing area of investigation for WebAssembly runtimes and is something we're always interested in improving on.</p>
</blockquote>



<a name="309003120"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%235243%20Is%20there%20a%20performance%20bottleneck%20.../near/309003120" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.235243.20Is.20there.20a.20performance.20bottleneck.20.2E.2E.2E.html#309003120">(Nov 10 2022 at 14:42)</a>:</h4>
<p>alexcrichton closed <a href="https://github.com/bytecodealliance/wasmtime/issues/5243">issue #5243</a>:</p>
<blockquote>
<h4>Question:</h4>
<p>I use wasmtime in c++ multithread program. I expected performance improvement when I use more threads, but it does not. Is there any bottleneck in wasmtime? And how can I avoid it?</p>
<h4>Hear is my performance test log.</h4>
<p>My machine environment is 24 core and 64GB memory.</p>
<p>1 thread: speed 8217/s, average time cost 120us<br>
2 thread: speed: 10137/s, average time cost: 196us<br>
10 thread: speed 11190/s, average time cost: 892us</p>
<h4>My code logic</h4>
<p>singleton for the engine and linker, creating a store on each call, use wasi and some host function.</p>
</blockquote>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>