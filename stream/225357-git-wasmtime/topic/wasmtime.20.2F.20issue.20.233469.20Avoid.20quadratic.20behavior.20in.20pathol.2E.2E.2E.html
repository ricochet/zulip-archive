<html>
<head><meta charset="utf-8"><title>wasmtime / issue #3469 Avoid quadratic behavior in pathol... · git-wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/index.html">git-wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233469.20Avoid.20quadratic.20behavior.20in.20pathol.2E.2E.2E.html">wasmtime / issue #3469 Avoid quadratic behavior in pathol...</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="258613109"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%233469%20Avoid%20quadratic%20behavior%20in%20pathol.../near/258613109" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233469.20Avoid.20quadratic.20behavior.20in.20pathol.2E.2E.2E.html#258613109">(Oct 21 2021 at 20:35)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/pull/3469#issuecomment-948983692">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/pull/3469">issue #3469</a>:</p>
<blockquote>
<blockquote>
<p>Out of further curiosity, even 70ms for a function like this seems somewhat high, is that still due to MachBuffer things or is it general "too much elbow grease is needed to bring that down further"</p>
</blockquote>
<p>I think it is mostly in the middle-end (analyses and optimizations), which will see the huge CFG with all the loops before it's reduced. The backend stages that are specifically broken out in the <code>clif-util wasm -T</code> output show: 3ms in CLIF -&gt; VCode lowering; 4ms in regalloc; and 4ms in binary emission (MachBuffer + cpu-specific instruction encoding code). So only 10ms in the "backend" and the rest in attempted optimization.</p>
<p>A <code>perf</code> profile of the compilation shows a lot of time in the kernel's pagefault path, so I think that just writing out the data structures has some overhead (for the large function body). I imagine we could probably be smarter about early optimizations that cut down the amount of work the later stages have to do; but nothing immediately obviously or anomalously bad is happening here, I think. </p>
</blockquote>



<a name="258613248"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%233469%20Avoid%20quadratic%20behavior%20in%20pathol.../near/258613248" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233469.20Avoid.20quadratic.20behavior.20in.20pathol.2E.2E.2E.html#258613248">(Oct 21 2021 at 20:36)</a>:</h4>
<p>cfallin edited a <a href="https://github.com/bytecodealliance/wasmtime/pull/3469#issuecomment-948983692">comment</a> on <a href="https://github.com/bytecodealliance/wasmtime/pull/3469">issue #3469</a>:</p>
<blockquote>
<blockquote>
<p>Out of further curiosity, even 70ms for a function like this seems somewhat high, is that still due to MachBuffer things or is it general "too much elbow grease is needed to bring that down further"</p>
</blockquote>
<p>I think it is mostly in the middle-end (analyses and optimizations), which will see the huge CFG with all the loops before it's reduced. The backend stages that are specifically broken out in the <code>clif-util wasm -T</code> output show: 3ms in CLIF -&gt; VCode lowering; 4ms in regalloc; and 4ms in binary emission (MachBuffer + cpu-specific instruction encoding code). So only 11ms (EDIT: I can add I promise) in the "backend" and the rest in attempted optimization.</p>
<p>A <code>perf</code> profile of the compilation shows a lot of time in the kernel's pagefault path, so I think that just writing out the data structures has some overhead (for the large function body). I imagine we could probably be smarter about early optimizations that cut down the amount of work the later stages have to do; but nothing immediately obviously or anomalously bad is happening here, I think. </p>
</blockquote>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>