<html>
<head><meta charset="utf-8"><title>wasmtime / Issue #900 Improve wasm handling for stack ove... · git-wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/index.html">git-wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20Issue.20.23900.20Improve.20wasm.20handling.20for.20stack.20ove.2E.2E.2E.html">wasmtime / Issue #900 Improve wasm handling for stack ove...</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="190342543"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20Issue%20%23900%20Improve%20wasm%20handling%20for%20stack%20ove.../near/190342543" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20Issue.20.23900.20Improve.20wasm.20handling.20for.20stack.20ove.2E.2E.2E.html#190342543">(Mar 11 2020 at 23:17)</a>:</h4>
<p>iximeow <a href="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-597926672" target="_blank" title="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-597926672">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/900" target="_blank" title="https://github.com/bytecodealliance/wasmtime/issues/900">Issue #900</a>:</p>
<blockquote>
<p>This is very similar to an issue we've been looking at addressing in <code>lucet</code>, where the "almost stack overflowed" case has similar fatal end results for us. The approach we've been most seriously considering looks much like this, though we're planning on keeping a guard page and only checking against some reserved stack space limit at the point we call into native code. This avoids needing instrumentation on each internal call, instead trading for a memory access, to get the stack limit from VMCtx.</p>
<p>In the <code>lucet</code> case, we'd like to avoid reserving an extra native thread(ish) of stack unconditionally, so we might tweak this approach a bit more. I've recently suggested that we reframe the approach as having an amount of stack space reserved for native calls. Then, in the case that the wasm stack doesn't have this much space available, we allocate a <code>NATIVE_RESERVED_STACK_SIZE</code> chunk of memory and do a native call there instead. In the happy path, we can do a native call on the same stack with the overhead of a memory access and compare. In the less happy path, we can try to proceed instead of aborting the program, assuming the system itself has memory available.</p>
<p>One concern we've run into is the case of mutual recursion between wasm code and native code. If this is a concern for wasmtime too? If it is, it sounds like you'd handle this by using a new stack limit when calling back into wasm code, so that makes sense.</p>
<p>I assume a stack overflow in native code would then be considered a native code error by virtue of not fitting within the reserved stack space? It looks like those would be program-ending faults still. One of the reasons we want <code>lucet-runtime</code> to continue handing segfaults in the stack guard page is to try isolating these errors, but if we end up needing to unwind native call frames to run destructors we might use more stack leading to an overflow when trying to unwind from an overflow...</p>
</blockquote>



<a name="190405601"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20Issue%20%23900%20Improve%20wasm%20handling%20for%20stack%20ove.../near/190405601" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20Issue.20.23900.20Improve.20wasm.20handling.20for.20stack.20ove.2E.2E.2E.html#190405601">(Mar 12 2020 at 15:48)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-598262374" target="_blank" title="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-598262374">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/900" target="_blank" title="https://github.com/bytecodealliance/wasmtime/issues/900">Issue #900</a>:</p>
<blockquote>
<p>@iximeow that sounds like a strategy that would work for this as well. I'm always iffy myself on tracking stack sizes, but the general idea is the same where whenever native code is running we try to provide a guarantee there's a "reasonable amount of stack space". I figured though that if this limit was ever blown we'd just return a wasm stack overflow trap rather than trying to allocate more native stack at the last second to keep running code.</p>
<p>I think we'd definitely want to handle mutually recursive wasm/native code, and my thinking there at lesat is that you might get some weird errors like shallow wasm invocations triggering stack overflow b/c a previous wasm module recursed so much, but as long as everything has pretty reasonable limits I think it'll probably turn out roughly ok.</p>
<p>I do agree yeah native stack overflow is still going to be a program-ending fault, and I'm mostly uncomfortable running sigsegv signals on the sigaltstack which is frequently too small, and if we didn't do that there'd be no way to have libstd's nice "you overflowed the stack" message as well.</p>
</blockquote>



<a name="193343518"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20Issue%20%23900%20Improve%20wasm%20handling%20for%20stack%20ove.../near/193343518" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20Issue.20.23900.20Improve.20wasm.20handling.20for.20stack.20ove.2E.2E.2E.html#193343518">(Apr 08 2020 at 16:19)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-611054274" title="https://github.com/bytecodealliance/wasmtime/issues/900#issuecomment-611054274">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/900" title="https://github.com/bytecodealliance/wasmtime/issues/900">Issue #900</a>:</p>
<blockquote>
<p>For posterity <a href="https://gist.github.com/alexcrichton/2bed51a164ea278b8965ccea88c89c6c" title="https://gist.github.com/alexcrichton/2bed51a164ea278b8965ccea88c89c6c">here's a test</a> which shows the bug we have today, and how we're "catching" segfaults in host code.</p>
</blockquote>



<a name="194840086"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20Issue%20%23900%20Improve%20wasm%20handling%20for%20stack%20ove.../near/194840086" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20Issue.20.23900.20Improve.20wasm.20handling.20for.20stack.20ove.2E.2E.2E.html#194840086">(Apr 21 2020 at 18:03)</a>:</h4>
<p>sunfishcode closed <a href="https://github.com/bytecodealliance/wasmtime/issues/900" title="https://github.com/bytecodealliance/wasmtime/issues/900">Issue #900</a>:</p>
<blockquote>
<p>Currently <code>wasmtime</code> handles stack overflow in wasm code through the use of the segfault signal handler, relying on wasm code to hit the guard page to trigger a segfault which we the longjmp to recover from. Unfortunately, though, this has a consequence where it doesn't work well for "almost stack overflowed" wasm code which calls native imports. </p>
<p>For example let's say that a wasm module has an extremely deep call stack, but then it calls an imported function where then the imported function hits the guard page. This will trigger a segfault, and we still want this to be a somewhat recoverable situation! In this scenario though it's not actually save to <code>longjmp</code> over a bunch of Rust frames since it can skip some critical destructors.</p>
<p>I think in general we'll want to update <code>wasmtime</code>'s handling of stack overflow in WebAssembly code to not rely on segfaults. In talking with some Spidermonkey folks, I think we'll want to switch to a scheme that looks something like:</p>
<ul>
<li>We "reserve" a fixed amount of stack space (in bytes) for wasm. Not literally on the side, but we say that the wasm stack can't ever be larger than "N" bytes.</li>
<li>Each wasm function has a prelude check against "where is the current stack", and manually aborts if it's about to overflow. This may require a form of a dedicated register for storing the latest stack limit.</li>
<li>Then we'll limit segfault handling <em>only</em> to out of bounds loads/stores in wasm code, and not to stack overflow.</li>
</ul>
<p>This should help retain all our current speed (with sufficient tweaks/optimization) but also allow us to guarantee that native code imported by wasm always has a reasonable amount of stack space. This means that stack overflow in native code would never be recovered from (it'd abort the process as typical Rust programs do).</p>
</blockquote>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>