<html>
<head><meta charset="utf-8"><title>wasmtime / issue #6118 riscv64: Implementing Fixed Width ... · git-wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/index.html">git-wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html">wasmtime / issue #6118 riscv64: Implementing Fixed Width ...</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="345472389"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345472389" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345472389">(Mar 29 2023 at 17:34)</a>:</h4>
<p>afonso360 opened <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p><span aria-label="wave" class="emoji emoji-1f44b" role="img" title="wave">:wave:</span> Hey,</p>
<p>I've been thinking about how to implement SIMD operations on the RISC-V backend. These are sort of my notes / thoughts about this. Hopefully I haven't missed something too big that invalidates all of this.</p>
<p>Feedback would be appreciated! </p>
<h1>RISC-V Vector Intro</h1>
<p>This is a small introduction to the Vector Extensions in case people aren't familiar with it.</p>
<ul>
<li>In RISC-V we have 32 vector registers.</li>
<li>These registers have <em>some</em> uarch specific size.</li>
<li>Each vector register has a minimum of 32bits (The maximum is 64KiB <span aria-label="eyes" class="emoji emoji-1f440" role="img" title="eyes">:eyes:</span>).<br>
    * The minimum for Application Processors is 128 bits</li>
<li>It can process elements of size 8, 16, 32 and 64 bits<br>
    * Element size is part of architectural state and not each explicit in each instruction<br>
    * So, we have a generic <code>add</code> instruction that is both <code>add.i32</code> and <code>add.i64</code> depending on how the hardware is currently configured</li>
<li>If necessary we can group multiple registers to get a larger register<br>
    * If we have 32 x 128bit registers, we can use them as 16 x 256bit registers instead<br>
    * This is also part of architectural state and not defined in each instruction<br>
    * We probably won't use this, but its a cool trick</li>
<li>Hardware is configured using the <code>vset{i}vl{i}</code> instruction<br>
    * I'm mention it here, because I use that instruction name a few times in the rest of the document</li>
<li>Masking is supported<br>
    * We have one mask register (v0)<br>
    * The mask register has double use as both a regular vector register and a mask register<br>
    * I don't think we will use masking anywhere in this proposal<br>
        * Maybe for some weird SIMD instruction?</li>
</ul>
<p>I like this [blog post that explains how this all works in a much better way][rvv-intro-blog].</p>
<h1>1. Planned implementation</h1>
<p>With some careful orchestration we can operate the Vector hardware for fixed width SIMD operations.</p>
<p>The general idea is that we can emulate a <code>iadd.i32x4</code> by emitting the following code:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
</code></pre></div>
<p>Here's an explanation of that:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w">  </span><span class="c1">;; This instruction configures the vector hardware</span>
<span class="w">         </span><span class="nf">zero</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Ignore the amount of processed elements. (We know that we can process them all in one go)</span>
<span class="w">               </span><span class="err">4,</span><span class="w"> </span><span class="c1">;; Process at most 4 elements</span>
<span class="w">                  </span><span class="nf">e32</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Each element is 32 bits</span>
<span class="w">                       </span><span class="nf">m1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Do not group registers</span>
<span class="w">                           </span><span class="nf">ta</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Tail-Agnostic Mode (The rest of the register past 128bits is left undefined)</span>
<span class="w">                               </span><span class="nf">ma</span><span class="w"> </span><span class="c1">;; Mask-Agnostic Mode (Similar to ta but for the mask register)</span>

<span class="nf">vadd.vv</span><span class="w"> </span><span class="c1">;; Vector Add (Vector-Vector)</span>
<span class="w">        </span><span class="nf">v0</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Store the results in v0 (It is a usable register for vectors unlike x0)</span>
<span class="w">            </span><span class="nf">v1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; LHS is the v1 register</span>
<span class="w">                </span><span class="nf">v2</span><span class="w"> </span><span class="c1">;; RHS is the v2 register</span>
</code></pre></div>
<p><code>vsetivli</code> has an output register that saves the amount of elements it can do, but since we know that all processors support a minimum of 128bits per vector register we have a guarantee that all elements will be processed by a single instruction and don't need to check the output register. So we set it to the zero register to ignore it. (There are some asterisks here, see <a href="#2.3.-regalloc-fun-for-small-vectors-implementations">Regalloc fun for small vectors implementations</a> for more details on that!)</p>
<p>We also only need to reconfigure the vector hardware when we change element-width or element-count. So this CLIF code:</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="n">v0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fadd</span><span class="p">.</span><span class="n">f32x4</span><span class="w"> </span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span>
<span class="n">v3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i32x4</span><span class="w"> </span><span class="n">v4</span><span class="p">,</span><span class="w"> </span><span class="n">v5</span>
<span class="n">v6</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i64x2</span><span class="w"> </span><span class="n">v7</span><span class="p">,</span><span class="w"> </span><span class="n">v8</span>
</code></pre></div>
<p>Could be lowered to:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 4 elements of 32bit size</span>
<span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
<span class="c1">;; Here we don't actually need to change the hardware despite it being a different CLIF type!</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span>
<span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="no">e64</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 2 elements of 64bit size</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span>
</code></pre></div>
<p>Switching vector modes is not done during instruction selection, but on a  VCode pass that runs post Instruction Selection.</p>
<p>Each lowered vector instruction carries the full vector configuration that it needs, and in the VCode Pass we insert <code>vsetvli</code>'s as necessary (i.e. between instructions with different vector configurations).</p>
<h2>1.1 VCode Instructions</h2>
<p>The first step is carrying the full vector configuration in each VCode instruction. Here's how I expect these instructions to look like</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span><span class="w"> </span><span class="c1">#avl=2 #vtype=(e64, m1, ta, ma)</span>
</code></pre></div>
<p>I've lifted these names out of the ISA spec. </p>
<p><code>avl</code> (Application Vector Length) is the maximum number of elements that we want to process. For this SIMD proposal it's always an immediate with the number of lanes. However for the purposes of VCode it can also be a  register, this is required for interoperability with a future dynamic vector implementation.</p>
<p><code>vtype</code> is the rest of the configuration data for the vector hardware.</p>
<p>There is additional state that I'm ignoring here:
* <code>vxrm</code>: Vector fixed-point rounding mode register
* <code>vxsat</code>: Vector fixed-point saturation flag register</p>
<p>Not sure if we need these, but we can handle them in the same manner as <code>vtype</code>, and insert their respective mode switching instructions in the same pass.</p>
<p>Additionally each instruction has an optional mask register. When unmasked this does not show up in the assembly, this is handled as a normal register input to each instruction.</p>
<h2>1.2 The VCode Pass</h2>
<p>After Instruction Selection (but before Register Allocation!) we need to run a custom VCode pass.</p>
<p>This pass walks the VCode forwards  and keeps track of the "current" vector configuration. Whenever a instruction requests a different one we emit a <code>vsetvli</code>.</p>
<p>The reason for this being done Pre-Regalloc is that for the actual dynamic vectors. <code>avl</code> is probably not an immediate, but a register with the number of elements that we want to process. So we also need to have that interaction with regalloc. I don't expect to have to do that for SIMD yet, but this pass should probably work for both the current SIMD implementation and a future Dynamic Vectors  implementation.</p>
<p>The current calling convention clobbers the vector configuration on all calls. So we also need to keep track of that and query the ABI layer.</p>
<p>A neat idea to further optimize this is by inheriting the vector configuration if all the dominator blocks to the current block end in the same vector configuration. This avoids us having to emit a <code>vsetvli</code> on each basic block if the configuration never changes.</p>
<p>A downside of this pass is that we <em>need</em> to run it to get correct codegen. Even if we never emit a vector instruction. I don't know the performance implications of this, but it's something to keep in mind.</p>
<p>This approach is quite similar to what LLVM does, see Page 41 of [this presentation][rvv-intro] for more details on that.</p>
<p>Some other ideas in <a href="#2.-alternative-ways-of-emitting-vsetvli">Alternative ways of emitting <code>vsetvli</code></a></p>
<h1>2. Additional considerations</h1>
<h2>2.1. Spills and Reloads</h2>
<p>We can't do a dynamic sized spill/reload, which is going to be an issue for implementing full dynamic vectors. (See also the discussion here: <a href="https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682">https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682</a>)</p>
<p>But since that isn't implemented yet, and we don't use vector registers for anything else maybe we can do a fixed size 128b store/load for now?</p>
<p>This is definitely incompatible with a full Dynamic Vector implementation. But for that to work we need to save the full registers and with that the scheme above should still work.</p>
<h2>2.2. Calling Convention for Vectors</h2>
<p>All registers are Caller-Saved, vl and vtype are also Caller-Saved. </p>
<p>Standard States:</p>
<blockquote>
<p>Vector registers are not used for passing arguments or return values; we intend to define a new calling convention variant to allow that as a future software optimization.</p>
</blockquote>
<p><a href="https://godbolt.org/z/T7sMqz4so">Clang does a dynamic stack store and seems to pass everything via stack.</a>. This is the same problem as <a href="#2.1.-spills-and-reloads">2.1. Spills and Reloads</a></p>
<ul>
<li>[RISC-V Vector Register Convention][psabi-vector-register-convention]</li>
<li>[RISC-V ELF psABI (pdf)][psabi]</li>
</ul>
<h2>2.3. Regalloc fun for small vectors implementations</h2>
<p>(See <code>§18.1. Zvl*: Minimum Vector Length Standard Extensions</code> of the [V Extension Spec][v-spec-18-1]) </p>
<p>The minimum vector register width is 32bits. This means that in the worse case we need to group up 4 registers to process a single 128b operation. (This is something you can do with RISC-V Vector hardware, but hopefully we won't have to)</p>
<p>This affects regalloc since if we compile with a minimum vector register width of 32bits, we effectively only have 8 registers to work with.</p>
<p>This is a problem because we have to share our regalloc space with the float registers since we don't have space for an additional register class (see: [regalloc2/#47][regalloc2-reg-classes]). This means that we need to have the same number of float registers as vector registers. (At least I'm not seeing any clever regalloc tricks that we can pull off here)</p>
<p>My solution for this is to ignore <code>Zvl32b</code> and <code>Zvl64b</code> for now. </p>
<p>Additionally <code>§18.3. V: Vector Extension for Application Processors</code> states: </p>
<blockquote>
<p>The V vector extension requires Zvl128b.</p>
</blockquote>
<p>So it seems like a reasonable expectation that Linux running RISC-V CPU's will have <code>Zvl128b</code>, and if this turns out to be untrue we can change regalloc to deal with it.</p>
<h2>3. Alternative ways of emitting <code>vsetvli</code></h2>
<p>This applies to both the SIMD implementation and future Dynamic Vector implementations so we need to keep that in mind.</p>
<h3>3.1 Keeping state during instruction selection</h3>
<p>It would be neat if we could query the last set element length during instruction selection, that wa<br>
[message truncated]</p>
</blockquote>



<a name="345472394"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345472394" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345472394">(Mar 29 2023 at 17:34)</a>:</h4>
<p>afonso360 labeled <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p><span aria-label="wave" class="emoji emoji-1f44b" role="img" title="wave">:wave:</span> Hey,</p>
<p>I've been thinking about how to implement SIMD operations on the RISC-V backend. These are sort of my notes / thoughts about this. Hopefully I haven't missed something too big that invalidates all of this.</p>
<p>Feedback would be appreciated! </p>
<h1>RISC-V Vector Intro</h1>
<p>This is a small introduction to the Vector Extensions in case people aren't familiar with it.</p>
<ul>
<li>In RISC-V we have 32 vector registers.</li>
<li>These registers have <em>some</em> uarch specific size.</li>
<li>Each vector register has a minimum of 32bits (The maximum is 64KiB <span aria-label="eyes" class="emoji emoji-1f440" role="img" title="eyes">:eyes:</span>).<br>
    * The minimum for Application Processors is 128 bits</li>
<li>It can process elements of size 8, 16, 32 and 64 bits<br>
    * Element size is part of architectural state and not each explicit in each instruction<br>
    * So, we have a generic <code>add</code> instruction that is both <code>add.i32</code> and <code>add.i64</code> depending on how the hardware is currently configured</li>
<li>If necessary we can group multiple registers to get a larger register<br>
    * If we have 32 x 128bit registers, we can use them as 16 x 256bit registers instead<br>
    * This is also part of architectural state and not defined in each instruction<br>
    * We probably won't use this, but its a cool trick</li>
<li>Hardware is configured using the <code>vset{i}vl{i}</code> instruction<br>
    * I'm mention it here, because I use that instruction name a few times in the rest of the document</li>
<li>Masking is supported<br>
    * We have one mask register (v0)<br>
    * The mask register has double use as both a regular vector register and a mask register<br>
    * I don't think we will use masking anywhere in this proposal<br>
        * Maybe for some weird SIMD instruction?</li>
</ul>
<p>I like this [blog post that explains how this all works in a much better way][rvv-intro-blog].</p>
<h1>1. Planned implementation</h1>
<p>With some careful orchestration we can operate the Vector hardware for fixed width SIMD operations.</p>
<p>The general idea is that we can emulate a <code>iadd.i32x4</code> by emitting the following code:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
</code></pre></div>
<p>Here's an explanation of that:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w">  </span><span class="c1">;; This instruction configures the vector hardware</span>
<span class="w">         </span><span class="nf">zero</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Ignore the amount of processed elements. (We know that we can process them all in one go)</span>
<span class="w">               </span><span class="err">4,</span><span class="w"> </span><span class="c1">;; Process at most 4 elements</span>
<span class="w">                  </span><span class="nf">e32</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Each element is 32 bits</span>
<span class="w">                       </span><span class="nf">m1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Do not group registers</span>
<span class="w">                           </span><span class="nf">ta</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Tail-Agnostic Mode (The rest of the register past 128bits is left undefined)</span>
<span class="w">                               </span><span class="nf">ma</span><span class="w"> </span><span class="c1">;; Mask-Agnostic Mode (Similar to ta but for the mask register)</span>

<span class="nf">vadd.vv</span><span class="w"> </span><span class="c1">;; Vector Add (Vector-Vector)</span>
<span class="w">        </span><span class="nf">v0</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Store the results in v0 (It is a usable register for vectors unlike x0)</span>
<span class="w">            </span><span class="nf">v1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; LHS is the v1 register</span>
<span class="w">                </span><span class="nf">v2</span><span class="w"> </span><span class="c1">;; RHS is the v2 register</span>
</code></pre></div>
<p><code>vsetivli</code> has an output register that saves the amount of elements it can do, but since we know that all processors support a minimum of 128bits per vector register we have a guarantee that all elements will be processed by a single instruction and don't need to check the output register. So we set it to the zero register to ignore it. (There are some asterisks here, see <a href="#2.3.-regalloc-fun-for-small-vectors-implementations">Regalloc fun for small vectors implementations</a> for more details on that!)</p>
<p>We also only need to reconfigure the vector hardware when we change element-width or element-count. So this CLIF code:</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="n">v0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fadd</span><span class="p">.</span><span class="n">f32x4</span><span class="w"> </span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span>
<span class="n">v3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i32x4</span><span class="w"> </span><span class="n">v4</span><span class="p">,</span><span class="w"> </span><span class="n">v5</span>
<span class="n">v6</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i64x2</span><span class="w"> </span><span class="n">v7</span><span class="p">,</span><span class="w"> </span><span class="n">v8</span>
</code></pre></div>
<p>Could be lowered to:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 4 elements of 32bit size</span>
<span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
<span class="c1">;; Here we don't actually need to change the hardware despite it being a different CLIF type!</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span>
<span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="no">e64</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 2 elements of 64bit size</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span>
</code></pre></div>
<p>Switching vector modes is not done during instruction selection, but on a  VCode pass that runs post Instruction Selection.</p>
<p>Each lowered vector instruction carries the full vector configuration that it needs, and in the VCode Pass we insert <code>vsetvli</code>'s as necessary (i.e. between instructions with different vector configurations).</p>
<h2>1.1 VCode Instructions</h2>
<p>The first step is carrying the full vector configuration in each VCode instruction. Here's how I expect these instructions to look like</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span><span class="w"> </span><span class="c1">#avl=2 #vtype=(e64, m1, ta, ma)</span>
</code></pre></div>
<p>I've lifted these names out of the ISA spec. </p>
<p><code>avl</code> (Application Vector Length) is the maximum number of elements that we want to process. For this SIMD proposal it's always an immediate with the number of lanes. However for the purposes of VCode it can also be a  register, this is required for interoperability with a future dynamic vector implementation.</p>
<p><code>vtype</code> is the rest of the configuration data for the vector hardware.</p>
<p>There is additional state that I'm ignoring here:
* <code>vxrm</code>: Vector fixed-point rounding mode register
* <code>vxsat</code>: Vector fixed-point saturation flag register</p>
<p>Not sure if we need these, but we can handle them in the same manner as <code>vtype</code>, and insert their respective mode switching instructions in the same pass.</p>
<p>Additionally each instruction has an optional mask register. When unmasked this does not show up in the assembly, this is handled as a normal register input to each instruction.</p>
<h2>1.2 The VCode Pass</h2>
<p>After Instruction Selection (but before Register Allocation!) we need to run a custom VCode pass.</p>
<p>This pass walks the VCode forwards  and keeps track of the "current" vector configuration. Whenever a instruction requests a different one we emit a <code>vsetvli</code>.</p>
<p>The reason for this being done Pre-Regalloc is that for the actual dynamic vectors. <code>avl</code> is probably not an immediate, but a register with the number of elements that we want to process. So we also need to have that interaction with regalloc. I don't expect to have to do that for SIMD yet, but this pass should probably work for both the current SIMD implementation and a future Dynamic Vectors  implementation.</p>
<p>The current calling convention clobbers the vector configuration on all calls. So we also need to keep track of that and query the ABI layer.</p>
<p>A neat idea to further optimize this is by inheriting the vector configuration if all the dominator blocks to the current block end in the same vector configuration. This avoids us having to emit a <code>vsetvli</code> on each basic block if the configuration never changes.</p>
<p>A downside of this pass is that we <em>need</em> to run it to get correct codegen. Even if we never emit a vector instruction. I don't know the performance implications of this, but it's something to keep in mind.</p>
<p>This approach is quite similar to what LLVM does, see Page 41 of [this presentation][rvv-intro] for more details on that.</p>
<p>Some other ideas in <a href="#2.-alternative-ways-of-emitting-vsetvli">Alternative ways of emitting <code>vsetvli</code></a></p>
<h1>2. Additional considerations</h1>
<h2>2.1. Spills and Reloads</h2>
<p>We can't do a dynamic sized spill/reload, which is going to be an issue for implementing full dynamic vectors. (See also the discussion here: <a href="https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682">https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682</a>)</p>
<p>But since that isn't implemented yet, and we don't use vector registers for anything else maybe we can do a fixed size 128b store/load for now?</p>
<p>This is definitely incompatible with a full Dynamic Vector implementation. But for that to work we need to save the full registers and with that the scheme above should still work.</p>
<h2>2.2. Calling Convention for Vectors</h2>
<p>All registers are Caller-Saved, vl and vtype are also Caller-Saved. </p>
<p>Standard States:</p>
<blockquote>
<p>Vector registers are not used for passing arguments or return values; we intend to define a new calling convention variant to allow that as a future software optimization.</p>
</blockquote>
<p><a href="https://godbolt.org/z/T7sMqz4so">Clang does a dynamic stack store and seems to pass everything via stack.</a>. This is the same problem as <a href="#2.1.-spills-and-reloads">2.1. Spills and Reloads</a></p>
<ul>
<li>[RISC-V Vector Register Convention][psabi-vector-register-convention]</li>
<li>[RISC-V ELF psABI (pdf)][psabi]</li>
</ul>
<h2>2.3. Regalloc fun for small vectors implementations</h2>
<p>(See <code>§18.1. Zvl*: Minimum Vector Length Standard Extensions</code> of the [V Extension Spec][v-spec-18-1]) </p>
<p>The minimum vector register width is 32bits. This means that in the worse case we need to group up 4 registers to process a single 128b operation. (This is something you can do with RISC-V Vector hardware, but hopefully we won't have to)</p>
<p>This affects regalloc since if we compile with a minimum vector register width of 32bits, we effectively only have 8 registers to work with.</p>
<p>This is a problem because we have to share our regalloc space with the float registers since we don't have space for an additional register class (see: [regalloc2/#47][regalloc2-reg-classes]). This means that we need to have the same number of float registers as vector registers. (At least I'm not seeing any clever regalloc tricks that we can pull off here)</p>
<p>My solution for this is to ignore <code>Zvl32b</code> and <code>Zvl64b</code> for now. </p>
<p>Additionally <code>§18.3. V: Vector Extension for Application Processors</code> states: </p>
<blockquote>
<p>The V vector extension requires Zvl128b.</p>
</blockquote>
<p>So it seems like a reasonable expectation that Linux running RISC-V CPU's will have <code>Zvl128b</code>, and if this turns out to be untrue we can change regalloc to deal with it.</p>
<h2>3. Alternative ways of emitting <code>vsetvli</code></h2>
<p>This applies to both the SIMD implementation and future Dynamic Vector implementations so we need to keep that in mind.</p>
<h3>3.1 Keeping state during instruction selection</h3>
<p>It would be neat if we could query the last set element length during instruction selection, that w<br>
[message truncated]</p>
</blockquote>



<a name="345477966"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345477966" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345477966">(Mar 29 2023 at 17:57)</a>:</h4>
<p>afonso360 edited <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p><span aria-label="wave" class="emoji emoji-1f44b" role="img" title="wave">:wave:</span> Hey,</p>
<p>I've been thinking about how to implement SIMD operations on the RISC-V backend. These are sort of my notes / thoughts about this. Hopefully I haven't missed something too big that invalidates all of this.</p>
<p>Feedback would be appreciated! </p>
<h1>RISC-V Vector Intro</h1>
<p>This is a small introduction to the Vector Extensions in case people aren't familiar with it.</p>
<ul>
<li>In RISC-V we have 32 vector registers.</li>
<li>These registers have <em>some</em> uarch specific size.<ul>
<li>This can be queried at run time</li>
</ul>
</li>
<li>Each vector register has a minimum of 32bits (The maximum is 64KiB <span aria-label="eyes" class="emoji emoji-1f440" role="img" title="eyes">:eyes:</span>).<br>
    * The minimum for Application Processors is 128 bits</li>
<li>It can process elements of size 8, 16, 32 and 64 bits<br>
    * Element size is part of architectural state and not each explicit in each instruction<br>
    * So, we have a generic <code>add</code> instruction that is both <code>add.i32</code> and <code>add.i64</code> depending on how the hardware is currently configured</li>
<li>If necessary we can group multiple registers to get a larger register<br>
    * If we have 32 x 128bit registers, we can use them as 16 x 256bit registers instead<br>
    * This is also part of architectural state and not defined in each instruction<br>
    * We probably won't use this, but its a cool trick</li>
<li>Hardware is configured using the <code>vset{i}vl{i}</code> instruction<br>
    * I'm mention it here, because I use that instruction name a few times in the rest of the document</li>
<li>Masking is supported<br>
    * We have one mask register (v0)<br>
    * The mask register has double use as both a regular vector register and a mask register<br>
    * I don't think we will use masking anywhere in this proposal<br>
        * Maybe for some weird SIMD instruction?</li>
</ul>
<p>I like this [blog post that explains how this all works in a much better way][rvv-intro-blog].</p>
<h1>1. Planned implementation</h1>
<p>With some careful orchestration we can operate the Vector hardware for fixed width SIMD operations.</p>
<p>The general idea is that we can emulate a <code>iadd.i32x4</code> by emitting the following code:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
</code></pre></div>
<p>Here's an explanation of that:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w">  </span><span class="c1">;; This instruction configures the vector hardware</span>
<span class="w">         </span><span class="nf">zero</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Ignore the amount of processed elements. (We know that we can process them all in one go)</span>
<span class="w">               </span><span class="err">4,</span><span class="w"> </span><span class="c1">;; Process at most 4 elements</span>
<span class="w">                  </span><span class="nf">e32</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Each element is 32 bits</span>
<span class="w">                       </span><span class="nf">m1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Do not group registers</span>
<span class="w">                           </span><span class="nf">ta</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Tail-Agnostic Mode (The rest of the register past 128bits is left undefined)</span>
<span class="w">                               </span><span class="nf">ma</span><span class="w"> </span><span class="c1">;; Mask-Agnostic Mode (Similar to ta but for the mask register)</span>

<span class="nf">vadd.vv</span><span class="w"> </span><span class="c1">;; Vector Add (Vector-Vector)</span>
<span class="w">        </span><span class="nf">v0</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Store the results in v0 (It is a usable register for vectors unlike x0)</span>
<span class="w">            </span><span class="nf">v1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; LHS is the v1 register</span>
<span class="w">                </span><span class="nf">v2</span><span class="w"> </span><span class="c1">;; RHS is the v2 register</span>
</code></pre></div>
<p><code>vsetivli</code> has an output register that saves the amount of elements it can do, but since we know that all processors support a minimum of 128bits per vector register we have a guarantee that all elements will be processed by a single instruction and don't need to check the output register. So we set it to the zero register to ignore it. (There are some asterisks here, see <a href="#2.3.-regalloc-fun-for-small-vectors-implementations">Regalloc fun for small vectors implementations</a> for more details on that!)</p>
<p>We also only need to reconfigure the vector hardware when we change element-width or element-count. So this CLIF code:</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="n">v0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fadd</span><span class="p">.</span><span class="n">f32x4</span><span class="w"> </span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span>
<span class="n">v3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i32x4</span><span class="w"> </span><span class="n">v4</span><span class="p">,</span><span class="w"> </span><span class="n">v5</span>
<span class="n">v6</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i64x2</span><span class="w"> </span><span class="n">v7</span><span class="p">,</span><span class="w"> </span><span class="n">v8</span>
</code></pre></div>
<p>Could be lowered to:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 4 elements of 32bit size</span>
<span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
<span class="c1">;; Here we don't actually need to change the hardware despite it being a different CLIF type!</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span>
<span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="no">e64</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 2 elements of 64bit size</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span>
</code></pre></div>
<p>Switching vector modes is not done during instruction selection, but on a  VCode pass that runs post Instruction Selection.</p>
<p>Each lowered vector instruction carries the full vector configuration that it needs, and in the VCode Pass we insert <code>vsetvli</code>'s as necessary (i.e. between instructions with different vector configurations).</p>
<h2>1.1 VCode Instructions</h2>
<p>The first step is carrying the full vector configuration in each VCode instruction. Here's how I expect these instructions to look like</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span><span class="w"> </span><span class="c1">#avl=2 #vtype=(e64, m1, ta, ma)</span>
</code></pre></div>
<p>I've lifted these names out of the ISA spec. </p>
<p><code>avl</code> (Application Vector Length) is the maximum number of elements that we want to process. For this SIMD proposal it's always an immediate with the number of lanes. However for the purposes of VCode it can also be a  register, this is required for interoperability with a future dynamic vector implementation.</p>
<p><code>vtype</code> is the rest of the configuration data for the vector hardware.</p>
<p>There is additional state that I'm ignoring here:
* <code>vxrm</code>: Vector fixed-point rounding mode register
* <code>vxsat</code>: Vector fixed-point saturation flag register</p>
<p>Not sure if we need these, but we can handle them in the same manner as <code>vtype</code>, and insert their respective mode switching instructions in the same pass.</p>
<p>Additionally each instruction has an optional mask register. When unmasked this does not show up in the assembly, this is handled as a normal register input to each instruction.</p>
<h2>1.2 The VCode Pass</h2>
<p>After Instruction Selection (but before Register Allocation!) we need to run a custom VCode pass.</p>
<p>This pass walks the VCode forwards  and keeps track of the "current" vector configuration. Whenever a instruction requests a different one we emit a <code>vsetvli</code>.</p>
<p>The reason for this being done Pre-Regalloc is that for the actual dynamic vectors. <code>avl</code> is probably not an immediate, but a register with the number of elements that we want to process. So we also need to have that interaction with regalloc. I don't expect to have to do that for SIMD yet, but this pass should probably work for both the current SIMD implementation and a future Dynamic Vectors  implementation.</p>
<p>The current calling convention clobbers the vector configuration on all calls. So we also need to keep track of that and query the ABI layer.</p>
<p>A neat idea to further optimize this is by inheriting the vector configuration if all the dominator blocks to the current block end in the same vector configuration. This avoids us having to emit a <code>vsetvli</code> on each basic block if the configuration never changes.</p>
<p>A downside of this pass is that we <em>need</em> to run it to get correct codegen. Even if we never emit a vector instruction. I don't know the performance implications of this, but it's something to keep in mind.</p>
<p>This approach is quite similar to what LLVM does, see Page 41 of [this presentation][rvv-intro] for more details on that.</p>
<p>Some other ideas in <a href="#2.-alternative-ways-of-emitting-vsetvli">Alternative ways of emitting <code>vsetvli</code></a></p>
<h1>2. Additional considerations</h1>
<h2>2.1. Spills and Reloads</h2>
<p>We can't do a dynamic sized spill/reload, which is going to be an issue for implementing full dynamic vectors. (See also the discussion here: <a href="https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682">https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682</a>)</p>
<p>But since that isn't implemented yet, and we don't use vector registers for anything else maybe we can do a fixed size 128b store/load for now?</p>
<p>This is definitely incompatible with a full Dynamic Vector implementation. But for that to work we need to save the full registers and with that the scheme above should still work.</p>
<h2>2.2. Calling Convention for Vectors</h2>
<p>All registers are Caller-Saved, vl and vtype are also Caller-Saved. </p>
<p>Standard States:</p>
<blockquote>
<p>Vector registers are not used for passing arguments or return values; we intend to define a new calling convention variant to allow that as a future software optimization.</p>
</blockquote>
<p><a href="https://godbolt.org/z/T7sMqz4so">Clang does a dynamic stack store and seems to pass everything via stack.</a>. This is the same problem as <a href="#2.1.-spills-and-reloads">2.1. Spills and Reloads</a></p>
<ul>
<li>[RISC-V Vector Register Convention][psabi-vector-register-convention]</li>
<li>[RISC-V ELF psABI (pdf)][psabi]</li>
</ul>
<h2>2.3. Regalloc fun for small vectors implementations</h2>
<p>(See <code>§18.1. Zvl*: Minimum Vector Length Standard Extensions</code> of the [V Extension Spec][v-spec-18-1]) </p>
<p>The minimum vector register width is 32bits. This means that in the worse case we need to group up 4 registers to process a single 128b operation. (This is something you can do with RISC-V Vector hardware, but hopefully we won't have to)</p>
<p>This affects regalloc since if we compile with a minimum vector register width of 32bits, we effectively only have 8 registers to work with.</p>
<p>This is a problem because we have to share our regalloc space with the float registers since we don't have space for an additional register class (see: [regalloc2/#47][regalloc2-reg-classes]). This means that we need to have the same number of float registers as vector registers. (At least I'm not seeing any clever regalloc tricks that we can pull off here)</p>
<p>My solution for this is to ignore <code>Zvl32b</code> and <code>Zvl64b</code> for now. </p>
<p>Additionally <code>§18.3. V: Vector Extension for Application Processors</code> states: </p>
<blockquote>
<p>The V vector extension requires Zvl128b.</p>
</blockquote>
<p>So it seems like a reasonable expectation that Linux running RISC-V CPU's will have <code>Zvl128b</code>, and if this turns out to be untrue we can change regalloc to deal with it.</p>
<h2>3. Alternative ways of emitting <code>vsetvli</code></h2>
<p>This applies to both the SIMD implementation and future Dynamic Vector implementations so we need to keep that in mind.</p>
<h3>3.1 Keeping state during instruction selection</h3>
<p>It would be neat if we could query the last set element length <br>
[message truncated]</p>
</blockquote>



<a name="345483209"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345483209" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345483209">(Mar 29 2023 at 18:18)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489085308">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>I've got no prior knowledge of RISC-V, and I'm by no means a Cranelift expert, but this all sounds quite good! Two random thoughts I had reading over this:</p>
<blockquote>
<p>ta, ;; Tail-Agnostic Mode (The rest of the register past 128bits is left undefined)</p>
</blockquote>
<p>This reminds me of SSE-vs-AVX on the x64 architecture. SSE instructions only modify the lower 128-bits of each register, not modifying the upper bits of the register. AVX instructions, however, explicitly all zero the upper portions of each register. I believe one of the reasons for doing this was to prevent false dependencies between instructions and registers. For example if an SSE instruction modifies a register and then that's fed into an AVX instruction the AVX instruction might mistakenly think that whatever instruction prior to the SSE instruction which defined the register is additionally a dependency and must stall the processor pipeline until its done. This won't be necessary in the case that the AVX instruction only operates on the lower 128-bits though. </p>
<p>Now all of this is x64-specific and also I think it has to do with really specific details of how the processor is implemented (e.g. it assumes the processor has its own means of tracking dependencies between instructions and such). I bring all this up because it sounded pretty similar to this Tail-Agnostic mode? Is this something that the RISC-V spec recommends and/or are we following suit with LLVM here? I would otherwise naively say that the lesson learned from x64 was to explicitly zero upper bits of registers.</p>
<p>Although that being said I'm not sure how this fits in RISC-V since if you explicitly configure the hardware with what size of register you're operating over I'm not sure where the tail end shows up since we'll configure 128-bit registers and all operations will work over 128-bit registers.</p>
<blockquote>
<p>After Instruction Selection (but before Register Allocation!) we need to run a custom VCode pass.</p>
</blockquote>
<p>I actually naively thought that after emission we had lost all block-related structure and loops and such. This control flow is naturally quite important for a pass such as this, however. You also mention though that we can see if configuration can be inherited from dominating blocks so it sounds like this sort of control flow isn't lost? Mostly just wanted to confirm that we've still got all known control flow at this point.</p>
<p>Also is block domination the metric we'd want to use here? If block A dominates block B then that doesn't guarantee that A's vector configuration will make its way to B because all we can say is that A definitely executed before B but we can't say that nothing else executed between A and B?</p>
</blockquote>



<a name="345485022"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345485022" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345485022">(Mar 29 2023 at 18:26)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489097098">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>Oh also something that wasn't clear to me:</p>
<blockquote>
<p>A downside of this pass is that we need to run it to get correct codegen. Even if we never emit a vector instruction.</p>
</blockquote>
<p>Why is this? I'm not able to piece together why we'd run this pass even if we didn't emit vector instructions.</p>
</blockquote>



<a name="345489819"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345489819" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345489819">(Mar 29 2023 at 18:45)</a>:</h4>
<p>afonso360 <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489121805">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>bring all this up because it sounded pretty similar to this Tail-Agnostic mode? Is this something that the RISC-V spec recommends and/or are we following suit with LLVM here? I would otherwise naively say that the lesson learned from x64 was to explicitly zero upper bits of registers.</p>
</blockquote>
<p>The other mode we have is <code>tu</code> Tail-Undisturbed which preserves the previous value of the register. My understanding is that tail agnostic is an optimization since it allows processors to ignore the rest of the register which has some performance benefits.</p>
<p>Here's the <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#343-vector-tail-agnostic-and-vector-mask-agnostic-vta-and-vma">relevant part in the spec</a></p>
<blockquote>
<p>The agnostic policy was added to accommodate machines with vector register renaming. With an undisturbed policy, all elements would have to be read from the old physical destination vector register to be copied into the new physical destination vector register. This causes an inefficiency when these inactive or tail values are not required for subsequent calculations. </p>
</blockquote>
<hr>
<blockquote>
<p>Although that being said I'm not sure how this fits in RISC-V since if you explicitly configure the hardware with what size of register you're operating over I'm not sure where the tail end shows up since we'll configure 128-bit registers and all operations will work over 128-bit registers.</p>
</blockquote>
<p>The tail only shows up if we are mixing different vector sizes, which we don't with SIMD, or at least not until we mix different SIMD sizes. (Not really planning on that right now)</p>
<hr>
<blockquote>
<p>I actually naively thought that after emission we had lost all block-related structure and loops and such. This control flow is naturally quite important for a pass such as this, however. You also mention though that we can see if configuration can be inherited from dominating blocks so it sounds like this sort of control flow isn't lost? Mostly just wanted to confirm that we've still got all known control flow at this point.</p>
</blockquote>
<p>After emission I think we no longer have that. But I was planning on inserting this after the initial VCode creation. So we still have the full VCode layout which we modify and feed something different to regalloc.</p>
<p>As far as I understand we still have the full block information there. (And I really hope I'm not wrong on this since it would put quite a dent on this plan)</p>
<hr>
<blockquote>
<p>Also is block domination the metric we'd want to use here? If block A dominates block B then that doesn't guarantee that A's vector configuration will make its way to B because all we can say is that A definitely executed before B but we can't say that nothing else executed between A and B?</p>
</blockquote>
<p>Oh that's right! That's not really what we want, I guess we want to check <em>Immediate Dominators</em> of this block. (i.e. no intermediate blocks)</p>
<hr>
<blockquote>
<blockquote>
<p>A downside of this pass is that we need to run it to get correct codegen. Even if we never emit a vector instruction.<br>
Why is this? I'm not able to piece together why we'd run this pass even if we didn't emit vector instructions.</p>
</blockquote>
</blockquote>
<p>I was going to say that we don't know if that happened. But we can always keep track of that? Do we have a way of storing that information in the vcode? </p>
<p>Otherwise I agree, if we emit no vector instructions we shouldn't need that pass.<br>
</p>
</blockquote>



<a name="345490332"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345490332" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345490332">(Mar 29 2023 at 18:48)</a>:</h4>
<p>afonso360 edited a <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489121805">comment</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>bring all this up because it sounded pretty similar to this Tail-Agnostic mode? Is this something that the RISC-V spec recommends and/or are we following suit with LLVM here? I would otherwise naively say that the lesson learned from x64 was to explicitly zero upper bits of registers.</p>
</blockquote>
<p>The other mode we have is <code>tu</code> Tail-Undisturbed which preserves the previous value of the register. My understanding is that tail agnostic is an optimization since it allows processors to ignore the rest of the register which has some performance benefits.</p>
<p>Here's the <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#343-vector-tail-agnostic-and-vector-mask-agnostic-vta-and-vma">relevant part in the spec</a></p>
<blockquote>
<p>The agnostic policy was added to accommodate machines with vector register renaming. With an undisturbed policy, all elements would have to be read from the old physical destination vector register to be copied into the new physical destination vector register. This causes an inefficiency when these inactive or tail values are not required for subsequent calculations. </p>
</blockquote>
<hr>
<blockquote>
<p>Although that being said I'm not sure how this fits in RISC-V since if you explicitly configure the hardware with what size of register you're operating over I'm not sure where the tail end shows up since we'll configure 128-bit registers and all operations will work over 128-bit registers.</p>
</blockquote>
<p>The tail only shows up if we are mixing different vector sizes, which we don't with the current SIMD implementation. </p>
<hr>
<blockquote>
<p>I actually naively thought that after emission we had lost all block-related structure and loops and such. This control flow is naturally quite important for a pass such as this, however. You also mention though that we can see if configuration can be inherited from dominating blocks so it sounds like this sort of control flow isn't lost? Mostly just wanted to confirm that we've still got all known control flow at this point.</p>
</blockquote>
<p>After emission I think we no longer have that. But I was planning on inserting this after the initial VCode creation. So we still have the full VCode layout which we modify and feed something different to regalloc.</p>
<p>As far as I understand we still have the full block information there. (And I really hope I'm not wrong on this since it would put quite a dent on this plan)</p>
<hr>
<blockquote>
<p>Also is block domination the metric we'd want to use here? If block A dominates block B then that doesn't guarantee that A's vector configuration will make its way to B because all we can say is that A definitely executed before B but we can't say that nothing else executed between A and B?</p>
</blockquote>
<p>Oh that's right! That's not really what we want, I guess we want to check <em>Immediate Dominators</em> of this block. (i.e. no intermediate blocks)</p>
<hr>
<blockquote>
<blockquote>
<p>A downside of this pass is that we need to run it to get correct codegen. Even if we never emit a vector instruction.<br>
Why is this? I'm not able to piece together why we'd run this pass even if we didn't emit vector instructions.</p>
</blockquote>
</blockquote>
<p>I was going to say that we don't know if that happened. But we can always keep track of that? Do we have a way of storing that information in the vcode? </p>
<p>Otherwise I agree, if we emit no vector instructions we shouldn't need that pass.<br>
</p>
</blockquote>



<a name="345492172"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345492172" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345492172">(Mar 29 2023 at 18:57)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489138497">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>Oh that's right! That's not really what we want, I guess we want to check _Immediate Dominators_ of this block. (i.e. no intermediate blocks)</p>
</blockquote>
<p>A quick note on this before diving into the full writeup (thanks for thinking through all of this, by the way!): idom isn't quite right either, I think. The idom of a block isn't necessarily an immediate predecessor, just the closest block that does dominate (does not dom any other block that doms the block in question). For example, in an if-else diamond, the tail block's idom is the head block (before the if-else), but either of the if-branch or else-branch could have modified state.</p>
<p>So I think what's needed is actually a forward dataflow analysis. We could avoid doing the fixpoint by always assuming state is unknown entering a loop (any block with a pred that is not earlier in RPO) and then do a forward scan, accumulating and meeting (on the semilattice) state at the end of forward edges as we see them.</p>
<p>I'd actually be curious how much difference there would be with a much simpler approach: assume state is unknown entering every basic block, and configure vector state as needed. This could even be tracked in the <code>EmitState</code>, so would not need a separate pass before <code>VCode::emit</code> (it would just need a "reset at top of basic block" hook on the <code>EmitState</code>). Then any vector inst could potentially emit the "set up state for what I expect" before the actual inst, and update <code>EmitState</code> appropriately. (Detail to take care of: max inst size needs to account for that.)</p>
</blockquote>



<a name="345493797"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345493797" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345493797">(Mar 29 2023 at 19:04)</a>:</h4>
<p>alexcrichton <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489149504">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>The other mode we have is tu Tail-Undisturbed which preserves the previous value of the register</p>
</blockquote>
<p>Ah nice! Ok so sounds like what you're recommending matches with the "lesson learned" from x64, so sounds good!</p>
<hr>
<blockquote>
<p>The tail only shows up if we are mixing different vector sizes, which we don't with the current SIMD implementation.</p>
</blockquote>
<p>Ok now you've got me curious though. I realize it's probably not relevant for wasm/Cranelift since it only supports 128-bit vectors for now, but in the abstract, I'm still not actually sure how this would show up? It sounded like each instruction would run in the configuration previously configured, so in that sense isn't the width of the registers always fully defined and instructions all operate on full registers widths? Or are there some instructions which operate on, for example, half of whatever the current register width is?</p>
<p>Given my curiosity here I should probably also go read over the blog you linked which likely has an example of when ta-vs-tu comes up.</p>
<hr>
<blockquote>
<p>I was going to say that we don't know if that happened. But we can always keep track of that? Do we have a way of storing that information in the vcode?</p>
</blockquote>
<p>Ah ok makes sense! I do agree that it might be a bit tricky to track whether vector instructions were emitted, and it wouldn't be the first thing that I would reach for. My gut instinct though would be to implement the pass you've outlined (pending an alternative strategy) and only have this sort of optimization to skip the pass entirely if it's measured to be too expensive (for some threshold of "too expensive")</p>
</blockquote>



<a name="345495098"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345495098" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345495098">(Mar 29 2023 at 19:11)</a>:</h4>
<p>jameysharp <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489159054">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>Thank you for the thorough explanation!</p>
<p>Regarding adding more register classes, it looks like Cranelift quit using <code>regalloc2::OperandKind::Mod</code> as of #5073 last October. So hopefully we're on track for fixing <a href="https://github.com/bytecodealliance/regalloc2/issues/47">bytecodealliance/regalloc2#47</a> "soon". But it sounds like you can safely get this working with the assumption that vector registers are at least 128 bits wide, and extend to grouped registers later if necessary.</p>
<p>I actually like the "Post-Lowering VCode Delete pass" option better than a pass that inserts instructions. <code>Vec::retain</code> is O(n) in the number of instructions, works in-place, and is in <code>std</code>. By contrast, if you want to insert a bunch of randomly-located elements in linear time, the easiest way is to allocate a new buffer and copy into it. If you know how many instructions you need to insert then you can do it in linear time by working backward, but that isn't conveniently provided by <code>std</code>.</p>
<p>We wouldn't want to track in the vcode whether any vector instructions were used, but I think lowering should be able to carry a flag through the lowering context. So if you do need to do a pass over the vcode I don't think it's hard to avoid paying that cost when you don't need it.</p>
<p>That said, does the register allocator need to see the <code>vsetvli</code> instructions? If you keep some sort of side table about which points require reconfiguring the vector mode, you could look up during instruction emission whether you need to emit a <code>vsetvli</code> first, and avoid actually editing the vcode. There's a similar idea for emitting moves that register allocation inserted, without editing the vcode.</p>
<p>I was thinking that emission happened in backward order, but only lowering does that I guess. So yeah, I like Chris' suggestion about tracking state during emission within only the local basic block. A forward dataflow pass may get better results but it's worth seeing how far we can get with the simpler option first.</p>
</blockquote>



<a name="345500858"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345500858" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345500858">(Mar 29 2023 at 19:42)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489198018">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>Indeed, with the removal of <code>Mod</code> I reassigned the associated bit in <code>Operand</code> to the class field, so we can have up to four classes now.</p>
<p>Re: extra pass -- to be clear, I think we can get away without <em>any</em> extra pass, as opposed to the two options above of "deleting pass" and "inserting pass". It would work the same way that our pseudoinsts do today: in e.g. the <code>emit</code> impl for a vector ALU instruction, we do something like</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="k">if</span><span class="w"> </span><span class="kd">let</span><span class="w"> </span><span class="nb">Some</span><span class="p">(</span><span class="n">vsetvli</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">emit_state</span><span class="p">.</span><span class="n">setup_for_state</span><span class="p">(</span><span class="n">lane_config</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">vsetvli</span><span class="p">.</span><span class="n">emit</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span><span class="w"> </span><span class="o">..</span><span class="p">.);</span>
<span class="p">}</span>
<span class="n">emit</span><span class="p">(</span><span class="n">actual_opcodes</span><span class="p">);</span>
</code></pre></div>
<p>that avoids the overhead of the pass, and of materializing the insts into a buffer.</p>
</blockquote>



<a name="345511309"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345511309" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345511309">(Mar 29 2023 at 20:39)</a>:</h4>
<p>afonso360 <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489278310">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>A quick note on this before diving into the full writeup (thanks for thinking through all of this, by the way!): idom isn't quite right either, I think. The idom of a block isn't necessarily an immediate predecessor, just the closest block that does dominate (does not dom any other block that doms the block in question). </p>
</blockquote>
<p>Ha! I need to go read that stuff again more carefully!</p>
<blockquote>
<p>I'd actually be curious how much difference there would be with a much simpler approach: assume state is unknown entering every basic block, and configure vector state as needed. This could even be tracked in the EmitState, so would not need a separate pass before VCode::emit (it would just need a "reset at top of basic block" hook on the EmitState). Then any vector inst could potentially emit the "set up state for what I expect" before the actual inst, and update EmitState appropriately. (Detail to take care of: max inst size needs to account for that.)</p>
</blockquote>
<p>Not needing a separate pass would be really nice. And I think it might work! </p>
<p>I think this prevents analysis of the previous vector state between blocks right? But even if it does, we can always move to a separate pass later!</p>
<p>I really like this!</p>
<hr>
<blockquote>
<p>Or are there some instructions which operate on, for example, half of whatever the current register width is?</p>
</blockquote>
<p>Yeah, the simplest one I can think of is <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#161-integer-scalar-move-instructions"><code>vmv.s.x</code></a> which moves a scalar register into element 0 of a vector. And leaves the rest of the vector up to the tail policy.</p>
<p>Also <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#14-vector-reduction-operations">Vector Reduction Operations</a> do a reduction of the vector into the first element of the vector and consider the rest of the vector the "tail".</p>
<p>So a <code>vredsum.vs</code> (Vector Reduce Sum) instruction with tail undisturbed would place the sum in the first element of the vector, but leave the other elements unchanged.</p>
<p>I'm not sure which instruction we have for for example f64 -&gt; f32, but I would assume those would also leave half the register up to the tail policy</p>
<hr>
<blockquote>
<p>But it sounds like you can safely get this working with the assumption that vector registers are at least 128 bits wide, and extend to grouped registers later if necessary.</p>
</blockquote>
<p>I think we should be ok for now. I just didn't want to outright exclude any implementation of vectors that isn't &gt;=128b.</p>
<blockquote>
<p>I was thinking that emission happened in backward order, but only lowering does that I guess. So yeah, I like Chris' suggestion about tracking state during emission within only the local basic block. A forward dataflow pass may get better results but it's worth seeing how far we can get with the simpler option first.</p>
</blockquote>
<p>Yeah, I agree with that! It seems like a good idea for a first implementation.<br>
</p>
</blockquote>



<a name="345511408"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345511408" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345511408">(Mar 29 2023 at 20:40)</a>:</h4>
<p>afonso360 edited a <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489278310">comment</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>A quick note on this before diving into the full writeup (thanks for thinking through all of this, by the way!): idom isn't quite right either, I think. The idom of a block isn't necessarily an immediate predecessor, just the closest block that does dominate (does not dom any other block that doms the block in question). </p>
</blockquote>
<p>Ha! I need to go read that stuff again more carefully!</p>
<blockquote>
<p>I'd actually be curious how much difference there would be with a much simpler approach: assume state is unknown entering every basic block, and configure vector state as needed. This could even be tracked in the EmitState, so would not need a separate pass before VCode::emit (it would just need a "reset at top of basic block" hook on the EmitState). Then any vector inst could potentially emit the "set up state for what I expect" before the actual inst, and update EmitState appropriately. (Detail to take care of: max inst size needs to account for that.)</p>
</blockquote>
<p>Not needing a separate pass would be really nice. And I think it might work! </p>
<p>I think this prevents analysis of the previous vector state between blocks right? But even if it does, we can always move to a separate pass later.</p>
<p>I really like this!</p>
<hr>
<blockquote>
<p>Or are there some instructions which operate on, for example, half of whatever the current register width is?</p>
</blockquote>
<p>Yeah, the simplest one I can think of is <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#161-integer-scalar-move-instructions"><code>vmv.s.x</code></a> which moves a scalar register into element 0 of a vector. And leaves the rest of the vector up to the tail policy.</p>
<p>Also <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#14-vector-reduction-operations">Vector Reduction Operations</a> do a reduction of the vector into the first element of the vector and consider the rest of the vector the "tail".</p>
<p>So a <code>vredsum.vs</code> (Vector Reduce Sum) instruction with tail undisturbed would place the sum in the first element of the vector, but leave the other elements unchanged.</p>
<p>I'm not sure which instruction we have for for example f64 -&gt; f32, but I would assume those would also leave half the register up to the tail policy</p>
<hr>
<blockquote>
<p>But it sounds like you can safely get this working with the assumption that vector registers are at least 128 bits wide, and extend to grouped registers later if necessary.</p>
</blockquote>
<p>I think we should be ok for now. I just didn't want to outright exclude any implementation of vectors that isn't &gt;=128b.</p>
<blockquote>
<p>I was thinking that emission happened in backward order, but only lowering does that I guess. So yeah, I like Chris' suggestion about tracking state during emission within only the local basic block. A forward dataflow pass may get better results but it's worth seeing how far we can get with the simpler option first.</p>
</blockquote>
<p>Yeah, I agree with that! It seems like a good idea for a first implementation.<br>
</p>
</blockquote>



<a name="345515091"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345515091" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345515091">(Mar 29 2023 at 21:03)</a>:</h4>
<p>afonso360 edited a <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489278310">comment</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>A quick note on this before diving into the full writeup (thanks for thinking through all of this, by the way!): idom isn't quite right either, I think. The idom of a block isn't necessarily an immediate predecessor, just the closest block that does dominate (does not dom any other block that doms the block in question). </p>
</blockquote>
<p>Ha! I need to go read that stuff again more carefully!</p>
<blockquote>
<p>I'd actually be curious how much difference there would be with a much simpler approach: assume state is unknown entering every basic block, and configure vector state as needed. This could even be tracked in the EmitState, so would not need a separate pass before VCode::emit (it would just need a "reset at top of basic block" hook on the EmitState). Then any vector inst could potentially emit the "set up state for what I expect" before the actual inst, and update EmitState appropriately. (Detail to take care of: max inst size needs to account for that.)</p>
</blockquote>
<p>Not needing a separate pass would be really nice. And I think it might work! </p>
<p>I think this prevents analysis of the previous vector state between blocks right? But even if it does, we can always move to a separate pass later.</p>
<p>I really like this!</p>
<hr>
<blockquote>
<p>Or are there some instructions which operate on, for example, half of whatever the current register width is?</p>
</blockquote>
<p>Yeah, the simplest one I can think of is <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#161-integer-scalar-move-instructions"><code>vmv.s.x</code></a> which moves a scalar register into element 0 of a vector. And leaves the rest of the vector up to the tail policy.</p>
<p>Also <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#14-vector-reduction-operations">Vector Reduction Operations</a> do a reduction of the vector into the first element of the vector and consider the rest of the vector the "tail".</p>
<p>So a <code>vredsum.vs</code> (Vector Reduce Sum) instruction with tail undisturbed would place the sum in the first element of the vector, but leave the other elements unchanged.</p>
<p>I'm not sure which instruction we have for for example f64 -&gt; f32, but I would assume those would also leave half the register up to the tail policy</p>
<p>Edit: Actually <a href="https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#103-narrowing-vector-arithmetic-instructions">Vector Narrowing Operations</a> work the other way. One of the registers is accessed at twice the current element width. So we would configure it for 4x32bits elements, and it accesses 4x64 bits in one of the registers.</p>
<hr>
<blockquote>
<p>But it sounds like you can safely get this working with the assumption that vector registers are at least 128 bits wide, and extend to grouped registers later if necessary.</p>
</blockquote>
<p>I think we should be ok for now. I just didn't want to outright exclude any implementation of vectors that isn't &gt;=128b.</p>
<blockquote>
<p>I was thinking that emission happened in backward order, but only lowering does that I guess. So yeah, I like Chris' suggestion about tracking state during emission within only the local basic block. A forward dataflow pass may get better results but it's worth seeing how far we can get with the simpler option first.</p>
</blockquote>
<p>Yeah, I agree with that! It seems like a good idea for a first implementation.<br>
</p>
</blockquote>



<a name="345516067"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345516067" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345516067">(Mar 29 2023 at 21:08)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489324480">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<blockquote>
<p>I think this prevents analysis of the previous vector state between blocks right? But even if it does, we can always move to a separate pass later.</p>
</blockquote>
<p>Right, it needs to be basic-block-local for now. We could definitely do better in several ways if we need to later... e.g. I can see a way to build the single-pass-only variant of the analysis into the emit pass by giving <code>EmitState</code> methods to "observe <code>EmitState</code> from source at destination of forward edge" (merge vector states, go to "unknown" if conflict) and "observe destination of backward edge" (clear known vector state).</p>
</blockquote>



<a name="345521872"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/345521872" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#345521872">(Mar 29 2023 at 21:50)</a>:</h4>
<p>jameysharp <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1489375584">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>If it turns out to matter later, I think we could build a summary of inter-block vector state during lowering. We'll have seen all blocks during that phase and we don't need the information until the emission phase. If there's a call or vector instruction in a block, we know that block's final state with certainty. For the remaining blocks, we can either do a forward dataflow analysis to fill in the state, or just treat them as having unknown state. Then determining each block's entry state is a linear pass over all edges.</p>
</blockquote>



<a name="352112373"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/352112373" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#352112373">(Apr 23 2023 at 19:06)</a>:</h4>
<p>afonso360 <a href="https://github.com/bytecodealliance/wasmtime/issues/6118#issuecomment-1519134721">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p>Closing this since the initial part has landed in #6240.</p>
</blockquote>



<a name="352112375"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%236118%20riscv64%3A%20Implementing%20Fixed%20Width%20.../near/352112375" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.236118.20riscv64.3A.20Implementing.20Fixed.20Width.20.2E.2E.2E.html#352112375">(Apr 23 2023 at 19:06)</a>:</h4>
<p>afonso360 closed <a href="https://github.com/bytecodealliance/wasmtime/issues/6118">issue #6118</a>:</p>
<blockquote>
<p><span aria-label="wave" class="emoji emoji-1f44b" role="img" title="wave">:wave:</span> Hey,</p>
<p>I've been thinking about how to implement SIMD operations on the RISC-V backend. These are sort of my notes / thoughts about this. Hopefully I haven't missed something too big that invalidates all of this.</p>
<p>Feedback would be appreciated! </p>
<h1>RISC-V Vector Intro</h1>
<p>This is a small introduction to the Vector Extensions in case people aren't familiar with it.</p>
<ul>
<li>In RISC-V we have 32 vector registers.</li>
<li>These registers have <em>some</em> uarch specific size.<ul>
<li>This can be queried at run time</li>
</ul>
</li>
<li>Each vector register has a minimum of 32bits (The maximum is 64KiB <span aria-label="eyes" class="emoji emoji-1f440" role="img" title="eyes">:eyes:</span>).<br>
    * The minimum for Application Processors is 128 bits</li>
<li>It can process elements of size 8, 16, 32 and 64 bits<br>
    * Element size is part of architectural state and not each explicit in each instruction<br>
    * So, we have a generic <code>add</code> instruction that is both <code>add.i32</code> and <code>add.i64</code> depending on how the hardware is currently configured</li>
<li>If necessary we can group multiple registers to get a larger register<br>
    * If we have 32 x 128bit registers, we can use them as 16 x 256bit registers instead<br>
    * This is also part of architectural state and not defined in each instruction<br>
    * We probably won't use this, but its a cool trick</li>
<li>Hardware is configured using the <code>vset{i}vl{i}</code> instruction<br>
    * I'm mention it here, because I use that instruction name a few times in the rest of the document</li>
<li>Masking is supported<br>
    * We have one mask register (v0)<br>
    * The mask register has double use as both a regular vector register and a mask register<br>
    * I don't think we will use masking anywhere in this proposal<br>
        * Maybe for some weird SIMD instruction?</li>
</ul>
<p>I like this [blog post that explains how this all works in a much better way][rvv-intro-blog].</p>
<h1>1. Planned implementation</h1>
<p>With some careful orchestration we can operate the Vector hardware for fixed width SIMD operations.</p>
<p>The general idea is that we can emulate a <code>iadd.i32x4</code> by emitting the following code:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
</code></pre></div>
<p>Here's an explanation of that:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w">  </span><span class="c1">;; This instruction configures the vector hardware</span>
<span class="w">         </span><span class="nf">zero</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Ignore the amount of processed elements. (We know that we can process them all in one go)</span>
<span class="w">               </span><span class="err">4,</span><span class="w"> </span><span class="c1">;; Process at most 4 elements</span>
<span class="w">                  </span><span class="nf">e32</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Each element is 32 bits</span>
<span class="w">                       </span><span class="nf">m1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Do not group registers</span>
<span class="w">                           </span><span class="nf">ta</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Tail-Agnostic Mode (The rest of the register past 128bits is left undefined)</span>
<span class="w">                               </span><span class="nf">ma</span><span class="w"> </span><span class="c1">;; Mask-Agnostic Mode (Similar to ta but for the mask register)</span>

<span class="nf">vadd.vv</span><span class="w"> </span><span class="c1">;; Vector Add (Vector-Vector)</span>
<span class="w">        </span><span class="nf">v0</span><span class="p">,</span><span class="w"> </span><span class="c1">;; Store the results in v0 (It is a usable register for vectors unlike x0)</span>
<span class="w">            </span><span class="nf">v1</span><span class="p">,</span><span class="w"> </span><span class="c1">;; LHS is the v1 register</span>
<span class="w">                </span><span class="nf">v2</span><span class="w"> </span><span class="c1">;; RHS is the v2 register</span>
</code></pre></div>
<p><code>vsetivli</code> has an output register that saves the amount of elements it can do, but since we know that all processors support a minimum of 128bits per vector register we have a guarantee that all elements will be processed by a single instruction and don't need to check the output register. So we set it to the zero register to ignore it. (There are some asterisks here, see <a href="#2.3.-regalloc-fun-for-small-vectors-implementations">Regalloc fun for small vectors implementations</a> for more details on that!)</p>
<p>We also only need to reconfigure the vector hardware when we change element-width or element-count. So this CLIF code:</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="n">v0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fadd</span><span class="p">.</span><span class="n">f32x4</span><span class="w"> </span><span class="n">v1</span><span class="p">,</span><span class="w"> </span><span class="n">v2</span>
<span class="n">v3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i32x4</span><span class="w"> </span><span class="n">v4</span><span class="p">,</span><span class="w"> </span><span class="n">v5</span>
<span class="n">v6</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">iadd</span><span class="p">.</span><span class="n">i64x2</span><span class="w"> </span><span class="n">v7</span><span class="p">,</span><span class="w"> </span><span class="n">v8</span>
</code></pre></div>
<p>Could be lowered to:</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="no">e32</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 4 elements of 32bit size</span>
<span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span>
<span class="c1">;; Here we don't actually need to change the hardware despite it being a different CLIF type!</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span>
<span class="nf">vsetivli</span><span class="w"> </span><span class="no">zero</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="no">e64</span><span class="p">,</span><span class="w"> </span><span class="no">m1</span><span class="p">,</span><span class="w"> </span><span class="no">ta</span><span class="p">,</span><span class="w"> </span><span class="no">ma</span><span class="w"> </span><span class="c1">;; 2 elements of 64bit size</span>
<span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span>
</code></pre></div>
<p>Switching vector modes is not done during instruction selection, but on a  VCode pass that runs post Instruction Selection.</p>
<p>Each lowered vector instruction carries the full vector configuration that it needs, and in the VCode Pass we insert <code>vsetvli</code>'s as necessary (i.e. between instructions with different vector configurations).</p>
<h2>1.1 VCode Instructions</h2>
<p>The first step is carrying the full vector configuration in each VCode instruction. Here's how I expect these instructions to look like</p>
<div class="codehilite" data-code-language="GAS"><pre><span></span><code><span class="nf">vfadd.vv</span><span class="w"> </span><span class="no">v0</span><span class="p">,</span><span class="w"> </span><span class="no">v1</span><span class="p">,</span><span class="w"> </span><span class="no">v2</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v3</span><span class="p">,</span><span class="w"> </span><span class="no">v4</span><span class="p">,</span><span class="w"> </span><span class="no">v5</span><span class="w"> </span><span class="c1">#avl=4 #vtype=(e32, m1, ta, ma)</span>
<span class="w"> </span><span class="nf">vadd.vv</span><span class="w"> </span><span class="no">v6</span><span class="p">,</span><span class="w"> </span><span class="no">v7</span><span class="p">,</span><span class="w"> </span><span class="no">v8</span><span class="w"> </span><span class="c1">#avl=2 #vtype=(e64, m1, ta, ma)</span>
</code></pre></div>
<p>I've lifted these names out of the ISA spec. </p>
<p><code>avl</code> (Application Vector Length) is the maximum number of elements that we want to process. For this SIMD proposal it's always an immediate with the number of lanes. However for the purposes of VCode it can also be a  register, this is required for interoperability with a future dynamic vector implementation.</p>
<p><code>vtype</code> is the rest of the configuration data for the vector hardware.</p>
<p>There is additional state that I'm ignoring here:<br>
* <code>vxrm</code>: Vector fixed-point rounding mode register<br>
* <code>vxsat</code>: Vector fixed-point saturation flag register</p>
<p>Not sure if we need these, but we can handle them in the same manner as <code>vtype</code>, and insert their respective mode switching instructions in the same pass.</p>
<p>Additionally each instruction has an optional mask register. When unmasked this does not show up in the assembly, this is handled as a normal register input to each instruction.</p>
<h2>1.2 The VCode Pass</h2>
<p>After Instruction Selection (but before Register Allocation!) we need to run a custom VCode pass.</p>
<p>This pass walks the VCode forwards  and keeps track of the "current" vector configuration. Whenever a instruction requests a different one we emit a <code>vsetvli</code>.</p>
<p>The reason for this being done Pre-Regalloc is that for the actual dynamic vectors. <code>avl</code> is probably not an immediate, but a register with the number of elements that we want to process. So we also need to have that interaction with regalloc. I don't expect to have to do that for SIMD yet, but this pass should probably work for both the current SIMD implementation and a future Dynamic Vectors  implementation.</p>
<p>The current calling convention clobbers the vector configuration on all calls. So we also need to keep track of that and query the ABI layer.</p>
<p>A neat idea to further optimize this is by inheriting the vector configuration if all the dominator blocks to the current block end in the same vector configuration. This avoids us having to emit a <code>vsetvli</code> on each basic block if the configuration never changes.</p>
<p>A downside of this pass is that we <em>need</em> to run it to get correct codegen. Even if we never emit a vector instruction. I don't know the performance implications of this, but it's something to keep in mind.</p>
<p>This approach is quite similar to what LLVM does, see Page 41 of [this presentation][rvv-intro] for more details on that.</p>
<p>Some other ideas in <a href="#2.-alternative-ways-of-emitting-vsetvli">Alternative ways of emitting <code>vsetvli</code></a></p>
<h1>2. Additional considerations</h1>
<h2>2.1. Spills and Reloads</h2>
<p>We can't do a dynamic sized spill/reload, which is going to be an issue for implementing full dynamic vectors. (See also the discussion here: <a href="https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682">https://github.com/bytecodealliance/rfcs/pull/19#issuecomment-998999682</a>)</p>
<p>But since that isn't implemented yet, and we don't use vector registers for anything else maybe we can do a fixed size 128b store/load for now?</p>
<p>This is definitely incompatible with a full Dynamic Vector implementation. But for that to work we need to save the full registers and with that the scheme above should still work.</p>
<h2>2.2. Calling Convention for Vectors</h2>
<p>All registers are Caller-Saved, vl and vtype are also Caller-Saved. </p>
<p>Standard States:</p>
<blockquote>
<p>Vector registers are not used for passing arguments or return values; we intend to define a new calling convention variant to allow that as a future software optimization.</p>
</blockquote>
<p><a href="https://godbolt.org/z/T7sMqz4so">Clang does a dynamic stack store and seems to pass everything via stack.</a>. This is the same problem as <a href="#2.1.-spills-and-reloads">2.1. Spills and Reloads</a></p>
<ul>
<li>[RISC-V Vector Register Convention][psabi-vector-register-convention]</li>
<li>[RISC-V ELF psABI (pdf)][psabi]</li>
</ul>
<h2>2.3. Regalloc fun for small vectors implementations</h2>
<p>(See <code>§18.1. Zvl*: Minimum Vector Length Standard Extensions</code> of the [V Extension Spec][v-spec-18-1]) </p>
<p>The minimum vector register width is 32bits. This means that in the worse case we need to group up 4 registers to process a single 128b operation. (This is something you can do with RISC-V Vector hardware, but hopefully we won't have to)</p>
<p>This affects regalloc since if we compile with a minimum vector register width of 32bits, we effectively only have 8 registers to work with.</p>
<p>This is a problem because we have to share our regalloc space with the float registers since we don't have space for an additional register class (see: [regalloc2/#47][regalloc2-reg-classes]). This means that we need to have the same number of float registers as vector registers. (At least I'm not seeing any clever regalloc tricks that we can pull off here)</p>
<p>My solution for this is to ignore <code>Zvl32b</code> and <code>Zvl64b</code> for now. </p>
<p>Additionally <code>§18.3. V: Vector Extension for Application Processors</code> states: </p>
<blockquote>
<p>The V vector extension requires Zvl128b.</p>
</blockquote>
<p>So it seems like a reasonable expectation that Linux running RISC-V CPU's will have <code>Zvl128b</code>, and if this turns out to be untrue we can change regalloc to deal with it.</p>
<h2>3. Alternative ways of emitting <code>vsetvli</code></h2>
<p>This applies to both the SIMD implementation and future Dynamic Vector implementations so we need to keep that in mind.</p>
<h3>3.1 Keeping state during instruction selection</h3>
<p>It would be neat if we could query the last set element length <br>
[message truncated]</p>
</blockquote>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>