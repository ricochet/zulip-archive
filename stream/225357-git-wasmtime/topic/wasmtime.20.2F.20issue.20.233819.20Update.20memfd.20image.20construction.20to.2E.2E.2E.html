<html>
<head><meta charset="utf-8"><title>wasmtime / issue #3819 Update memfd image construction to... · git-wasmtime · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/index.html">git-wasmtime</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233819.20Update.20memfd.20image.20construction.20to.2E.2E.2E.html">wasmtime / issue #3819 Update memfd image construction to...</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="272353084"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%233819%20Update%20memfd%20image%20construction%20to.../near/272353084" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233819.20Update.20memfd.20image.20construction.20to.2E.2E.2E.html#272353084">(Feb 18 2022 at 02:37)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/pull/3819#issuecomment-1043764790">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/pull/3819">issue #3819</a>:</p>
<blockquote>
<p>@alexcrichton I've been playing a bit with different modules to see if the above heuristics work, and I'm becoming increasingly worried. For example I have a wizened SpiderMonkey wasm with <code>init_size</code> of 7.8MB and <code>data_size</code> of 4.7MB; with some more playing with allocation ordering and such I'm sure I could push that under the 50%-density limit. Wasm modules that are Wizened from garbage-collected languages are especially vulnerable, because the memory layout tends to be more special than just "keep appending data", but really any process that snapshots could result in lower-density images because the right malloc/free pattern can create fragmentation in the heap.</p>
<p>My fundamental worry is, still, the performance cliff: if the user gets unlucky, they fall into a much lower-performance mode. It feels like we're optimizing for the wrong thing here: an abstract notion of sparse memory usage and leanness, but at the cost of real-world scenarios.</p>
<p>To give another example, if I write a program with a native toolchain and embed data in it, and that data happens to have lots of zeroes, <code>ld</code> is happy to produce a <code>.data</code> or <code>.rodata</code> that is huge, proportional with my program's initial memory footprint. It's optimizing for mmap-ability of the data.</p>
<p>I think we should do the same thing: fundamentally, we're compiling to a representation that is "close to the metal", and part of that closeness is that it has a one-to-one image of what will go into memory. Making that a behavior that one has to fit the right heuristics to get just feels wrong somehow; like JavaScript engines all over again.</p>
<p>So, I'd like to argue that we revert this change, and go back to a static limit of some sort, as I had proposed above. We could perhaps make it user-configurable (I'd happily agree that baked-in arbitrary limits are bad), but I want to make sure the cliff is harder to hit than "oops, did too much wizening and heap is a bit sparse" :-)</p>
<p>Thoughts?</p>
</blockquote>



<a name="272353535"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%233819%20Update%20memfd%20image%20construction%20to.../near/272353535" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233819.20Update.20memfd.20image.20construction.20to.2E.2E.2E.html#272353535">(Feb 18 2022 at 02:45)</a>:</h4>
<p>cfallin edited a <a href="https://github.com/bytecodealliance/wasmtime/pull/3819#issuecomment-1043764790">comment</a> on <a href="https://github.com/bytecodealliance/wasmtime/pull/3819">issue #3819</a>:</p>
<blockquote>
<p>@alexcrichton I've been playing a bit with different modules to see if the above heuristics work, and I'm becoming increasingly worried. For example I have a wizened SpiderMonkey wasm with <code>init_size</code> of 7.8MB and <code>data_size</code> of 4.7MB; with some more playing with allocation ordering and such I'm sure I could push that under the 50%-density limit. Wasm modules that are Wizened from garbage-collected languages are especially vulnerable, because the memory layout tends to be more special than just "keep appending data", but really any process that snapshots could result in lower-density images because the right malloc/free pattern can create fragmentation in the heap.</p>
<p>My fundamental worry is, still, the performance cliff: if the user gets unlucky, they fall into a much lower-performance mode. It feels like we're optimizing for the wrong thing here: an abstract notion of sparse memory usage and leanness, but at the cost of real-world scenarios.</p>
<p>To give another example, if I write a program with a native toolchain and embed data in it, and that data happens to have lots of zeroes, <code>ld</code> is happy to produce a <code>.data</code> or <code>.rodata</code> that is huge, proportional with my program's initial memory footprint. It's optimizing for mmap-ability of the data.</p>
<p>I think we should do the same thing: fundamentally, we're compiling to a representation that is "close to the metal", and part of that closeness is that it has a one-to-one image of what will go into memory. Making that a behavior that one has to fit the right heuristics to get just feels wrong somehow; like JavaScript engines all over again.</p>
<p>So, I'd like to argue that we revert this change, and go back to a static limit of some sort, as I had proposed above (EDIT: actually in the discussion in #3815). We could perhaps make it user-configurable (I'd happily agree that baked-in arbitrary limits are bad), but I want to make sure the cliff is harder to hit than "oops, did too much wizening and heap is a bit sparse" :-)</p>
<p>Thoughts?</p>
</blockquote>



<a name="272355633"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/225357-git-wasmtime/topic/wasmtime%20/%20issue%20%233819%20Update%20memfd%20image%20construction%20to.../near/272355633" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Wasmtime GitHub notifications bot <a href="https://bytecodealliance.github.io/zulip-archive/stream/225357-git-wasmtime/topic/wasmtime.20.2F.20issue.20.233819.20Update.20memfd.20image.20construction.20to.2E.2E.2E.html#272355633">(Feb 18 2022 at 03:21)</a>:</h4>
<p>cfallin <a href="https://github.com/bytecodealliance/wasmtime/pull/3819#issuecomment-1043816301">commented</a> on <a href="https://github.com/bytecodealliance/wasmtime/pull/3819">issue #3819</a>:</p>
<blockquote>
<p>Ah, and one more advantage of a static limit-based approach is that we can take advantage of the "image and leftovers" aspect of our initialization data structure: we can build a dense image, ready to mmap, for all memory up to the last data segment that is below our bound; and then only do eager initialization for data beyond that.</p>
<p>This means that e.g. if we have relatively dense heap down in the 0..N MB range, and then a random byte up at 1GiB, we don't reject the whole thing and do eager init of N megabytes; instead we continue to do memfd as normal and then just do eager init of the one random high byte.</p>
<p>I'll go ahead and create an issue for this rather than braindumping on a closed PR, sorry :-)</p>
</blockquote>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>