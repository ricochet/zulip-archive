<html>
<head><meta charset="utf-8"><title>wamr jit/aot faster than native · wamr · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://bytecodealliance.github.io/zulip-archive/stream/290350-wamr/index.html">wamr</a></h2>
<h3>Topic: <a href="https://bytecodealliance.github.io/zulip-archive/stream/290350-wamr/topic/wamr.20jit.2Faot.20faster.20than.20native.html">wamr jit/aot faster than native</a></h3>

<hr>

<base href="https://bytecodealliance.zulipchat.com">

<head><link href="https://bytecodealliance.github.io/zulip-archive/style.css" rel="stylesheet"></head>

<a name="407495052"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/290350-wamr/topic/wamr%20jit/aot%20faster%20than%20native/near/407495052" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mats Brorsson <a href="https://bytecodealliance.github.io/zulip-archive/stream/290350-wamr/topic/wamr.20jit.2Faot.20faster.20than.20native.html#407495052">(Dec 12 2023 at 14:54)</a>:</h4>
<p>Under what circumstances will a WebAssembly program execute faster with iwasm using the llvm jit? I have made a study and there is one program, PolyBench/correleation which can be found in this repo: <a href="https://github.com/matsbror/wabench/tree/ace5g">https://github.com/matsbror/wabench/tree/ace5g</a>, which on x86_64 executes faster with iwasm/llmv-jit than natively. </p>
<p>It seems conter-intuitive. I have tried to isolate the function in question as a WebAssembly module of its own and disassemble it, but, unfortunately, then the performance advantage disappeared.</p>
<p>Any ideas?</p>
<div class="message_embed"><a class="message_embed_image" href="https://github.com/matsbror/wabench/tree/ace5g" style="background-image: url(https\:\/\/uploads\.zulipusercontent\.net\/819591ed08be9c205fa4e085dd95f8e7f9a5e29f\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f363439316661613639393338366462333936666366333862393335623838323433323137353262626238646635393531663435653137643737303839656130662f6d61747362726f722f776162656e6368)"></a><div class="data-container"><div class="message_embed_title"><a href="https://github.com/matsbror/wabench/tree/ace5g" title="GitHub - matsbror/wabench at ace5g">GitHub - matsbror/wabench at ace5g</a></div><div class="message_embed_description">Contribute to matsbror/wabench development by creating an account on GitHub.</div></div></div>



<a name="407507836"></a>
<h4><a href="https://bytecodealliance.zulipchat.com#narrow/stream/290350-wamr/topic/wamr%20jit/aot%20faster%20than%20native/near/407507836" class="zl"><img src="https://bytecodealliance.github.io/zulip-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Jämes Ménétrey <a href="https://bytecodealliance.github.io/zulip-archive/stream/290350-wamr/topic/wamr.20jit.2Faot.20faster.20than.20native.html#407507836">(Dec 12 2023 at 15:49)</a>:</h4>
<p>Hello,</p>
<p>Check the following studies for similar observations:</p>
<ul>
<li>Twine: An Embedded Trusted Runtime for WebAssembly (<a href="https://arxiv.org/abs/2103.15860">https://arxiv.org/abs/2103.15860</a>), Section V.B.</li>
<li>Not So Fast: Analyzing the Performance of WebAssembly vs. Native Code (<a href="https://www.usenix.org/conference/atc19/presentation/jangda">https://www.usenix.org/conference/atc19/presentation/jangda</a>), Section 6.3.</li>
</ul>
<p>Basically, we concluded that a slightly faster execution using AOT may be due to fewer L1 instructions cache misses.</p>
<p>Cheers</p>



<hr><p>Last updated: Jan 20 2025 at 06:04 UTC</p>
</html>