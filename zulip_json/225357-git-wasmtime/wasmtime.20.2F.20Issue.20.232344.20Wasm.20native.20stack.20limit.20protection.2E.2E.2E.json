[
    {
        "content": "<p>alexcrichton opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Recently we've received a number of fuzz bugs all about stack overflows in native code. Each fuzz bug has a module which contains an infinitely recursive set of functions when instantiated/called, and the stack overflow happens in the native code of Wasmtime, and the exact native code changes depending on what the module is doing. This situation is supposed to be mitigated by limiting the amount of stack space wasm is allowed to take. After some investigation, however, this limiting isn't happening. </p>\n<p>When ASan is run with <code>ASAN_OPTIONS=\"detect_stack_use_after_return=1\"</code> then it allocates a \"shadow stack\" for each function frame. This means that <a href=\"https://github.com/bytecodealliance/wasmtime/blob/44cbdecea03c360ea82e6482f0cf6c614effef21/crates/runtime/src/traphandlers.rs#L504\">our guess of what the stack pointer is</a> is actually pointing into the shadow stack area instead of the real native stack. This means that we install a stack limit very far away from the actual stack  itself, rendering the stack limit useless since stack overflow is hit long before we get to the shadow stack.</p>\n<p>To be clear I don't think this is necessarily a but in Wasmtime, this only comes up with fuzzing under AddressSanitizer. That being said that fuzz mode is very important and we don't want to lose that! I think there's a few possible fixes we could do in this situation:</p>\n<ol>\n<li>Disable fuzzing with <code>detect_stack_use_after_return</code>. From what I can tell I think this is for having better error reports, and it may not be that critical for Wasmtime, especially with how rare use-after-return is in Rust. That being said I would prefer to take this route as a last resort.</li>\n<li>Fix our \"educated guess\" about what the stack pointer is. This would probably involve us compiling an asm stub which only says <code>mov %rsp, %rax; ret</code> or something like that. This I think should work since it won't be instrumented by ASan and point into the shadow stack. It's a bummer to maintain custom assembly, however.</li>\n<li>Refactor how we account for native stack space in wasm modules. Right now this is a <code>usize</code> where if <code>%rsp</code> is ever beneath it we trap. Instead we could change it to a <code>usize</code> of \"you have this many bytes left\" where each function subtracts and traps on overflow. Additionally, interrupts, which use this same flag, would simply set the remaining bytes to a negative number so the next comparison traps.</li>\n</ol>\n<p>I would personally lean towards the third option since I think it also reflects more accurately how much stack space wasm can use. It means we don't ever need the stack pointer itself in native code and interleaving small wasm stacks with larger native stacks will actually work, where it doesn't work today since wasm isn't allowed to go beyond the maximum stack size of the first wasm module on the stack.</p>\n<p>I'm curious what others think though!</p>\n</blockquote>",
        "id": 215266378,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604270757
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720257376\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>+1 to option 3; getting and reasoning about the stack pointer directly (at least in a platform-independent way by taking the address of an on-stack object...) seems quite fragile, whereas a countdown is completely portable.</p>\n<p>Also, if I understand correctly, this serves as a resource limit, but we still presumably have guard page(s) to protect against e.g. overflow in native code?</p>\n</blockquote>",
        "id": 215281944,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604297102
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720620661\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Right yeah we should always have a guard page, and that's what's being hit on CI where native code hits the guard page. We'd just rather not have native code hit the guard page for misbehaving wasm code!</p>\n</blockquote>",
        "id": 215352465,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604338730
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720780595\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Hm ok so I dug into this today, and I almost got it working. I realized, however, that option 3 works well for stack overflow but does not work well for interrupting execution of wasm modules. Currently, in an effort to make the function prologue efficient, we do both checks in one by updating the stack limit dynamically to kill any functions that later check the stack. This technique doesn't work when the functions themselves are updating the stack limit as well, since there's no synchronization with each function call.</p>\n<p>My best idea of how to handle this is that instead of this:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">sub</span><span class=\"w\"> </span><span class=\"cp\">$stack_size</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">stack_limit</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"n\">jns</span><span class=\"w\"> </span><span class=\"n\">ok</span><span class=\"w\"></span>\n<span class=\"n\">ud2</span><span class=\"w\"></span>\n<span class=\"n\">ok</span>:\n<span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"></span>\n</code></pre></div>\n<p>we instead do something like this:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">movq</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">stack_limit</span><span class=\"p\">),</span><span class=\"w\"> </span><span class=\"o\">%</span><span class=\"mi\">64_</span><span class=\"n\">bit_scratch</span><span class=\"w\"></span>\n<span class=\"n\">sub</span><span class=\"w\"> </span><span class=\"cp\">$stack_limit</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"o\">%</span><span class=\"mi\">64_</span><span class=\"n\">bit_scratch</span><span class=\"w\"></span>\n<span class=\"n\">jns</span><span class=\"w\"> </span><span class=\"n\">ok</span><span class=\"w\"></span>\n<span class=\"n\">ud2</span><span class=\"w\"></span>\n<span class=\"n\">ok</span>:\n<span class=\"nc\">movl</span><span class=\"w\"> </span><span class=\"o\">%</span><span class=\"mi\">64_</span><span class=\"n\">bit_scratch</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">stack_limit</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"></span>\n</code></pre></div>\n<p>where the idea is that we load 64-bits but only store 32-bits. That way the upper 32-bits can in theory be atomically modified since we're only updating the lower 32-bits on each frame. This would also cap native stack sizes for wasm at 4G, but that seems pretty reasonable.</p>\n<p>Is that a workable instruction sequence, though? That seems wonky to load both with one 64-bit load and expect that we'll just happen to see remote updates of the upper 32-bits, but I think that at least for x86 it should work?</p>\n</blockquote>",
        "id": 215392407,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604359154
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720788459\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>That's a clever solution! I think that should work, but (<em>puts on computer-architect hat</em>) I think the performance might not be great on modern out-of-order machines...</p>\n<p>... specifically, we have to worry about partial-store stalls in the load/store queue. In particular, if we have one of these sequences in each prologue, and we have call-heavy code, we could have a number of prologues in-flight in the instruction window; each of the 64-bit loads will stall (probably until the store retires?) because the half-forward, half-not-forward case is generally not in the happy path.</p>\n<p>I think we can actually just have a separate interrupt-flag and do the two checks in four instructions, i.e. no more expensive that the second sequence above:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">  </span><span class=\"n\">subq</span><span class=\"w\"> </span><span class=\"cp\">$imm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">stack_limit_field</span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">vmctx</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">js</span><span class=\"w\"> </span><span class=\"n\">bad</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">cmp</span><span class=\"w\"> </span><span class=\"cp\">$</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">interrupt_field</span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">vmctx</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">jne</span><span class=\"w\"> </span><span class=\"n\">bad</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"></span>\n\n<span class=\"n\">bad</span>:\n  <span class=\"nc\">ud2</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(I think it is probably better to put the <code>ud2</code> at the end of the function as well -- it's cold, so we don't want to burn icache space, and it'll be absorbed into alignment padding with 15/16 probability anyway)</p>\n<p>Thoughts?</p>\n</blockquote>",
        "id": 215394289,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604360572
    },
    {
        "content": "<p>cfallin edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720788459\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>That's a clever solution! I think that should work, but (<em>puts on computer-architect hat</em>) I think the performance might not be great on modern out-of-order machines...</p>\n<p>... specifically, we have to worry about partial-store stalls in the load/store queue. In particular, if we have one of these sequences in each prologue, and we have call-heavy code, we could have a number of prologues in-flight in the instruction window; each of the 64-bit loads will stall (probably until the store retires?) because the half-forward, half-not-forward case is generally not in the happy path.</p>\n<p>I think we can actually just have a separate interrupt-flag and do the two checks in four instructions, i.e. no more expensive than the second sequence above:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">  </span><span class=\"n\">subq</span><span class=\"w\"> </span><span class=\"cp\">$imm</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">stack_limit_field</span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">vmctx</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">js</span><span class=\"w\"> </span><span class=\"n\">bad</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">cmp</span><span class=\"w\"> </span><span class=\"cp\">$</span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">interrupt_field</span><span class=\"p\">(</span><span class=\"o\">%</span><span class=\"n\">vmctx</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">jne</span><span class=\"w\"> </span><span class=\"n\">bad</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"></span>\n\n<span class=\"n\">bad</span>:\n  <span class=\"nc\">ud2</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(I think it is probably better to put the <code>ud2</code> at the end of the function as well -- it's cold, so we don't want to burn icache space, and it'll be absorbed into alignment padding with 15/16 probability anyway)</p>\n<p>Thoughts?</p>\n</blockquote>",
        "id": 215394627,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604360827
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-720809777\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Ok this took <em>way</em> too long to dawn on me, but it turns out if you subtract at the start you also need to add back in the allocation at the end. This means that if we want to have a dynamically updated stack limit we need to instrument all exits from the function as well as the prologue.</p>\n<p>That I think places this strategy into a realm of \"maybe not as feasible as originally though\" and makes me lean towards option 2 above where we just implement a way to get the real and actual stack pointer.</p>\n</blockquote>",
        "id": 215399381,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604364659
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344#issuecomment-721799954\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Ok I've just gone ahead and made a small patch to use <code>psm</code> at <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2358\">https://github.com/bytecodealliance/wasmtime/pull/2358</a></p>\n</blockquote>",
        "id": 215596491,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604503741
    },
    {
        "content": "<p>yurydelendik closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2344\">Issue #2344</a>:</p>\n<blockquote>\n<p>Recently we've received a number of fuzz bugs all about stack overflows in native code. Each fuzz bug has a module which contains an infinitely recursive set of functions when instantiated/called, and the stack overflow happens in the native code of Wasmtime, and the exact native code changes depending on what the module is doing. This situation is supposed to be mitigated by limiting the amount of stack space wasm is allowed to take. After some investigation, however, this limiting isn't happening. </p>\n<p>When ASan is run with <code>ASAN_OPTIONS=\"detect_stack_use_after_return=1\"</code> then it allocates a \"shadow stack\" for each function frame. This means that <a href=\"https://github.com/bytecodealliance/wasmtime/blob/44cbdecea03c360ea82e6482f0cf6c614effef21/crates/runtime/src/traphandlers.rs#L504\">our guess of what the stack pointer is</a> is actually pointing into the shadow stack area instead of the real native stack. This means that we install a stack limit very far away from the actual stack  itself, rendering the stack limit useless since stack overflow is hit long before we get to the shadow stack.</p>\n<p>To be clear I don't think this is necessarily a but in Wasmtime, this only comes up with fuzzing under AddressSanitizer. That being said that fuzz mode is very important and we don't want to lose that! I think there's a few possible fixes we could do in this situation:</p>\n<ol>\n<li>Disable fuzzing with <code>detect_stack_use_after_return</code>. From what I can tell I think this is for having better error reports, and it may not be that critical for Wasmtime, especially with how rare use-after-return is in Rust. That being said I would prefer to take this route as a last resort.</li>\n<li>Fix our \"educated guess\" about what the stack pointer is. This would probably involve us compiling an asm stub which only says <code>mov %rsp, %rax; ret</code> or something like that. This I think should work since it won't be instrumented by ASan and point into the shadow stack. It's a bummer to maintain custom assembly, however.</li>\n<li>Refactor how we account for native stack space in wasm modules. Right now this is a <code>usize</code> where if <code>%rsp</code> is ever beneath it we trap. Instead we could change it to a <code>usize</code> of \"you have this many bytes left\" where each function subtracts and traps on overflow. Additionally, interrupts, which use this same flag, would simply set the remaining bytes to a negative number so the next comparison traps.</li>\n</ol>\n<p>I would personally lean towards the third option since I think it also reflects more accurately how much stack space wasm can use. It means we don't ever need the stack pointer itself in native code and interleaving small wasm stacks with larger native stacks will actually work, where it doesn't work today since wasm isn't allowed to go beyond the maximum stack size of the first wasm module on the stack.</p>\n<p>I'm curious what others think though!</p>\n</blockquote>",
        "id": 215710732,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1604582945
    }
]