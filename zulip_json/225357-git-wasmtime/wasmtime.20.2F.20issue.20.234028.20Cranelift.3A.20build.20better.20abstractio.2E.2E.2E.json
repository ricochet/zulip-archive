[
    {
        "content": "<p>cfallin opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>In the VCode container, we've stumbled into a fairly handy data structure design idiom, like so:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">    </span><span class=\"sd\">/// Operands: pre-regalloc references to virtual registers with</span>\n<span class=\"w\">    </span><span class=\"sd\">/// constraints, in one flattened array. This allows the regalloc</span>\n<span class=\"w\">    </span><span class=\"sd\">/// to efficiently access all operands without requiring expensive</span>\n<span class=\"w\">    </span><span class=\"sd\">/// matches or method invocations on insts.</span>\n<span class=\"w\">    </span><span class=\"n\">operands</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"n\">Operand</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n\n<span class=\"w\">    </span><span class=\"sd\">/// Operand index ranges: for each instruction in `insts`, there</span>\n<span class=\"w\">    </span><span class=\"sd\">/// is a tuple here providing the range in `operands` for that</span>\n<span class=\"w\">    </span><span class=\"sd\">/// instruction's operands.</span>\n<span class=\"w\">    </span><span class=\"n\">operand_ranges</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"p\">(</span><span class=\"kt\">u32</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"p\">)</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"sd\">/// Operands: pre-regalloc references to virtual registers with</span>\n<span class=\"w\">    </span><span class=\"sd\">/// constraints, in one flattened array. This allows the regalloc</span>\n<span class=\"w\">    </span><span class=\"sd\">/// to efficiently access all operands without requiring expensive</span>\n<span class=\"w\">    </span><span class=\"sd\">/// matches or method invocations on insts.</span>\n<span class=\"w\">    </span><span class=\"n\">operands</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"n\">Operand</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n\n<span class=\"w\">    </span><span class=\"sd\">/// Operand index ranges: for each instruction in `insts`, there</span>\n<span class=\"w\">    </span><span class=\"sd\">/// is a tuple here providing the range in `operands` for that</span>\n<span class=\"w\">    </span><span class=\"sd\">/// instruction's operands.</span>\n<span class=\"w\">    </span><span class=\"n\">operand_ranges</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"p\">(</span><span class=\"kt\">u32</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"p\">)</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n</code></pre></div>\n<p>which lets us aggregate allocation overhead into fewer, larger <code>Vec</code>s rather than a bunch of little ones when we have a conceptually-2D (or N-D) array. This pattern can be extended further, for example for outgoing block args, which are 3D (per block, per successor, we have a list): we do this with a rangelist that gives a range in another rangelist that gives ranges in a pooled sequence.</p>\n<p>We manage this manually, and even combine the pooled <code>Vec</code> when we can for more goodness. It would be nice to make this less error-prone by wrapping it up in a typesafe wrapper:</p>\n<ul>\n<li>A core struct that owns the pool (the <code>operands</code> above);</li>\n<li>A means of composing types to add one or more range-lists on top of that pool;</li>\n<li>A handle type that temporarily takes ownership, allows appending, and adds a rangelist entry when done, to enforce that sequences must be contiguous in the pooled sequence.</li>\n</ul>\n<p>Doing this while allowing pool-sharing will take a little thought, but if we can find a way to do it, it could allow us to reduce allocations further.</p>\n</blockquote>",
        "id": 278910986,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1649898066
    },
    {
        "content": "<p>cfallin edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>In the VCode container, we've stumbled into a fairly handy data structure design idiom, like so:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">    </span><span class=\"sd\">/// Operands: pre-regalloc references to virtual registers with</span>\n<span class=\"w\">    </span><span class=\"sd\">/// constraints, in one flattened array. This allows the regalloc</span>\n<span class=\"w\">    </span><span class=\"sd\">/// to efficiently access all operands without requiring expensive</span>\n<span class=\"w\">    </span><span class=\"sd\">/// matches or method invocations on insts.</span>\n<span class=\"w\">    </span><span class=\"n\">operands</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"n\">Operand</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n\n<span class=\"w\">    </span><span class=\"sd\">/// Operand index ranges: for each instruction in `insts`, there</span>\n<span class=\"w\">    </span><span class=\"sd\">/// is a tuple here providing the range in `operands` for that</span>\n<span class=\"w\">    </span><span class=\"sd\">/// instruction's operands.</span>\n<span class=\"w\">    </span><span class=\"n\">operand_ranges</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"p\">(</span><span class=\"kt\">u32</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"p\">)</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n</code></pre></div>\n<p>which lets us aggregate allocation overhead into fewer, larger <code>Vec</code>s rather than a bunch of little ones when we have a conceptually-2D (or N-D) array. This pattern can be extended further, for example for outgoing block args, which are 3D (per block, per successor, we have a list): we do this with a rangelist that gives a range in another rangelist that gives ranges in a pooled sequence.</p>\n<p>We manage this manually, and even combine the pooled <code>Vec</code> when we can for more goodness. It would be nice to make this less error-prone by wrapping it up in a typesafe wrapper:</p>\n<ul>\n<li>A core struct that owns the pool (the <code>operands</code> above);</li>\n<li>A means of composing types to add one or more range-lists on top of that pool;</li>\n<li>A handle type that temporarily takes ownership, allows appending, and adds a rangelist entry when done, to enforce that sequences must be contiguous in the pooled sequence.</li>\n</ul>\n<p>Doing this while allowing pool-sharing will take a little thought, but if we can find a way to do it, it could allow us to reduce allocations further.</p>\n</blockquote>",
        "id": 278911605,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1649898588
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1098915565\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>Isn't this just <code>cranelift_entity::EntityList</code>?</p>\n</blockquote>",
        "id": 278941754,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1649928069
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1099390715\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>Also basically a poor person's bump allocator, but instead of handing out references, hands out indices.</p>\n</blockquote>",
        "id": 278990169,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1649954608
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1099393241\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>@bjorn3 -- not quite, though they are in the same area: <code>EntityList</code> has alloc/realloc/free and appears to keep metadata in the array as well (length of each individual list), and is specifically a list of indices, rather than <code>T</code>.</p>\n<p>Indeed this is a bump allocator! I guess the special twist is that it has a secondary list-of-ranges and so the abstraction is \"list of lists\" rather than \"list of arbitrary objects\". It'd be great to have a wrapper that lets us do the same things we do in VCode now (build each sublist one element at a time, demarcate the end of a list and get a range).</p>\n</blockquote>",
        "id": 278990595,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1649954803
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>In the VCode container, we've stumbled into a fairly handy data structure design idiom, like so:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">    </span><span class=\"sd\">/// Operands: pre-regalloc references to virtual registers with</span>\n<span class=\"w\">    </span><span class=\"sd\">/// constraints, in one flattened array. This allows the regalloc</span>\n<span class=\"w\">    </span><span class=\"sd\">/// to efficiently access all operands without requiring expensive</span>\n<span class=\"w\">    </span><span class=\"sd\">/// matches or method invocations on insts.</span>\n<span class=\"w\">    </span><span class=\"n\">operands</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"n\">Operand</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n\n<span class=\"w\">    </span><span class=\"sd\">/// Operand index ranges: for each instruction in `insts`, there</span>\n<span class=\"w\">    </span><span class=\"sd\">/// is a tuple here providing the range in `operands` for that</span>\n<span class=\"w\">    </span><span class=\"sd\">/// instruction's operands.</span>\n<span class=\"w\">    </span><span class=\"n\">operand_ranges</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"p\">(</span><span class=\"kt\">u32</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"p\">)</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n</code></pre></div>\n<p>which lets us aggregate allocation overhead into fewer, larger <code>Vec</code>s rather than a bunch of little ones when we have a conceptually-2D (or N-D) array. This pattern can be extended further, for example for outgoing block args, which are 3D (per block, per successor, we have a list): we do this with a rangelist that gives a range in another rangelist that gives ranges in a pooled sequence.</p>\n<p>We manage this manually, and even combine the pooled <code>Vec</code> when we can for more goodness. It would be nice to make this less error-prone by wrapping it up in a typesafe wrapper:</p>\n<ul>\n<li>A core struct that owns the pool (the <code>operands</code> above);</li>\n<li>A means of composing types to add one or more range-lists on top of that pool;</li>\n<li>A handle type that temporarily takes ownership, allows appending, and adds a rangelist entry when done, to enforce that sequences must be contiguous in the pooled sequence.</li>\n</ul>\n<p>Doing this while allowing pool-sharing will take a little thought, but if we can find a way to do it, it could allow us to reduce allocations further.</p>\n</blockquote>",
        "id": 281810173,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652182354
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>In the VCode container, we've stumbled into a fairly handy data structure design idiom, like so:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">    </span><span class=\"sd\">/// Operands: pre-regalloc references to virtual registers with</span>\n<span class=\"w\">    </span><span class=\"sd\">/// constraints, in one flattened array. This allows the regalloc</span>\n<span class=\"w\">    </span><span class=\"sd\">/// to efficiently access all operands without requiring expensive</span>\n<span class=\"w\">    </span><span class=\"sd\">/// matches or method invocations on insts.</span>\n<span class=\"w\">    </span><span class=\"n\">operands</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"n\">Operand</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n\n<span class=\"w\">    </span><span class=\"sd\">/// Operand index ranges: for each instruction in `insts`, there</span>\n<span class=\"w\">    </span><span class=\"sd\">/// is a tuple here providing the range in `operands` for that</span>\n<span class=\"w\">    </span><span class=\"sd\">/// instruction's operands.</span>\n<span class=\"w\">    </span><span class=\"n\">operand_ranges</span>: <span class=\"nb\">Vec</span><span class=\"o\">&lt;</span><span class=\"p\">(</span><span class=\"kt\">u32</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"p\">)</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n</code></pre></div>\n<p>which lets us aggregate allocation overhead into fewer, larger <code>Vec</code>s rather than a bunch of little ones when we have a conceptually-2D (or N-D) array. This pattern can be extended further, for example for outgoing block args, which are 3D (per block, per successor, we have a list): we do this with a rangelist that gives a range in another rangelist that gives ranges in a pooled sequence.</p>\n<p>We manage this manually, and even combine the pooled <code>Vec</code> when we can for more goodness. It would be nice to make this less error-prone by wrapping it up in a typesafe wrapper:</p>\n<ul>\n<li>A core struct that owns the pool (the <code>operands</code> above);</li>\n<li>A means of composing types to add one or more range-lists on top of that pool;</li>\n<li>A handle type that temporarily takes ownership, allows appending, and adds a rangelist entry when done, to enforce that sequences must be contiguous in the pooled sequence.</li>\n</ul>\n<p>Doing this while allowing pool-sharing will take a little thought, but if we can find a way to do it, it could allow us to reduce allocations further.</p>\n</blockquote>",
        "id": 281810475,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652182567
    },
    {
        "content": "<p>jakubDoka <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1122781523\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>@cfallin you don't need <code>Vec&lt;(u32, u32)&gt;</code> but just <code>Vec&lt;u32&gt;</code>, where you start with <code>vec![0]</code> and always push the length of <code>operands</code> after allocating new list. Then when you need to get a slice, ask for <code>EntityRef</code> and get star and and like <code>(k.index(), k.index() + 1)</code>.</p>\n</blockquote>",
        "id": 281874380,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652210989
    },
    {
        "content": "<p>jakubDoka edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1122781523\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>@cfallin you don't need <code>Vec&lt;(u32, u32)&gt;</code> but just <code>Vec&lt;u32&gt;</code>, where you start with <code>vec![0]</code> and always push the length of <code>operands</code> after allocating new list. Then when you need to get a slice, ask for <code>EntityRef</code> and get (start, end) like <code>(k.index(), k.index() + 1)</code>.</p>\n</blockquote>",
        "id": 281874516,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652211032
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1122857990\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>@jakubDoka unfortunately this technique doesn't work if the instructions are reordered in any way: for example in the <code>VCode</code> we emit bottom-to-top (to allow us to pattern-match up the operand trees) and then reverse at the end. In general the order of list contents in the backing pool may not match the order of lists so we can't rely on \"my end is next list's start\" as an invariant.</p>\n</blockquote>",
        "id": 281886145,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652216649
    },
    {
        "content": "<p>jakubDoka <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028#issuecomment-1123196776\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4028\">issue #4028</a>:</p>\n<blockquote>\n<p>@cfallin I see. Well I guess these are two different data-structures, each having it's onw advantages.<br>\n</p>\n</blockquote>",
        "id": 281919903,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1652246330
    }
]