[
    {
        "content": "<p>MaxGraey opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x84/x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register size. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217569265,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606078278
    },
    {
        "content": "<p>MaxGraey edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x84/x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register size. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217569326,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606078351
    },
    {
        "content": "<p>MaxGraey edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x84/x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register size. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217569971,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606079151
    },
    {
        "content": "<p>MaxGraey edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register size. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217569973,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606079159
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731861663\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Hi @MaxGraey, thanks for bringing this up!</p>\n<p>From an instruction-selector perspective, this would certainly be possible, though in general I want to be careful about adding complexity without evidence that it will bring benefit in some way. (It's perhaps possible for one case, but if the isel starts growing conditionals for microarchitecture and for optimized cases everywhere, it soon becomes unmaintainable if we don't have a framework for reasoning about machine costs in a more principled way.) Have you seen workloads where division latency in particular became a bottleneck?</p>\n</blockquote>",
        "id": 217574845,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606085921
    },
    {
        "content": "<p>MaxGraey <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731864704\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<blockquote>\n<p>Have you seen workloads where division latency in particular became a bottleneck?</p>\n</blockquote>\n<p>Div / Rem usually most expensive operations. There are many possibilities to reduce cost of this operations, most often this is done before instruction scheduling. But there is usually very little opportunity to speed up the most general case. In this case, I think this is interesting approach which shouldn't be too complex.</p>\n</blockquote>",
        "id": 217575864,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606087336
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731864704\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<blockquote>\n<p>Have you seen workloads where division latency in particular became a bottleneck?</p>\n</blockquote>\n<p>Div / Rem usually most expensive operations. There are many possibilities to reduce cost of this operations, most often this is done before instruction scheduling. But there is usually very little opportunity to speed up the most general case. In this case, I think this is interesting approach which shouldn't be too complex in term of implementation.</p>\n</blockquote>",
        "id": 217575868,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606087354
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731868843\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Indeed, I agree that division is an expensive instruction! What I'm wondering is whether workloads exist where (i) the presence of divide instructions is a bottleneck, i.e., the latency is not hidden by other operations and is a visible portion of total runtime, and (ii) the workload uses 64-bit divides but values always have zeroed top-32-bits.</p>\n<p>That data would show the benefit; the cost, in turn is (i) an additional comparison (logical-or, right-shift, branch-if-zero, so three instructions) in every divide's main code path, (ii) additional code size due to the comparison and the fastpath, (iii) complexity in isel, which imposes maintenance burden and a small compile time increase.</p>\n<p>So, basically, I have a better handle on what the cost would be and I'm curious if we have any data points on the potential benefit. I'm hesitant to include something like this, because of the above downsides, but evidence of real upside could convince me :-)</p>\n</blockquote>",
        "id": 217577175,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606089280
    },
    {
        "content": "<p>MaxGraey <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731890182\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Oh, so you ask about real scenarios which could potentially benefit from this?</p>\n<p>I guess all range of modern cryptography which based on modular arithmetic with small primes. For example 64-bit integer modulo intensively used in Montgomery reduction for example in <code>modPow</code> (x1 ^ x2 mod m) part. I guess @jedisct1 could tell much more than me. Another potential user case is multi-precision float points and integers.</p>\n</blockquote>",
        "id": 217581988,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606096448
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731890182\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Oh, so you ask about real scenarios which could potentially benefit from this?</p>\n<p>I guess all range of modern cryptography which based on modular arithmetic with small primes. For example 64-bit integer modulo intensively used in Montgomery reduction for example in <code>modPow</code> (x1 ^ x2 mod m) part. I guess @jedisct1 could tell much more than me. Another potential user case is multi-precision float points and integers which also use modular arithmetic</p>\n</blockquote>",
        "id": 217582008,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606096499
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731897364\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Fair enough -- I think that we could investigate further. I'm still worried about the impact of the three additional instructions for every divide; so I'd want us to collect data on various numeric benchmarks (compression and media codecs come to mind) to make sure this impact isn't an issue. The benchmarking situation is looking to improve soon (<a href=\"https://github.com/bytecodealliance/rfcs/issues/4\">bytecodealliance/rfcs#4</a>) so we should be able to study this fairly easily!</p>\n<p>@MaxGraey would you be willing to prototype it?</p>\n</blockquote>",
        "id": 217583570,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606098786
    },
    {
        "content": "<p>MaxGraey <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this was implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys at LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transsformation</a>.</p>\n</blockquote>",
        "id": 217583844,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099205
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys from LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transsformation</a>.</p>\n</blockquote>",
        "id": 217583850,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099233
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys from LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transsformation</a>.</p>\n<blockquote>\n<p>The benchmarking situation is looking to improve soon</p>\n</blockquote>\n<p>Nice!</p>\n<blockquote>\n<p>@MaxGraey would you be willing to prototype it?</p>\n</blockquote>\n<p>Thanks for the suggestions, but I think this is a bit tricky case for me)</p>\n</blockquote>",
        "id": 217583947,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099424
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys from LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transsformation</a>.</p>\n<blockquote>\n<p>The benchmarking situation is looking to improve soon</p>\n</blockquote>\n<p>Nice!</p>\n<blockquote>\n<p>@MaxGraey would you be willing to prototype it?</p>\n</blockquote>\n<p>Thanks for the suggestions, but I think this is a bit tricky and low-level case for me) </p>\n</blockquote>",
        "id": 217583990,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099445
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys from LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transformation</a>.</p>\n<blockquote>\n<p>The benchmarking situation is looking to improve soon</p>\n</blockquote>\n<p>Nice!</p>\n<blockquote>\n<p>@MaxGraey would you be willing to prototype it?</p>\n</blockquote>\n<p>Thanks for the suggestions, but I think this is a bit tricky and low-level case for me) </p>\n</blockquote>",
        "id": 217583997,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099465
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731901163\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>Thanks for the link to the LLVM transform!</p>\n<p>Re: overhead, one option would be to add a flag to our CPU-specific backend flags to enable this; then the embedder could enable on platforms where this helps.</p>\n<p>I'll see if I can get to this at some point (lots of things on my plate at the moment) but anyone feel free to try this in the meantime!</p>\n</blockquote>",
        "id": 217584303,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606099954
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731960934\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>As an example where division jad disproportionate effects: <a href=\"https://github.com/gimli-rs/gimli/pull/476\">https://github.com/gimli-rs/gimli/pull/476</a> made line debuginfo generation twice as fast by avoiding a division in the common case.</p>\n</blockquote>",
        "id": 217593522,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606113840
    },
    {
        "content": "<p>bjorn3 edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731960934\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>As an example where division had disproportionate effects: <a href=\"https://github.com/gimli-rs/gimli/pull/476\">https://github.com/gimli-rs/gimli/pull/476</a> made line debuginfo generation twice as fast by avoiding a division in the common case.</p>\n</blockquote>",
        "id": 217593589,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606113931
    },
    {
        "content": "<p>MaxGraey edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439#issuecomment-731898847\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<p>historically, this was implemented exclusively for Intel Atom back in 2013, but later it is already used even for generic x64. I think the guys from LLVM have learned pretty well the specifics of this <a href=\"https://github.com/llvm/llvm-project/blob/master/llvm/lib/Transforms/Utils/BypassSlowDivision.cpp\">BypassSlowDivision transformation</a>.</p>\n<blockquote>\n<p>The benchmarking situation is looking to improve soon</p>\n</blockquote>\n<p>Nice!</p>\n<blockquote>\n<p>@MaxGraey would you be willing to prototype it?</p>\n</blockquote>\n<p>Thanks for the suggestions, but I think this is a bit tricky and low-level case for me) </p>\n</blockquote>",
        "id": 217623684,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606135942
    },
    {
        "content": "<p>MaxGraey edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register width. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217624337,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606136347
    },
    {
        "content": "<p>MaxGraey edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register's width. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 217624355,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1606136357
    },
    {
        "content": "<p>bnjbvr labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register's width. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 224204191,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611763725
    },
    {
        "content": "<p>bnjbvr labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register's width. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 224204193,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611763725
    },
    {
        "content": "<p>bnjbvr labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/2439\">Issue #2439</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>Latency and RCP for division depends on register sizes for most of x64 architectures. So Clang do one interesting trick which may speedup 64-bit division if high parts of operands equal to zero. Pseudocode:</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"n\">idiv</span><span class=\"p\">(</span><span class=\"nl\">a</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">,</span> <span class=\"nl\">b</span><span class=\"p\">:</span> <span class=\"n\">i64</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">i64</span> <span class=\"p\">{</span>\n  <span class=\"k\">if</span> <span class=\"p\">((</span><span class=\"n\">a</span> <span class=\"o\">|</span> <span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"o\">&gt;&gt;</span> <span class=\"mi\">32</span><span class=\"p\">)</span> <span class=\"k\">return</span> <span class=\"n\">a</span> <span class=\"o\">/</span> <span class=\"n\">b</span><span class=\"p\">;</span> <span class=\"c1\">// full 64-bit division</span>\n  <span class=\"k\">return</span> <span class=\"nf\">i32</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">)</span> <span class=\"o\">/</span> <span class=\"n\">i32</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">)</span> <span class=\"n\">as</span> <span class=\"n\">i64</span><span class=\"p\">;</span> <span class=\"c1\">// 32-bit division</span>\n<span class=\"p\">}</span>\n</code></pre></div>\n<p>godbolt: <a href=\"https://godbolt.org/z/Tqqzs1\">https://godbolt.org/z/Tqqzs1</a></p>\n<p>Is it make sense apply same optimization for cranelift only for x64 architecture?</p>\n<h4>Benefit</h4>\n<p>it may speedup div / rem over 2x for arguments without high parts with small constant overhead according to this table:<br>\n&lt;img width=\"525\" alt=\"comparision\" src=\"<a href=\"https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png\">https://user-images.githubusercontent.com/1301959/99916476-0cf5dc80-2d13-11eb-9ffe-7dcfd04eab8e.png</a>\"&gt;</p>\n<p>But it is worth excluding <strong>Zen1,2,3</strong> architecture due to it uses a more modern scheme for division which doesn't dependent on register's width. Also it doesn't need for ARM.</p>\n</blockquote>",
        "id": 224204194,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611763725
    }
]