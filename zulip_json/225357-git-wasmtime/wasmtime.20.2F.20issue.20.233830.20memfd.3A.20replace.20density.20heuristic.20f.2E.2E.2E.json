[
    {
        "content": "<p>cfallin opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>In #3815, we saw a case where a fuzzer came up with a Wasm heap consisting of (i) a byte at address 0, and (ii) a byte at address 1 GiB. With memfd enabled, this produces a <code>.cwasm</code> with a data segment, ready to mmap, that takes a full 1GiB.</p>\n<p>We probably don't want that, so in #3819 we added some heuristics based on \"density\" of the data segments: if less than half the bytes are set, then the image is sparse and we don't do memfd.</p>\n<p>Unfortunately this creates a really subtle performance cliff: if the user's toolchain happens to produce a Wasm with more than 50% of its bytes in its heap zero, it will slow down the whole instantiation significantly (often pushing from microsecond to millisecond range). This is unfortunate both because it's a cliff and because it affects <em>all</em> memory contents, not just those that exceed e.g. some bound. (In other words it's a \"non-graduated\" penalty: adding just one more thing penalizes all of the things, instead of just the new thing.)</p>\n<p>I was able to get close to the 50% limit with a \"real\" Wasm toolchain (specifically, one based on Wizer and SpiderMonkey that produces wasm binaries for services).</p>\n<p>An alternative proposed in #3815 was a simpler static limit: all data segments below some bound go into a memfd image, and those above some bound go into a list of segments to eagerly initialize on instantiation. This was rejected because it is also a cliff, but IMHO a static limit is easier to understand than a ratio, and can often also be aligned to other limits in the system (e.g. if a platform already bounds the maximum module or heap size, then it can set the memfd-image limit  to that size and get a guarantee that it will never see the slow case).</p>\n<p>In addition, we could perhaps generate the memfd image for all data segments that <em>are</em> within a limit, then only keep a sparse list of those that are out of bound. This bounds our image size to O(kMaxDenseSize) + O(|wasm|), and importantly, gives a \"graduated\" cost: if the module grows to slightly exceed the limit someday, then the new bytes cost more, but the whole thing doesn't get 100x slower to instantiate.</p>\n<p>cc @alexcrichton </p>\n</blockquote>",
        "id": 272356456,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645155131
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830#issuecomment-1043983446\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>Here's a proof-of-concept of the issue: I produced <a href=\"http://cfallin.org/assets/sparse-spidermonkey-wizened.wasm\">this Wasm module</a> by Wizening a SpiderMonkey-based JS project that includes a markdown renderer and does some pre-rendering at the toplevel (which runs at wizening time), and simulates some more init-time alloc/free by allocating a large array. (I played with the sizes until it got just past the threshold, for full disclosure, which is why this is \"suspiciously close\", but the point I was trying to convince myself of was that this is indeed possible to hit.) <a href=\"https://github.com/cfallin/sparse-wasm-module\">Source is here</a>.</p>\n<p>I observe the following stats:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"p\">[</span><span class=\"n\">crates</span><span class=\"o\">/</span><span class=\"n\">environ</span><span class=\"o\">/</span><span class=\"n\">src</span><span class=\"o\">/</span><span class=\"n\">module</span><span class=\"p\">.</span><span class=\"n\">rs</span>:<span class=\"mi\">372</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"n\">memory_init_size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">11993088</span><span class=\"w\"></span>\n<span class=\"p\">[</span><span class=\"n\">crates</span><span class=\"o\">/</span><span class=\"n\">environ</span><span class=\"o\">/</span><span class=\"n\">src</span><span class=\"o\">/</span><span class=\"n\">module</span><span class=\"p\">.</span><span class=\"n\">rs</span>:<span class=\"mi\">372</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"n\">data_size</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"mi\">5963776</span><span class=\"w\"></span>\n</code></pre></div>\n<p>which is just under the 50%-dense threshold, so this module would fail to use memfd with the new heuristics.</p>\n</blockquote>",
        "id": 272364560,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645165394
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830#issuecomment-1047930787\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>cc <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3831\">https://github.com/bytecodealliance/wasmtime/pull/3831</a> to have the link here</p>\n<p>I'm all for a fancier mmap scheme where we either have mmap+leftovers or something a bit fancier like up to N mmap images plus leftovers. I'm not sure off the top of my head how we'd determine what's appropriate for what module but I'm all for making this a more intelligent decision in Wasmtime.</p>\n</blockquote>",
        "id": 272821133,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645544739
    },
    {
        "content": "<p>alexcrichton labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>In #3815, we saw a case where a fuzzer came up with a Wasm heap consisting of (i) a byte at address 0, and (ii) a byte at address 1 GiB. With memfd enabled, this produces a <code>.cwasm</code> with a data segment, ready to mmap, that takes a full 1GiB.</p>\n<p>We probably don't want that, so in #3819 we added some heuristics based on \"density\" of the data segments: if less than half the bytes are set, then the image is sparse and we don't do memfd.</p>\n<p>Unfortunately this creates a really subtle performance cliff: if the user's toolchain happens to produce a Wasm with more than 50% of its bytes in its heap zero, it will slow down the whole instantiation significantly (often pushing from microsecond to millisecond range). This is unfortunate both because it's a cliff and because it affects <em>all</em> memory contents, not just those that exceed e.g. some bound. (In other words it's a \"non-graduated\" penalty: adding just one more thing penalizes all of the things, instead of just the new thing.)</p>\n<p>I was able to get close to the 50% limit with a \"real\" Wasm toolchain (specifically, one based on Wizer and SpiderMonkey that produces wasm binaries for services).</p>\n<p>An alternative proposed in #3815 was a simpler static limit: all data segments below some bound go into a memfd image, and those above some bound go into a list of segments to eagerly initialize on instantiation. This was rejected because it is also a cliff, but IMHO a static limit is easier to understand than a ratio, and can often also be aligned to other limits in the system (e.g. if a platform already bounds the maximum module or heap size, then it can set the memfd-image limit  to that size and get a guarantee that it will never see the slow case).</p>\n<p>In addition, we could perhaps generate the memfd image for all data segments that <em>are</em> within a limit, then only keep a sparse list of those that are out of bound. This bounds our image size to O(kMaxDenseSize) + O(|wasm|), and importantly, gives a \"graduated\" cost: if the module grows to slightly exceed the limit someday, then the new bytes cost more, but the whole thing doesn't get 100x slower to instantiate.</p>\n<p>cc @alexcrichton </p>\n</blockquote>",
        "id": 276393183,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1648066392
    },
    {
        "content": "<p>alexcrichton closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>In #3815, we saw a case where a fuzzer came up with a Wasm heap consisting of (i) a byte at address 0, and (ii) a byte at address 1 GiB. With memfd enabled, this produces a <code>.cwasm</code> with a data segment, ready to mmap, that takes a full 1GiB.</p>\n<p>We probably don't want that, so in #3819 we added some heuristics based on \"density\" of the data segments: if less than half the bytes are set, then the image is sparse and we don't do memfd.</p>\n<p>Unfortunately this creates a really subtle performance cliff: if the user's toolchain happens to produce a Wasm with more than 50% of its bytes in its heap zero, it will slow down the whole instantiation significantly (often pushing from microsecond to millisecond range). This is unfortunate both because it's a cliff and because it affects <em>all</em> memory contents, not just those that exceed e.g. some bound. (In other words it's a \"non-graduated\" penalty: adding just one more thing penalizes all of the things, instead of just the new thing.)</p>\n<p>I was able to get close to the 50% limit with a \"real\" Wasm toolchain (specifically, one based on Wizer and SpiderMonkey that produces wasm binaries for services).</p>\n<p>An alternative proposed in #3815 was a simpler static limit: all data segments below some bound go into a memfd image, and those above some bound go into a list of segments to eagerly initialize on instantiation. This was rejected because it is also a cliff, but IMHO a static limit is easier to understand than a ratio, and can often also be aligned to other limits in the system (e.g. if a platform already bounds the maximum module or heap size, then it can set the memfd-image limit  to that size and get a guarantee that it will never see the slow case).</p>\n<p>In addition, we could perhaps generate the memfd image for all data segments that <em>are</em> within a limit, then only keep a sparse list of those that are out of bound. This bounds our image size to O(kMaxDenseSize) + O(|wasm|), and importantly, gives a \"graduated\" cost: if the module grows to slightly exceed the limit someday, then the new bytes cost more, but the whole thing doesn't get 100x slower to instantiate.</p>\n<p>cc @alexcrichton </p>\n</blockquote>",
        "id": 313403724,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1669939994
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830#issuecomment-1334604981\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3830\">issue #3830</a>:</p>\n<blockquote>\n<p>I think this was more-or-less done at the time and appears to have served us well in the meantime, so I'm going to close.</p>\n</blockquote>",
        "id": 313403725,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1669939994
    }
]