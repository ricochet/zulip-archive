[
    {
        "content": "<p>uweigand opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Currently, <code>s390x</code> is the only big-endian platform supported by cranelift, which has already caused problems related to memory accesses in the past, since wasmtime defines all data in its memory to be in little-endian byte order.</p>\n<p>I had assumed that <em>register</em> contents are not affected by byte order, and while this is true for scalar types, it turns out this is not actually the case for vector registers.  This is because of a combination of two issues:</p>\n<ol>\n<li>There are IR instructions that directly refer to vector register _lanes_ by number; and</li>\n<li>There are IR instructions to re-interpret a vector register as any other vector type, including one with different lane numbers</li>\n</ol>\n<p>The combination of these two makes ISA byte order properties of vector registers visible to IR code, just like byte order in memory is visible via a combination of using memory addresses to access (parts of) a value in memory in a different type than it was stored.</p>\n<p>Specifically, in the Intel (or ARM) little-endian ISA, if you load e.g. a <code>I32X4</code> into a vector register, use <code>raw_bitcast</code> to re-interpret that register as <code>I8X16</code>, and retrieve lane 0 of the resulting value via <code>extractlane</code>, the result will be the <em>least</em>-significant byte of the <code>I32</code> in lane 0 of the original value.   And in fact, wasmtime <em>requires</em> this to be the case.</p>\n<p>On the other hand, on <code>s390x</code> the content of a vector register in <code>I32X4</code> mode will be a sequence of four <code>I32</code>, each in <em>big-endian</em> byte order (or else the arithmetic operations on the register will give wrong results).   Therefore, the same sequence of operations as above will return the <em>most</em>-significant byte of the <code>I32</code> in lane 0.   This actually caused many wasmtime tests to fail.</p>\n<hr>\n<p>To fix this, my current implementation of SIMD instructions on <code>s390x</code> uses a trick combining two different aspects:</p>\n<ul>\n<li>When loading the <code>I32X4</code> from little-endian memory into a vector register, I'm byte-reversing all 16 bytes of the loaded value.  This not only fixes each <code>I32</code> value to be in the correct big-endian order in the register so subsequent arithmetic will work, it <em>also</em> implicitly swaps the order of elements, i.e. the element in slot 0 in memory will end up in what the ISA considers slot 3 of the register etc.</li>\n<li>The implementation of all IR instructions that uses explicit lane numbers will be aware of this renumbering, and implicitly revert it to get back to the lanes the code intends to access, so e.g. using <code>extractlane</code> for lane 0 of a <code>I32X4</code> will actually at the ISA level extract lane 3 of the register.</li>\n</ul>\n<p>The combination of these two aspects makes accessing SIMD registers work correctly for wasmtime.  For example, in the above case, accessing lane 0 of a <code>I8X16</code> is converted to lane 15 of the register, which holds the <em>least</em>-significant byte of the <code>I32</code> in lane 3 of the register, which was loaded from lane 0 in memory -- so in the end we return the least-significant byte of the <code>I32</code> in lane 0 of the original value, as expected by wasmtime.</p>\n<hr>\n<p>However, in implementing support for <code>rustc_codegen_cranelift</code>, I noticed that the current implementation actually breaks when handling <em>big-endian</em> vectors in memory - this will be the case for rustc, since that uses native platform byte order everywhere.  Specifically, when loading a big-endian vector from memory, I'm just loading the bytes unchanged.  This means that e.g. lane 0 of a <code>I32X4</code> in memory ends up in its original byte order (which is OK since this is already big-endian) in lane 0 of the register - but the latter is a problem if subsequent code wants to extract that lane, since an <code>extractlane 0</code> will actually access lane 3 in the register as described above!</p>\n<p>To work around <em>that</em> problem, I've implemented a patch that will perform big-endian vector loads by swapping the order of the <em>elements</em>, but not the byte order within any single element.  This will cause lane 0 from memory to end up in lane 3 in the register, and makes <code>extractlane</code> work as expected again.</p>\n<p>With that fix, now <em>both</em> wasmtime and rustc_codegen_cranelift pass all their existing SIMD tests.   Unfortunately, I think this is still not quite a complete solution.</p>\n<hr>\n<p>Specifically, we can now run into two additional problems with big-endian code, which apparently are just never triggered by the existing rustc_codegen_cranelift tests.</p>\n<p>First, I guess it would be possible to re-interpret contents in a vector register in another type even in rustc.   Now, as opposed to wasmtime, rustc uses native endianness, presumably also w.r.t. vector contents.   Therefore, the semantics of such a re-interpretation would be platform-defined and differ between big- and little-endian platforms (which is probably why it's not frequently used).  However, users would expect this platform-specific behavior to be the <em>same</em> between the LLVM and cranelift back ends to rustc - which in the current implementation it would not be.</p>\n<p>Even more problematic, carrying vector elements in reverse order in vector registers actually affects the <em>ABI</em>, as vector types are passed in vector registers.   Code compiled by rustc using the LLVM back end would expect those to be in the \"normal\" platform order, while code compiled by rustc using the cranelift back end would expect them to be the \"reverse\" order.</p>\n<hr>\n<p>One option I'm thinking of would be to actually implement <em>both</em> methods in the cranelift back end.  Specifically, the back end could support both a \"vector big-endian\" and \"vector little-endian\" mode, where the \"big-endian\" mode would use lane numbers directly as defined by our ISA, while the \"little-endian\" mode would use the reverse ordering implemented by the current back end code.</p>\n<p>There's a slight complication in that we might have to support both big- and little-endian vector modes in load and store operations accessing any combination of big- and little-endian memory locations.  But that should be possible:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">mode</span><span class=\"w\">      </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\">    </span><span class=\"n\">load</span><span class=\"o\">/</span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">operation</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">direct</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">element</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">elements</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"mi\">16</span><span class=\"o\">-</span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(Starting with <code>z15</code> we actually can implement each of these operations using a single instruction, so that should also be efficient.)</p>\n<p>The one remaining question is, how to select between the \"vector big-endian\" and \"vector little-endian\" modes?   There are no attributes (like <code>MemFlags</code>) on the <code>extractlane</code> etc. operations, and that wouldn't even make sense: this is a global property, if you used big-endian mode to load the vector you must also use big-endian mode on all subsequent operations.</p>\n<p>So I guess this would have to be some sort of global flag, which wasmtime would set to always little-endian, and rustc would leave at native byte order.   Of course, this flag is actually ABI changing, so the same setting must be used for code to remain link-compatible.  But I think given the above use cases, that should actually be fine.</p>\n<hr>\n<p>FYI @cfallin - this is another problem I ran into while enabling <code>rustc_codegen_cranelift</code>  - I'd appreciate any comments or suggestions!</p>\n</blockquote>",
        "id": 291494410,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659279090
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1201599311\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Thanks for writing this up and for the discussion in today's Cranelift meeting. I'm not sure yet which approach I favor, but I thought it might be useful to write out a few principles that I want to try to stick to:</p>\n<ul>\n<li>I'd prefer for all behavior to be deterministic and fully specified as CLIF semantics, independently of the target platform. This I think you're already considering above with respect to observability, which is great. In general, I want us to make endianness explicit and remove any \"native\" or \"up to the target\" options (as in the currently dormant but still valid issue #3369).</li>\n<li>I also prefer the idea that behavior is specified on <em>instructions</em> or <em>types</em> rather than as a global or per-function mode, where possible. In general if we define a value and the heap as buckets of bits we can describe big-endian and little-endian loads as operations on those bits, and then where we largely deal with little-endian data (because of Wasm) on a big-endian target (e.g. s390x), the individual operations have byte-swapping where needed.</li>\n</ul>\n<p>I had mentioned the idea of an encoding in the vector <em>types</em> in the meeting earlier today and there was some issue that you had raised but I don't remember exactly what it was; so perhaps it's worth going through it again here. The idea is to have variants <code>I32X4LE</code> and <code>I32X4BE</code> (for example), and a model that a 128-bit vector register is otherwise just an array of 16 bytes loaded directly from memory (in Wasm terms, a <code>V128</code> type).</p>\n<p>That does imply the existence of two different ops <code>iadd.i32x4le</code> and <code>iadd.i32x4be</code>, though, and I suppose the issue could be that s390x does not have an efficient single-instruction lowering for <code>iadd.i32x4le</code> (i.e., each lane is byte-swapped from its perspective)? That's likely why you had done the byte-swapping on load originally?</p>\n<p>Perhaps another approach is to eliminate the notion of bitcasting being a no-op on SIMD vectors. That seems like the other root of the issue here: the actual bit positions change if we have a forward-lane-order, reverse-byte-order-within-lane version of an <code>i32x4</code> vs. <code>i64x2</code>.</p>\n<p>Maybe combining some of the above ideas, including the types, we can capture the actual format of the data in the type and require conversions like:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">    </span><span class=\"n\">v1</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">load</span><span class=\"p\">.</span><span class=\"n\">v128</span><span class=\"w\"> </span><span class=\"n\">addr</span><span class=\"o\">+</span><span class=\"mi\">0</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">v2</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">vec_reinterpret_le</span><span class=\"p\">.</span><span class=\"n\">i32x4</span><span class=\"w\"> </span><span class=\"n\">v1</span><span class=\"w\">    </span><span class=\"p\">;;</span><span class=\"w\"> </span><span class=\"n\">this</span><span class=\"w\"> </span><span class=\"n\">converts</span><span class=\"w\"> </span><span class=\"n\">an</span><span class=\"w\"> </span><span class=\"n\">i32x4le</span><span class=\"w\"> </span><span class=\"n\">into</span><span class=\"w\"> </span><span class=\"n\">s390x</span><span class=\"o\">'</span><span class=\"na\">s</span><span class=\"w\"> </span><span class=\"n\">internal</span><span class=\"w\"> </span><span class=\"n\">representation</span>: <span class=\"nc\">BE</span><span class=\"w\"> </span><span class=\"n\">lanes</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">lane</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"err\">`</span><span class=\"n\">le</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"err\">`</span><span class=\"n\">be</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"n\">variants</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">instruction</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">controlling</span><span class=\"w\"> </span><span class=\"k\">type</span> <span class=\"nc\">determines</span><span class=\"w\"> </span><span class=\"n\">lane</span><span class=\"w\"> </span><span class=\"n\">width</span><span class=\"o\">/</span><span class=\"n\">count</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">v3</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">extractlane</span><span class=\"w\"> </span><span class=\"n\">v2</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"p\">;;</span><span class=\"w\"> </span><span class=\"n\">accesses</span><span class=\"w\"> </span><span class=\"n\">hardware</span><span class=\"w\"> </span><span class=\"n\">lane</span><span class=\"w\"> </span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">because</span><span class=\"w\"> </span><span class=\"n\">v2</span><span class=\"o\">'</span><span class=\"na\">s</span><span class=\"w\"> </span><span class=\"k\">type</span> <span class=\"nc\">is</span><span class=\"w\"> </span><span class=\"n\">i32x4</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"n\">lanes</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"n\">lanes</span><span class=\"w\"> </span><span class=\"n\">are</span><span class=\"w\"> </span><span class=\"n\">reversed</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">v4</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">iadd</span><span class=\"w\"> </span><span class=\"n\">v2</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">v2</span><span class=\"w\">   </span><span class=\"p\">;;</span><span class=\"w\"> </span><span class=\"n\">native</span><span class=\"w\"> </span><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">add</span><span class=\"w\"> </span><span class=\"n\">instruction</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\"> </span><span class=\"n\">lanes</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">v5</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">vec_reinterpret_le</span><span class=\"p\">.</span><span class=\"n\">v128</span><span class=\"w\"> </span><span class=\"n\">v4</span><span class=\"w\">  </span><span class=\"p\">;;</span><span class=\"w\"> </span><span class=\"n\">convert</span><span class=\"w\"> </span><span class=\"n\">an</span><span class=\"w\"> </span><span class=\"n\">i32x4</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">its</span><span class=\"w\"> </span><span class=\"n\">internal</span><span class=\"w\"> </span><span class=\"n\">representation</span><span class=\"w\"> </span><span class=\"n\">back</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">v128</span><span class=\"w\"> </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\"> </span><span class=\"n\">ordering</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">v5</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">addr</span><span class=\"w\"></span>\n</code></pre></div>\n<p>So this sketch includes (i) a new <code>v128</code> type whose semantics are as-if an array of 16 bytes, so it can become a native 128-bit load/store on any platform of any endianness; (ii) <code>vec_reinterpret_le</code> and <code>vec_reinterpret_be</code> (or perhaps separate opcodes for v128-to-typed and typed-to-v128) that can be no-ops or byteswaps depending on platform; and (iii) a definition of types like <code>i32x4</code> on <code>s390x</code> that the type uses your byte-swapped, lane-swapped scheme.</p>\n<p>Or a slight variation on the above: <code>i32x4</code> and <code>i32x4rev</code> types, where <code>i32x4rev</code> means lane 0,1,2,3 are in lane 3,2,1,0. Then <code>vec_reinterpret_le.i32x4rev</code> on a <code>v128</code> is a 16-byte-swap (lane-agnostic) on s390x, and is used by the Wasm frontend; and <code>vec_reinterpret_be.i32x4</code> on a <code>v128</code> is a no-op, and is used by the Rust frontend.</p>\n<p>Then finally at ABI boundaries and at loads/stores we <em>only</em> allow <code>v128</code>, and the frontends keep this in the same format (endianness and lane order) as in memory.</p>\n<p>Anyway, hopefully one of the ideas above contains a kernel of usefulness -- eager to hear what you think @uweigand.</p>\n</blockquote>",
        "id": 291619610,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659380910
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1203092309\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<p>I had mentioned the idea of an encoding in the vector types in the meeting earlier today and there was some issue that you had raised but I don't remember exactly what it was; so perhaps it's worth going through it again here</p>\n</blockquote>\n<p>I was probably momentarily confused there.   Let me try to systematically go through the various representation options to see what makes sense:</p>\n<ol>\n<li>A value of vector type may reside in memory or in a register</li>\n<li>(Except for the <code>I8X16</code> case,) there are two ways to arrange the bytes within each lanes (\"byte order\")</li>\n<li>(Except for the <code>I128</code> case,) there are two ways to arrange the lanes themselves (\"lane order\")</li>\n</ol>\n<p>This would result in 8 different cases to be considered.  However, I believe half of those can be quickly eliminated since they serve no useful purpose:</p>\n<ul>\n<li>For vector values in memory, only one lane order is useful: the one that matches array order (lane 0 at low addreses)</li>\n<li>For vector values in registers, only one byte order is useful: the one that matches the native machine byte order</li>\n</ul>\n<p>As a result, we can conclude:</p>\n<ul>\n<li>The representation of vector values in memory is determined by specifying a byte order - and we already do this today via the <code>MemFlags</code> carried by all instructions that access memory.</li>\n<li>The representation of vector values in registers is determined by specifying a lane order - this remains the open question.</li>\n</ul>\n<p>The next question is, how to characterize the two \"lane order\" options for values in registers.  First, we notice that if the vector is interpreted as <code>I128</code>, there is actually only one option, because that type only has a single lane.  Next, we can define lane order for other types in terms of re-interpreting the bit pattern as <code>I128</code>:</p>\n<ul>\n<li>If lane 0 of a vector type occupies the <em>least</em>-significant bytes of the re-interpreted <code>I128</code> value, we call it \"little-endian lane order\".</li>\n<li>If lane 0 of a vector type occupies the <em>most</em>-significant bytes of the re-interpreted <code>I128</code> value, we call it \"big-endian lane order\".</li>\n</ul>\n<p>This definition ensures in particular that we can match WebAssembly vector conversion semantics by always using vector types in little-endian lane order (when in registers).   In order to match semantics requires by native vector code (e.g. for the Rust front end), we need to use whatever lane order is considered the \"native\" default for the platform.  It appears that this matches the native byte order for all platforms I'm aware of (i.e. all platforms with native little-endian byte order seem to be using native little-endian lane order, and all platforms with native big-endian byte order seem to be using native big-endian lane order), but that's actually not necessarily a requirement.</p>\n<p>So far, we have not looked at ISA instructions at all.  First, we note that most operations are in fact independent of the lane order: an <code>iadd.i32x4</code> in little-endian lane order vs. an <code>iadd.i32x4</code> in big-endian lane order are exactly the same operation and can be implemented by exactly the same target instruction.   There are only two types of instructions where lane order is relevant:</p>\n<ul>\n<li>Memory loads and stores.</li>\n<li>Instructions that explicitly refer to lane numbers (<code>insertlane</code>, <code>extractlane</code>, <code>swizzle</code>, and <code>shuffle</code>).</li>\n</ul>\n<p>For the memory operations, we have four versions each, depending on the memory byte-order and the register lane-order.  These match the four versions described in the table in the original issue text.   For the explicit lane number operations, we'd have two versions each, depending on the lane order.</p>\n<p>Finally, we have to look at ABI considerations.   Obviously, if a value of vector type crosses an ABI boundary, there are ABI concerns: caller and callee must agree on the representation, which means they must agree on byte order if the value is passed in memory, and they must agree on lane order if the value is passed in register.</p>\n<p>For in-memory byte order, that's actually just business as usual since that applies to all other types as well.  [ As an aside, the situation is a bit more complex than one might first think: for values explicitly passed as parameters, we always use native byte order (even with the Wasmtime ABI, all values on the stack are always stored in native byte order currently), but for values used more indirectly (e.g. from a global variable or via a pointer), platform assumptions are in play (Wasmtime uses LE for such values, native code uses native byte order). ]</p>\n<p>The in-register lane order for vector types at ABI boundaries is a new question to be asked.  For native code, we must follow existing precedent, which requires native lane order (whatever that is on any given platform).   For Wasmtime, if we're lucky the issue does not occur, since Wasmtime only supports a single <code>v128</code> type at ABI boundaries, which is effectively <code>I128</code>, and therefore its representation in register does not depend on lane order.  (However, there might be a hitch in that the Wasmtime translator currently uses <code>I8X16</code> to represent the Wasmtime <code>v128</code> type - and <code>I8X16</code> <em>does</em> depend on lane order ...)</p>\n<p>All that said, we still have to decide how to represent lane order information.</p>\n<p><strong>Option 1: Global or per-function setting</strong></p>\n<p>I understand you don't like this option, but it would certainly be feasible.   In particular, it seems to me now that tying the lane order to the function <em>ABI</em> might be a good option, given that:</p>\n<ul>\n<li>The lane order at ABI boundaries is in any case a part of the visible ABI.</li>\n<li>Usually, a function will use the same lane order throughout, so it makes sense to use the lane order at ABI boundaries also as lane order for the whole function.</li>\n<li>This could actually be implemented as a s390x back-end only change (\"if the current function uses the Wasmtime ABI, it will use little-endian lane order throughout, otherwise big-endian lane order\"), affecting nothing else.</li>\n</ul>\n<p><strong>Option 2: Types</strong></p>\n<p>It appears it would indeed also be possible to use types to encode the lane order information.  We'd have e.g. <code>i32x4le</code> and <code>i32x4be</code> (where <code>le</code> and <code>be</code> of course refer to <em>lane</em> order, not byte order), and then implement the above-mentioned instructions according to the lane order implied by the type. </p>\n<p>This option might have some less-desirable consequences:</p>\n<ul>\n<li>For <code>swizzle</code> and <code>shuffle</code>, we may run into the case that the two (or three?) vector input registers have types implying <em>different</em> lane orders.   Would we have to fully support all combinations here?  This might not make much sense ...</li>\n<li>The <code>le</code> and <code>be</code> types would only affect in-register representation.   The in-memory representation would be identical, which might make it a bit surprising to use two different types ...</li>\n<li>This option implies a large-scale change to CLIF IR and every user of cranelift, since all uses of vector types would have to be rewritten.</li>\n<li>Also, we'd need a way for native front ends like Rust to specific \"native\" lane order.   Either by querying ISA properties, or else by having a separate \"native\" set of types (similar to what we do today for byte order).</li>\n</ul>\n<p><strong>Option 3: Instructions</strong></p>\n<p>Another option would be use different <em>instructions</em>.   This basically means we'd have either two copies of the affected instructions (memory ops, lane number ops), or else they'd all get some flags argument.   Either way, the lane order to be used would be hard-coded into the instruction itself.</p>\n<p>Some disadvantages of this option:</p>\n<ul>\n<li>There would be no automatic validation that the inputs to an operation actually <em>are</em> in the lane order that the instruction assumes.  (In the case of types, the validator could ensure that.)</li>\n<li>There's still a need to change all users of cranelift, but possibly to a lesser extent than the type option.</li>\n<li>Similarly, there's still a need to specify \"native\" byte order.</li>\n</ul>\n<p><strong>Option 4: Explicit conversion</strong></p>\n<blockquote>\n<p>Perhaps another approach is to eliminate the notion of bitcasting being a no-op on SIMD vectors.</p>\n</blockquote>\n<p>Sure, if <code>raw_bitcast</code> is no longer a no-op, much of the above would not be necessary: we'd simply use native lane orders in registers always, and then implement <code>raw_bitcast</code> as permutation.</p>\n<p>However, we'd still have to know whether the user intended <code>raw_bitcast</code> to transform between types in little-endian or big-endian lane order, because it would still be a no-op in one case but not the other.  So we <em>still</em> have to solve the question of how to specify lane order.  (I guess if we chose the _per instruction_ method this might become a bit simpler, since we'd now just need two versions of <code>raw_bitcast</code>, every other instruction could stay the same.)</p>\n<p>But I really don't like that option, since it would significantly degrade performance of Wasmtime on BE machines.  Some instances of <code>raw_bitcast</code> could probably be optimized away (e.g. folded into an adjacent load or store), but the Wasmtime translator seems to be creating <em>a lot</em> of <code>raw_bitcast</code>, all over the place.</p>\n<hr>\n<p>As to your code example, I don't see how that would solve the full problem.  You're doing a <code>vec_reinterpret_le</code> or <code>vec_reinterpret_be</code> adjacent to the loads and stores -- that is effectively the same as having two flavors of load and store.</p>\n<p>However, that doesn't solve the problem because we <em>also</em> need two flavors of <code>extractlane</code>!  To have a somewhat contrived example, let's assume we have code that adds two i32x4 vectors from memory, bitcasts the result to i8x16, and extracts lane 0.</p>\n<p>In Wasmtime semantics, this is supposed to return the LSB of the sum of lanes 0 of the two inputs.   In native semantics, this is supposed to return the MSB of the sum of lanes 0 of the two inputs.</p>\n<p>The code sequences I want to generate to efficiently implement both operations would be, for the native case:</p>\n<p><div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">   </span><span class=\"n\">v1</span><span class=\"w\"> </span>:<span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">loa</span><span class=\"w\"></span>\n<span class=\"p\">[</span><span class=\"n\">message</span><span class=\"w\"> </span><span class=\"n\">truncated</span><span class=\"p\">]</span><span class=\"w\"></span>\n</code></pre></div><br>\n</p>\n</blockquote>",
        "id": 291752272,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659466241
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1204313493\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Thank you again @uweigand for the detailed space-exploration here; I need to think more about this. Perhaps we can schedule some more time to talk about it in a Cranelift meeting?</p>\n<p>I will say now that one concern I have with a function-level or global-level mode is composability: if the meaning of instructions depends on the environment (func or larger scope) and that environment has only one setting, then we can no longer write IR that uses both behaviors, and we can no longer copy instructions between functions. That may not be a common operation now, but it will become a first-order concern when we build an inlining pass. I could imagine a (far) future where we have native runtime code compiled from e.g. a Rust frontend, and Wasm code compiled from the Wasm frontend, and we want to perhaps inline across them. So from a semantics and clean-design point of view, I'd prefer for instructions to encapsulate their entire meaning, without influence from environment.</p>\n<p>That leaves either the types or some update to the opcodes; I'm not sure which is the better option at this point. More discussion and thought needed!</p>\n</blockquote>",
        "id": 291898905,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659550453
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1204342238\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Thanks for looking at this, @cfallin !  Happy to have a discussion in the meeting - I'd be available next Monday (Aug 8).</p>\n</blockquote>",
        "id": 291902924,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659552188
    },
    {
        "content": "<p>akirilov-arm <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1204435113\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<p>The next question is, how to characterize the two \"lane order\" options for values in registers. First, we notice that if the vector is interpreted as <code>I128</code>, there is actually only one option, because that type only has a single lane. Next, we can define lane order for other types in terms of re-interpreting the bit pattern as <code>I128</code>:</p>\n<div class=\"codehilite\"><pre><span></span><code>* If lane 0 of a vector type occupies the _least_-significant bytes of the re-interpreted `I128` value, we call it &quot;little-endian lane order&quot;.\n\n* If lane 0 of a vector type occupies the _most_-significant bytes of the re-interpreted `I128` value, we call it &quot;big-endian lane order&quot;.\n</code></pre></div>\n\n<p>This definition ensures in particular that we can match WebAssembly vector conversion semantics by always using vector types in little-endian lane order (when in registers). In order to match semantics requires by native vector code (e.g. for the Rust front end), we need to use whatever lane order is considered the \"native\" default for the platform. It appears that this matches the native byte order for all platforms I'm aware of (i.e. all platforms with native little-endian byte order seem to be using native little-endian lane order, and all platforms with native big-endian byte order seem to be using native big-endian lane order), but that's actually not necessarily a requirement.</p>\n</blockquote>\n<p>As I mentioned during the last Cranelift meeting, I think that when data endianness is set to big-endian, the 64-bit Arm architecture does not fit into either of those categories. Consider an indexed vector multiplication, i.e. a <a href=\"https://developer.arm.com/documentation/ddi0602/2022-06/SIMD-FP-Instructions/MUL--by-element---Multiply--vector--by-element--?lang=en\">variant</a> of the <code>MUL</code> instruction, as an example - both the instruction description and pseudocode do not mention endianness, so if we are dealing with 16-bit elements, then element 0 occupies bits 0 to 15 out of the 128-bit vector.</p>\n<p>Now, we do not have any plans to implement big-endian support inside Cranelift's AArch64 backend in the near future (big-endian platforms are somewhat exotic and in fact big-endian support is optional in the architecture), but I think that this information might inform whatever design we come up with.</p>\n<blockquote>\n<p><strong>Option 1: Global or per-function setting</strong></p>\n<p>I understand you don't like this option, but it would certainly be feasible.</p>\n</blockquote>\n<p>The option I mentioned during the meeting was to introduce an ISA-specific setting in <code>cranelift/codegen/meta/src/isa/s390x.rs</code>, for instance, but it seems that it is not flexible enough to support the use case of mixing Rust and Wasm code that @cfallin is talking about.</p>\n</blockquote>",
        "id": 291914815,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659558101
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1204548289\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<blockquote>\n<p>This definition ensures in particular that we can match WebAssembly vector conversion semantics by always using vector types in little-endian lane order (when in registers). In order to match semantics requires by native vector code (e.g. for the Rust front end), we need to use whatever lane order is considered the \"native\" default for the platform. It appears that this matches the native byte order for all platforms I'm aware of (i.e. all platforms with native little-endian byte order seem to be using native little-endian lane order, and all platforms with native big-endian byte order seem to be using native big-endian lane order), but that's actually not necessarily a requirement.</p>\n</blockquote>\n<p>As I mentioned during the last Cranelift meeting, I think that when data endianness is set to big-endian, the 64-bit Arm architecture does not fit into either of those categories. Consider an indexed vector multiplication, i.e. a <a href=\"https://developer.arm.com/documentation/ddi0602/2022-06/SIMD-FP-Instructions/MUL--by-element---Multiply--vector--by-element--?lang=en\">variant</a> of the <code>MUL</code> instruction, as an example - both the instruction description and pseudocode do not mention endianness, so if we are dealing with 16-bit elements, then element 0 occupies bits 0 to 15 out of the 128-bit vector.</p>\n</blockquote>\n<p>Thanks for the pointer!  From my reading of the document, this simply means that AArch64 always uses a native vector lane ordering (according to my definition above) of little-endian, independent on whether the default byte order is little-endian or big-endian.</p>\n<p>Now that I think about it, Power is actually similar: Power supports both big-endian and little-endian default byte order, but the native vector lane ordering is always big-endian.</p>\n<p>So my statement quoted above that native lane order seems to always match default byte order is definitely not true :-)  But as I said, it's not actually a requirement.  This simply means that we need to provide both default byte order and native vector lane order as independent parameters of an ISA.</p>\n</blockquote>",
        "id": 291928789,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659565755
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1204583853\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Thinking about this some more, I have some further comments on this option:</p>\n<blockquote>\n<p><strong>Option 4: Explicit conversion</strong></p>\n<blockquote>\n<p>Perhaps another approach is to eliminate the notion of bitcasting being a no-op on SIMD vectors.</p>\n</blockquote>\n<p>Sure, if <code>raw_bitcast</code> is no longer a no-op, much of the above would not be necessary: we'd simply use native lane orders in registers always, and then implement <code>raw_bitcast</code> as permutation.</p>\n<p>However, we'd still have to know whether the user intended <code>raw_bitcast</code> to transform between types in little-endian or big-endian lane order, because it would still be a no-op in one case but not the other. So we _still_ have to solve the question of how to specify lane order. (I guess if we chose the _per instruction_ method this might become a bit simpler, since we'd now just need two versions of <code>raw_bitcast</code>, every other instruction could stay the same.)</p>\n</blockquote>\n<p>Ignoring efficiency aspects for a moment, this option may actually be the cleanest, semantically, after all.  To be specific, the option would consist of replacing <code>raw_bitcast</code> with two new IR instructions, called something along the lines of <code>bitcast_le_lanes</code> and <code>bitcast_be_lanes</code>  (better naming suggestions welcome!).   This would be the sole change, there are no changes to any other instructions, no changes to the type system, and no global or implied parameters anywhere.</p>\n<p>The semantics of the new instructions would be:</p>\n<ul>\n<li><code>bitcast_le_lanes</code>: reinterpret the bit pattern of vector type A, assumed to be represented in little-endian lane order, as vector type B, also represented in little-endian lane order</li>\n<li><code>bitcast_be_lanes</code>: same, but using big-endian lane order</li>\n</ul>\n<p>The semantics of the two instructions would then actually be fully well-defined, and not dependent on any implicit platform properties (unlike the current <code>raw_bitcast</code>). </p>\n<p>If the requested lane order matches the lane order the implementation chose to hold vector values in vector registers, the operation remains a no-op; otherwise, the implementation is a permutation.   Specifically, a <code>bitcast_[bl]e_lanes</code> from type X to type Y is either a no-op, or a sequence of \"swap lanes of type X\" + \"no-op reinterpretation\" + \"swap lanes of type Y\".</p>\n<p>Now, lets look back at implementation efficiency.  As I noted above, a naive direct implementation of the semantics as just defined would be very inefficient, certainly in the case of Wasmtime on BE lane order systems.  However, there may be options to provide _optimizations_ to make the implementation more efficient - without any change to the semantics!  (And therefore, without affecting the properties you were concerned about, @cfallin.)</p>\n<p>Specifically, I can think of options to optimize implementation:</p>\n<p><strong>Explicit swap_lanes instructions</strong></p>\n<p>We could, as an optimization pass, do the following:</p>\n<ul>\n<li>Replace the <code>bitcast_[bl]e_lanes</code> instructions with a pair of explicit <code>swap_lanes</code> instructions as per the semantics above.</li>\n<li>Note that <code>swap_lanes</code> commutes directly over all \"normal\" vector instructions, and commutes over vector instructions using explicit lane numbers when adding the appropriate lane number compensation operations.   Also, two adjacent <code>swap_lanes</code> operations on the same type cancel each other, and a <code>swap_lanes</code> of a single-lane type is a no-op.  These are just generally valid, semantics-preserving transformations of the IR.</li>\n<li>Using a series of such transformations, we can push all <code>swap_lanes</code> up or down all the way to the original sources and sinks of the data flow graph.  Those would be arguments and return values, and memory loads and stores.  For the latter we can then use appropriate instruction selection to merge the swaps into the memory operation (if the ISA has such instructions).  For arguments and return values, the swaps remain (however in the Wasmtime special case, we should always see the single-lane V128 type here, so those swaps would also be no-ops).</li>\n</ul>\n<p>That is something that could possibly be done within the new egraph-based framework.  But maybe all that compile-time overhead isn't actually necessary either, because we can just do this instead:</p>\n<p><strong>Implementation choice of lane order (semantics preserving)</strong></p>\n<p>With the above model, Cranelift IR has well-defined semantics that does not depend on global parameters.  However, the code generation back-end is free to chose to emit whatever instruction sequence it wants - assuming it in the end implements that well-defined semantics.</p>\n<p>In particular, the implementation is actually always <strong>free to choose</strong> whether to represent vector values in vector registers in little-endian or big-endian lane order!   For example, on a platform like <code>s390x</code> with native big-endian lane order, I <em>can</em> implement Cranelift IR semantics as:</p>\n<ul>\n<li>Assuming the ABI prescribes vector values are in native (big-endian) lane order at ABI boundaries, just leave them that way.</li>\n<li>Implement memory operations and lane number related operations assuming big-endian lane order.</li>\n<li>Implement <code>bitcast_le_lanes</code> as explicit permutation.</li>\n<li>Implement <code>bitcast_be_lanes</code> as no-op.</li>\n</ul>\n<p>However, I <em>also</em> can implement the very same Cranelift IR semantics by doing instead:</p>\n<ul>\n<li>Lane-swap all vector values at the ABI boundary.</li>\n<li>Implement memory operations and lane number related operations assuming little-endian lane order.</li>\n<li>Implement <code>bitcast_le_lanes</code> as no-op.</li>\n<li>Implement <code>bitcast_be_lanes</code> as explicit permutation.</li>\n</ul>\n<p>This just results in a different instruction sequence for the current function, but implementing the exact same semantics.</p>\n<p>Now, since this is just an implementation choice, I'm free to use whatever heuristics make most sense to decide which way to go.   For example, if a function contains many <code>bitcast_le_lanes</code> and no <code>bitcast_be_lanes</code>, it would likely be beneficial to chose the implementation that makes <code>bitcast_le_lanes</code> a no-op, and vice versa.</p>\n<p>In fact, I could even just use the current function's ABI as input to that heuristic, and simply use little-endian lane order for functions using the Wasmtime ABI, and big-endian lane order otherwise.  Combined with the fact that in the Wasmtime ABI, we only have the single-lane V128 at ABI boundaries and therefore those swaps are no-ops, I would end up with <strong>exactly</strong> the same generated code, and basically no compile time overhead either, as I would have in the option described above as \"Option 1: Global or per-function setting\".</p>\n<p>But at the same time, there actually <em>is</em> no global state and Cranelift IR semantics is locally well-defined.   While I do look at the ABI to make a decision, the ABI only influences implementation choice heuristics, <em>not</em> semantics.</p>\n</blockquote>",
        "id": 291945337,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659569751
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1208336548\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<p>Thanks for looking at this, @cfallin ! Happy to have a discussion in the meeting - I'd be available next Monday (Aug 8).</p>\n</blockquote>\n<p>Hi @cfallin for reference here's the set of charts I shared in today's meetings: <a href=\"https://github.com/bytecodealliance/wasmtime/files/9283427/Vector-Endian.pdf\">Vector-Endian.pdf</a><br>\n</p>\n</blockquote>",
        "id": 292424627,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1659975743
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1232929685\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>The remaining open part of this issue is the question of how to define the new IR instruction(s) to implement bitcasts with explicitly specified lane order.  In preparation for this, I've been reviewing the existing <code>bitcast</code> and <code>raw_bitcast</code> instructions.</p>\n<p>First, we have <code>bitcast</code>, which is specified as</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">        </span><span class=\"n\">Reinterpret</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">bits</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"err\">`</span><span class=\"n\">x</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">different</span><span class=\"w\"> </span><span class=\"k\">type</span><span class=\"p\">.</span><span class=\"w\"></span>\n\n<span class=\"w\">        </span><span class=\"n\">The</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"n\">output</span><span class=\"w\"> </span><span class=\"n\">types</span><span class=\"w\"> </span><span class=\"n\">must</span><span class=\"w\"> </span><span class=\"n\">be</span><span class=\"w\"> </span><span class=\"n\">storable</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">same</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">size</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">A</span><span class=\"w\"> </span><span class=\"n\">bitcast</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"w\"> </span><span class=\"n\">equivalent</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">storing</span><span class=\"w\"> </span><span class=\"n\">one</span><span class=\"w\"> </span><span class=\"k\">type</span> <span class=\"nc\">and</span><span class=\"w\"> </span><span class=\"n\">loading</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">other</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"k\">type</span> <span class=\"nc\">from</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">same</span><span class=\"w\"> </span><span class=\"n\">address</span><span class=\"p\">.</span><span class=\"w\"></span>\n</code></pre></div>\n<p>However, the implementation doesn't really match the specification in various aspects:</p>\n<ul>\n<li>At the parser level, <code>bitcast</code> does accept exactly the set of types storable to memory (i.e. basically everything except bool), however the size check is only partially enforced: any set of types with <code>lane_bits(dest) &gt;= lane_bits(src)</code> is accepted by the validator.</li>\n<li>At the <em>implementation</em> level in all three back-ends, only a very limited set of types is actually supported: bitcasts between <code>I32</code> and <code>F32</code>, and between <code>I64</code> and <code>F64</code> respectively.  (These are implemented as cross-register-bank moves.)</li>\n<li>Reviewing all <em>users</em> of <code>bitcast</code>, I find that is it currently also only used for these particular combinations: to implement the <code>F32ReinterpretI32</code> etc. WebAssembly instructions, and in <code>cg_clif</code> to implement transmutes between exactly those types.</li>\n</ul>\n<p>Then, separately, we have <code>raw_bitcast</code>, which is specified as:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">        </span><span class=\"n\">Cast</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">bits</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"err\">`</span><span class=\"n\">x</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">different</span><span class=\"w\"> </span><span class=\"k\">type</span> <span class=\"nc\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">same</span><span class=\"w\"> </span><span class=\"n\">bit</span><span class=\"w\"> </span><span class=\"n\">width</span><span class=\"p\">.</span><span class=\"w\"></span>\n\n<span class=\"w\">        </span><span class=\"n\">This</span><span class=\"w\"> </span><span class=\"n\">instruction</span><span class=\"w\"> </span><span class=\"n\">does</span><span class=\"w\"> </span><span class=\"n\">not</span><span class=\"w\"> </span><span class=\"n\">change</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">data</span><span class=\"o\">'</span><span class=\"na\">s</span><span class=\"w\"> </span><span class=\"n\">representation</span><span class=\"w\"> </span><span class=\"n\">but</span><span class=\"w\"> </span><span class=\"n\">allows</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">data</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">registers</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">be</span><span class=\"w\"> </span><span class=\"n\">used</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"n\">different</span><span class=\"w\"> </span><span class=\"n\">types</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">e</span><span class=\"p\">.</span><span class=\"n\">g</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">an</span><span class=\"w\"> </span><span class=\"n\">i32x4</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">b8x16</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">The</span><span class=\"w\"> </span><span class=\"n\">only</span><span class=\"w\"> </span><span class=\"n\">constraint</span><span class=\"w\"> </span><span class=\"n\">on</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"err\">`</span><span class=\"n\">a</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"w\"> </span><span class=\"n\">that</span><span class=\"w\"> </span><span class=\"n\">it</span><span class=\"w\"> </span><span class=\"n\">can</span><span class=\"w\"> </span><span class=\"n\">be</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"err\">`</span><span class=\"n\">raw_bitcast</span><span class=\"err\">`</span><span class=\"w\"> </span><span class=\"n\">back</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">original</span><span class=\"w\"> </span><span class=\"k\">type</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">Also</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">raw_bitcast</span><span class=\"w\"> </span><span class=\"n\">between</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">types</span><span class=\"w\"> </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">same</span><span class=\"w\"> </span><span class=\"n\">number</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">lanes</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">value</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">result</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">lane</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">raw_bitcast</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">corresponding</span><span class=\"w\"> </span><span class=\"n\">operand</span><span class=\"w\"> </span><span class=\"n\">lane</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">TODO</span><span class=\"w\"> </span><span class=\"n\">there</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">currently</span><span class=\"w\"> </span><span class=\"n\">no</span><span class=\"w\"> </span><span class=\"n\">mechanism</span><span class=\"w\"> </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">enforcing</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">bit</span><span class=\"w\"> </span><span class=\"n\">width</span><span class=\"w\"> </span><span class=\"n\">constraint</span><span class=\"p\">.</span><span class=\"w\"></span>\n</code></pre></div>\n<p>Reading the text, it is somewhat unclear what exactly, on the specification level, the difference between <code>bitcast</code> and <code>raw_bitcast</code> is intended to be.  The only clearly mentioned difference is that <code>raw_bitcast</code> is explicitly supported on boolean types (or at least boolean <em>vector</em> types), which are not supported with <code>bitcast</code> as they cannot be stored to memory.</p>\n<p>Looking at the actual implementation, we see:</p>\n<ul>\n<li>Boolean types are in fact explicitly supported (but for some reason, dynamic SIMD types are not, so this is not a clear superset of the set of types supported by <code>bitcast</code> either).</li>\n<li>There is absolutely no check on type sizes (or lane number, for that matter) during validation.</li>\n<li>All back-ends implement this as a pure no-op.  This means <code>bitcast</code> cannot be replaced by <code>raw_bitcast</code> on those combinations where cross-register-bank moves would be required, even though the specification doesn't seem to exclude this directly.</li>\n<li><code>raw_bitcast</code> is used in a single place in <code>cg_clif</code> to implement transmutes between (any pair of) vector types.  It is frequently used by the wasm front-end to map between the WebAssembly <code>V128</code> and various CLIF vector types.  In particular, it is definitely used for boolean vector types.</li>\n</ul>\n<p>In addition, there are two places in cranelift middle-end common code that match and/or generate <code>raw_bitcast</code>:</p>\n<ul>\n<li><code>simplify</code> in <code>simple_preopt.rs</code>, when performing the <code>bitselect</code> to <code>vselect</code> optimization.</li>\n<li>when constructing a vector <code>bitselect</code> during NaN canonicalization.</li>\n</ul>\n<p>It seems to me that both of these aren't really necessary: I think the NaN canonicalization can just be done without bitcasts, and the <code>bitselect</code> to <code>vselect</code> optimization is only useful on x64 anyway and should really be done as an ISLE rule in that backend.</p>\n<p>In summary, it appears that the distinction between <code>bitselect</code> and <code>raw_bitselect</code> has been driven primarily by the particular implementation (int vs. float register bank moves on the one hand, and no-op re-interpretation of vector types on the other).  This doesn't seem an ideal choice for providing well-defined general operation sematics, though ...</p>\n<p>The specification in <code>bitcast</code> reading <code>A bitcast is equivalent to storing one type and loading the other type from the same address.</code> actually <em>does</em> look very reasonable to me.   And in particular, this would naturally handle the lane order distinction if the <code>storing</code> and <code>loading</code> operation mentioned there would be interpreted as using a particular byte order.  From that perspective, it might even make sense to just add <code>MemFlags</code> to the <code>bitcast</code> operation ...</p>\n<p>However, the one place this breaks down is that we cannot handle boolean types, since those cannot be stored to or loaded from memory.  But that in itself seems a bit of an inconsistency: I understand the reason for this restriction is that the actual bit pattern used to implement <code>true</code> and <code>false</code> values was intended to be platform-specific, and therefore there should be no CLIF IR operation that exposes this bit pattern.  But that's no longer true anyway as you can just <code>raw_bitcast</code> them.  And in fact, the wasm implementation of vector compare operations is only correct if back-ends use one particular implementation (namely, all 0 bits for <code>false</code>, and all 1 bits for <code>true</code>).</p>\n<p>So I think we <em>either</em> should make this an actual requirement, and then allow loading/storing those types, or else, we disallow <code>raw_bitcast</code> on boolean (vector) types and instead provide a new instruction similar to <code>bint</code> (except using 0/-1 instead of 0/1) that the wasm frontend could use to implement WebAssembly semantics.  In both cases, there would be no more need to distinguish between <code>bitcast</code> and <code>raw_bitcast</code> on an IR level.  Of course, back-ends would still need to implement both the cross-register-bank move and the in-register no-op semantics - but that distinction could be made via the <em>type</em> instead of the operation.</p>\n<p>Any comments or suggestions welcome!</p>\n</blockquote>",
        "id": 296323193,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661951993
    },
    {
        "content": "<p>akirilov-arm <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233087463\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>@uweigand Are you aware of PR #4820?</p>\n</blockquote>",
        "id": 296355999,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661959570
    },
    {
        "content": "<p>akirilov-arm edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233087463\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>@uweigand Are you aware of PR #4820?</p>\n<p>IMHO the only difference between <code>bitcast</code> and <code>raw_bitcast</code> is that the latter is allowed to change the number of lanes (while still keeping the overall size of the type the same). The fact that all backends implement <code>raw_bitcast</code> as a no-op is a bug, precisely because, as you imply, that's wrong for cast from <code>F64</code> to <code>I64</code>, for example. Of course, given the main use case of the operation (lane number change), we never hit this bug in practice. I am surprised that a fuzzer hasn't started hitting this issue, though.</p>\n</blockquote>",
        "id": 296358638,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661959843
    },
    {
        "content": "<p>akirilov-arm edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233087463\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>@uweigand Are you aware of PR #4820?</p>\n<p>IMHO the only difference between <code>bitcast</code> and <code>raw_bitcast</code> is that the latter is allowed to change the number of lanes (while still keeping the overall size of the type the same). The fact that all backends implement <code>raw_bitcast</code> as a no-op is a bug, precisely because, as you imply, that's wrong for a cast from <code>F64</code> to <code>I64</code>, for example. Of course, given the main use case of the operation (lane number change), we never hit this bug in practice. I am surprised that a fuzzer hasn't started hitting this issue, though.</p>\n</blockquote>",
        "id": 296358732,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661959873
    },
    {
        "content": "<p>akirilov-arm edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233087463\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>@uweigand Are you aware of PR #4820?</p>\n<p>IMHO the only difference between <code>bitcast</code> and <code>raw_bitcast</code> is that the latter is allowed to change the number of lanes (while still keeping the overall size of the type the same). The fact that all backends implement <code>raw_bitcast</code> as a no-op is a bug, precisely because, as you imply, that's wrong for a cast from <code>F64</code> to <code>I64</code>, for example. Of course, given the main use case of the operation (lane number change), we never hit this issue in practice. I am surprised that a fuzzer hasn't started to, though.</p>\n</blockquote>",
        "id": 296358926,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661959930
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233098351\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>It looks like cranelift-fuzzgen doesn't generate either variant of <code>bitcast</code> yet, and the other fuzzers generate wasm rather than CLIF. So I'm not surprised that fuzzing hasn't exercised this part of the CLIF specification.</p>\n</blockquote>",
        "id": 296359512,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661960098
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233179645\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<p>@uweigand Are you aware of PR #4820?</p>\n</blockquote>\n<p>I wasn't - thanks for the pointer!</p>\n<blockquote>\n<p>IMHO the only difference between <code>bitcast</code> and <code>raw_bitcast</code> is that the latter is allowed to change the number of lanes (while still keeping the overall size of the type the same).</p>\n</blockquote>\n<p>Well, that, and of course the boolean type issue I mentioned.<br>\n</p>\n</blockquote>",
        "id": 296405306,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661964434
    },
    {
        "content": "<p>akirilov-arm <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233198386\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Ah, I see, my memory is fuzzy, and I feel that this was discussed before, but is the boolean thing basically the only real reason for the distinction between <code>bitcast</code> and <code>raw_bitcast</code>? The latter is strictly more general than the former, so I suppose having <code>bitcast</code> just helps with type checking (oh, and I am intentionally ignoring what the backend implementations look like).</p>\n</blockquote>",
        "id": 296409217,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661965586
    },
    {
        "content": "<p>akirilov-arm edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233198386\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Ah, I see, my memory is fuzzy, and I feel that this was discussed before, but is the boolean thing basically the only real reason for the distinction between <code>bitcast</code> and <code>raw_bitcast</code>? The latter is strictly more general than the former, so I suppose having <code>bitcast</code> just helps with type checking (oh, and I am intentionally ignoring what the backend implementations look like).</p>\n<p><strong>P.S.</strong> IMHO the actual implementations of both <code>bitcast</code> and <code>raw_bitcast</code> should be exactly the same, at least in the AArch64 case, and PR #4820 contains the code (though it doesn't touch the <code>raw_bitcast</code> lowering, since @dheaton-arm doesn't necessarily share my opinion).</p>\n</blockquote>",
        "id": 296410246,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661965917
    },
    {
        "content": "<p>akirilov-arm edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233198386\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Ah, I see, my memory is fuzzy, and I feel that this was discussed before, but is the boolean thing basically the only real reason for the distinction between <code>bitcast</code> and <code>raw_bitcast</code>? The latter is strictly more general than the former, so I suppose having <code>bitcast</code> just helps with type checking (oh, and I am intentionally ignoring what the backend implementations look like).</p>\n<p><strong>P.S.</strong> IMHO the actual implementations of both <code>bitcast</code> and <code>raw_bitcast</code> should be exactly the same, at least in the AArch64 case, and PR #4820 contains the code (though it doesn't touch the <code>raw_bitcast</code> lowering, since @dheaton-arm doesn't necessarily share my opinion).</p>\n<p><strong>P.P.S.</strong> I just noticed the difference with respect to dynamic vector type support - @sparker-arm, was this just an accidental omission?</p>\n</blockquote>",
        "id": 296412553,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661966555
    },
    {
        "content": "<p>sparker-arm <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1233993240\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>I never thought bitcasts could be so complicated until I read the clif docs :)</p>\n<p>It sounds like the standarization of booleans, hopefully enabling storage, is the only thing preventing one cast to rule them all?</p>\n<p>RE: dynamic vectors, the fact that <code>bitcasts</code> are currently supported and <code>raw_bitcasts</code> are not is purely coincidental. Load/store to stack slots were implemented so the <code>Mem</code> type had dynamic vectors built in, the same type that we use <code>bitcast</code>.</p>\n<p>I'm don't believe any casts should even apply to dynamic vectors as, at the IR level, we can't tell whether two dynamic types have the equivalent sizes.  </p>\n</blockquote>",
        "id": 296546274,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662023618
    },
    {
        "content": "<p>dheaton-arm <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1234328105\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>@uweigand In case you aren't aware, there was <a href=\"#narrow/stream/217117-cranelift/topic/bitcasts\">some discussion</a> on Zulip about <code>bitcast</code>/<code>raw_bitcast</code> as well, which had some conclusions on the differences between <code>bitcast</code> and <code>raw_bitcast</code>.</p>\n</blockquote>",
        "id": 296592713,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662041036
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1234742078\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<blockquote>\n<p>From that perspective, it might even make sense to just add <code>MemFlags</code> to the <code>bitcast</code> operation ...</p>\n</blockquote>\n<p>This makes sense to me.</p>\n<blockquote>\n<p>However, the one place this breaks down is that we cannot handle boolean types, since those cannot be stored to or loaded from memory. But that in itself seems a bit of an inconsistency: I understand the reason for this restriction is that the actual bit pattern used to implement <code>true</code> and <code>false</code> values was intended to be platform-specific, and therefore there should be no CLIF IR operation that exposes this bit pattern. But that's no longer true anyway as you can just <code>raw_bitcast</code> them. And in fact, the wasm implementation of vector compare operations is only correct if back-ends use one particular implementation (namely, all 0 bits for <code>false</code>, and all 1 bits for <code>true</code>).</p>\n</blockquote>\n<p>I would actually be in favor of investigating whether we can completely remove boolean types. They are always the special, odd case. I'm not convinced that we couldn't just get by with <code>i8</code> instead, as the other scalar booleans don't seem particularly useful and the vector booleans even more so. It would certainly let us clean up a ton of things.</p>\n<p>I would also be in favor of investigating whether we can remove i8x16 et al and just have <code>v128</code> like Wasm has. I don't think the types are actually used by anything and we just have to insert these <code>raw_bitcast</code>s all over the place. What are they buying us? Although maybe this isn't possible because of lane ordering. I clearly haven't thought too deeply about this, but if it is practical, then I'm all for it.</p>\n</blockquote>",
        "id": 296693848,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662063784
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1234748156\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>The typed are used for determining what kind of operation (lane size, lane count) to perform when you have eg an iadd instruction. Also cg_clif doesn't need bitcasting for vectors nearly as much as rust uses unique types for each vector lane count+width.</p>\n</blockquote>",
        "id": 296694845,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662064216
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566#issuecomment-1234819394\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Weighing in a bit late here, sorry (and thank you @uweigand for the detailed analysis as always!) -- I think I'm converging toward the following thoughts:</p>\n<ul>\n<li>\n<p>Indeed, booleans are best addressed by removing them altogether. The <code>BNxM</code> vector-bool types and <code>Bn</code> wide-bool types for <code>n &gt; 1</code> never sat well with me: the intent is clearly to have some sort of mask value, but these types are n-bit containers where all but two of the <code>2^n</code> possible values are illegal. As we explored in #3205 (an issue which just celebrated its first birthday -- clearly this stuff is not easy), that implies either some sort of validation -- on load? on conversion into a wide bool type? -- or undefined behavior in some cases.</p>\n<p>The bitmask-like cases for wide bools can IMHO be satisfied by integer-typed SIMD values, and the cases were we need to communicate a value from an <code>icmp</code> to a \"bool\" consumer, like <code>select</code>, can pattern-match the <code>(select (icmp ...))</code> as they do today and work from a reified zero/nonzero value otherwise (any nonzero -&gt; true).</p>\n<p>I also suspect that our support for bool types is patchy at best -- there are lowerings in some places tested by tests, but bools have never been as well-exercised as ints. Simplifying our set of types gets us closer to full coverage in one big step.</p>\n</li>\n<li>\n<p>If we remove boolean types altogether, then we no longer need the distinction between the two bitcasts. At that point I favor calling it <code>bitcast</code>; the <code>raw_</code> is somewhat confusing (isn't a bit-level pun operation at some level \"raw\" no matter what?).</p>\n</li>\n<li>\n<p>Adding a <code>MemFlags</code> to the <code>bitcast</code> instruction is a pretty novel idea, and <em>almost</em> follows from the \"store-then-load\" equivalent sequence, I think, except that the underlying store and load could have different flags. Similarly some of the flags wouldn't matter (e.g., <code>notrap</code> and <code>aligned</code> -- the operation would be defined in terms of a hypothetical memory location that is always valid and aligned), and I generally prefer not to have representable variants that don't have semantic meaning. Instead could we make endianness part of the cast? This I think subsumes @uweigand's proposed ops above, with the LE / BE variants. The endianness is irrelevant for scalar casts in practice (and let's say by definition if we want: I don't think there are machines that use one endianness for I64 and another for F64?) but matters for vector lane order (see rest of this issue!).</p>\n</li>\n</ul>\n<p>If this seems reasonable, then I think the order of operations is (i) remove bools, (ii) remove <code>raw_bitcast</code> and move vector use-cases over to <code>bitcast</code>, merging the lowerings for the different cases in the backends, then (iii) add the notion of endianness to <code>bitcast</code>.</p>\n<p>Thoughts?</p>\n</blockquote>",
        "id": 296705595,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662069116
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Currently, <code>s390x</code> is the only big-endian platform supported by cranelift, which has already caused problems related to memory accesses in the past, since wasmtime defines all data in its memory to be in little-endian byte order.</p>\n<p>I had assumed that <em>register</em> contents are not affected by byte order, and while this is true for scalar types, it turns out this is not actually the case for vector registers.  This is because of a combination of two issues:</p>\n<ol>\n<li>There are IR instructions that directly refer to vector register _lanes_ by number; and</li>\n<li>There are IR instructions to re-interpret a vector register as any other vector type, including one with different lane numbers</li>\n</ol>\n<p>The combination of these two makes ISA byte order properties of vector registers visible to IR code, just like byte order in memory is visible via a combination of using memory addresses to access (parts of) a value in memory in a different type than it was stored.</p>\n<p>Specifically, in the Intel (or ARM) little-endian ISA, if you load e.g. a <code>I32X4</code> into a vector register, use <code>raw_bitcast</code> to re-interpret that register as <code>I8X16</code>, and retrieve lane 0 of the resulting value via <code>extractlane</code>, the result will be the <em>least</em>-significant byte of the <code>I32</code> in lane 0 of the original value.   And in fact, wasmtime <em>requires</em> this to be the case.</p>\n<p>On the other hand, on <code>s390x</code> the content of a vector register in <code>I32X4</code> mode will be a sequence of four <code>I32</code>, each in <em>big-endian</em> byte order (or else the arithmetic operations on the register will give wrong results).   Therefore, the same sequence of operations as above will return the <em>most</em>-significant byte of the <code>I32</code> in lane 0.   This actually caused many wasmtime tests to fail.</p>\n<hr>\n<p>To fix this, my current implementation of SIMD instructions on <code>s390x</code> uses a trick combining two different aspects:</p>\n<ul>\n<li>When loading the <code>I32X4</code> from little-endian memory into a vector register, I'm byte-reversing all 16 bytes of the loaded value.  This not only fixes each <code>I32</code> value to be in the correct big-endian order in the register so subsequent arithmetic will work, it <em>also</em> implicitly swaps the order of elements, i.e. the element in slot 0 in memory will end up in what the ISA considers slot 3 of the register etc.</li>\n<li>The implementation of all IR instructions that uses explicit lane numbers will be aware of this renumbering, and implicitly revert it to get back to the lanes the code intends to access, so e.g. using <code>extractlane</code> for lane 0 of a <code>I32X4</code> will actually at the ISA level extract lane 3 of the register.</li>\n</ul>\n<p>The combination of these two aspects makes accessing SIMD registers work correctly for wasmtime.  For example, in the above case, accessing lane 0 of a <code>I8X16</code> is converted to lane 15 of the register, which holds the <em>least</em>-significant byte of the <code>I32</code> in lane 3 of the register, which was loaded from lane 0 in memory -- so in the end we return the least-significant byte of the <code>I32</code> in lane 0 of the original value, as expected by wasmtime.</p>\n<hr>\n<p>However, in implementing support for <code>rustc_codegen_cranelift</code>, I noticed that the current implementation actually breaks when handling <em>big-endian</em> vectors in memory - this will be the case for rustc, since that uses native platform byte order everywhere.  Specifically, when loading a big-endian vector from memory, I'm just loading the bytes unchanged.  This means that e.g. lane 0 of a <code>I32X4</code> in memory ends up in its original byte order (which is OK since this is already big-endian) in lane 0 of the register - but the latter is a problem if subsequent code wants to extract that lane, since an <code>extractlane 0</code> will actually access lane 3 in the register as described above!</p>\n<p>To work around <em>that</em> problem, I've implemented a patch that will perform big-endian vector loads by swapping the order of the <em>elements</em>, but not the byte order within any single element.  This will cause lane 0 from memory to end up in lane 3 in the register, and makes <code>extractlane</code> work as expected again.</p>\n<p>With that fix, now <em>both</em> wasmtime and rustc_codegen_cranelift pass all their existing SIMD tests.   Unfortunately, I think this is still not quite a complete solution.</p>\n<hr>\n<p>Specifically, we can now run into two additional problems with big-endian code, which apparently are just never triggered by the existing rustc_codegen_cranelift tests.</p>\n<p>First, I guess it would be possible to re-interpret contents in a vector register in another type even in rustc.   Now, as opposed to wasmtime, rustc uses native endianness, presumably also w.r.t. vector contents.   Therefore, the semantics of such a re-interpretation would be platform-defined and differ between big- and little-endian platforms (which is probably why it's not frequently used).  However, users would expect this platform-specific behavior to be the <em>same</em> between the LLVM and cranelift back ends to rustc - which in the current implementation it would not be.</p>\n<p>Even more problematic, carrying vector elements in reverse order in vector registers actually affects the <em>ABI</em>, as vector types are passed in vector registers.   Code compiled by rustc using the LLVM back end would expect those to be in the \"normal\" platform order, while code compiled by rustc using the cranelift back end would expect them to be the \"reverse\" order.</p>\n<hr>\n<p>One option I'm thinking of would be to actually implement <em>both</em> methods in the cranelift back end.  Specifically, the back end could support both a \"vector big-endian\" and \"vector little-endian\" mode, where the \"big-endian\" mode would use lane numbers directly as defined by our ISA, while the \"little-endian\" mode would use the reverse ordering implemented by the current back end code.</p>\n<p>There's a slight complication in that we might have to support both big- and little-endian vector modes in load and store operations accessing any combination of big- and little-endian memory locations.  But that should be possible:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">mode</span><span class=\"w\">      </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\">    </span><span class=\"n\">load</span><span class=\"o\">/</span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">operation</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">direct</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">element</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">elements</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"mi\">16</span><span class=\"o\">-</span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(Starting with <code>z15</code> we actually can implement each of these operations using a single instruction, so that should also be efficient.)</p>\n<p>The one remaining question is, how to select between the \"vector big-endian\" and \"vector little-endian\" modes?   There are no attributes (like <code>MemFlags</code>) on the <code>extractlane</code> etc. operations, and that wouldn't even make sense: this is a global property, if you used big-endian mode to load the vector you must also use big-endian mode on all subsequent operations.</p>\n<p>So I guess this would have to be some sort of global flag, which wasmtime would set to always little-endian, and rustc would leave at native byte order.   Of course, this flag is actually ABI changing, so the same setting must be used for code to remain link-compatible.  But I think given the above use cases, that should actually be fine.</p>\n<hr>\n<p>FYI @cfallin - this is another problem I ran into while enabling <code>rustc_codegen_cranelift</code>  - I'd appreciate any comments or suggestions!</p>\n</blockquote>",
        "id": 296846448,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662133480
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Currently, <code>s390x</code> is the only big-endian platform supported by cranelift, which has already caused problems related to memory accesses in the past, since wasmtime defines all data in its memory to be in little-endian byte order.</p>\n<p>I had assumed that <em>register</em> contents are not affected by byte order, and while this is true for scalar types, it turns out this is not actually the case for vector registers.  This is because of a combination of two issues:</p>\n<ol>\n<li>There are IR instructions that directly refer to vector register _lanes_ by number; and</li>\n<li>There are IR instructions to re-interpret a vector register as any other vector type, including one with different lane numbers</li>\n</ol>\n<p>The combination of these two makes ISA byte order properties of vector registers visible to IR code, just like byte order in memory is visible via a combination of using memory addresses to access (parts of) a value in memory in a different type than it was stored.</p>\n<p>Specifically, in the Intel (or ARM) little-endian ISA, if you load e.g. a <code>I32X4</code> into a vector register, use <code>raw_bitcast</code> to re-interpret that register as <code>I8X16</code>, and retrieve lane 0 of the resulting value via <code>extractlane</code>, the result will be the <em>least</em>-significant byte of the <code>I32</code> in lane 0 of the original value.   And in fact, wasmtime <em>requires</em> this to be the case.</p>\n<p>On the other hand, on <code>s390x</code> the content of a vector register in <code>I32X4</code> mode will be a sequence of four <code>I32</code>, each in <em>big-endian</em> byte order (or else the arithmetic operations on the register will give wrong results).   Therefore, the same sequence of operations as above will return the <em>most</em>-significant byte of the <code>I32</code> in lane 0.   This actually caused many wasmtime tests to fail.</p>\n<hr>\n<p>To fix this, my current implementation of SIMD instructions on <code>s390x</code> uses a trick combining two different aspects:</p>\n<ul>\n<li>When loading the <code>I32X4</code> from little-endian memory into a vector register, I'm byte-reversing all 16 bytes of the loaded value.  This not only fixes each <code>I32</code> value to be in the correct big-endian order in the register so subsequent arithmetic will work, it <em>also</em> implicitly swaps the order of elements, i.e. the element in slot 0 in memory will end up in what the ISA considers slot 3 of the register etc.</li>\n<li>The implementation of all IR instructions that uses explicit lane numbers will be aware of this renumbering, and implicitly revert it to get back to the lanes the code intends to access, so e.g. using <code>extractlane</code> for lane 0 of a <code>I32X4</code> will actually at the ISA level extract lane 3 of the register.</li>\n</ul>\n<p>The combination of these two aspects makes accessing SIMD registers work correctly for wasmtime.  For example, in the above case, accessing lane 0 of a <code>I8X16</code> is converted to lane 15 of the register, which holds the <em>least</em>-significant byte of the <code>I32</code> in lane 3 of the register, which was loaded from lane 0 in memory -- so in the end we return the least-significant byte of the <code>I32</code> in lane 0 of the original value, as expected by wasmtime.</p>\n<hr>\n<p>However, in implementing support for <code>rustc_codegen_cranelift</code>, I noticed that the current implementation actually breaks when handling <em>big-endian</em> vectors in memory - this will be the case for rustc, since that uses native platform byte order everywhere.  Specifically, when loading a big-endian vector from memory, I'm just loading the bytes unchanged.  This means that e.g. lane 0 of a <code>I32X4</code> in memory ends up in its original byte order (which is OK since this is already big-endian) in lane 0 of the register - but the latter is a problem if subsequent code wants to extract that lane, since an <code>extractlane 0</code> will actually access lane 3 in the register as described above!</p>\n<p>To work around <em>that</em> problem, I've implemented a patch that will perform big-endian vector loads by swapping the order of the <em>elements</em>, but not the byte order within any single element.  This will cause lane 0 from memory to end up in lane 3 in the register, and makes <code>extractlane</code> work as expected again.</p>\n<p>With that fix, now <em>both</em> wasmtime and rustc_codegen_cranelift pass all their existing SIMD tests.   Unfortunately, I think this is still not quite a complete solution.</p>\n<hr>\n<p>Specifically, we can now run into two additional problems with big-endian code, which apparently are just never triggered by the existing rustc_codegen_cranelift tests.</p>\n<p>First, I guess it would be possible to re-interpret contents in a vector register in another type even in rustc.   Now, as opposed to wasmtime, rustc uses native endianness, presumably also w.r.t. vector contents.   Therefore, the semantics of such a re-interpretation would be platform-defined and differ between big- and little-endian platforms (which is probably why it's not frequently used).  However, users would expect this platform-specific behavior to be the <em>same</em> between the LLVM and cranelift back ends to rustc - which in the current implementation it would not be.</p>\n<p>Even more problematic, carrying vector elements in reverse order in vector registers actually affects the <em>ABI</em>, as vector types are passed in vector registers.   Code compiled by rustc using the LLVM back end would expect those to be in the \"normal\" platform order, while code compiled by rustc using the cranelift back end would expect them to be the \"reverse\" order.</p>\n<hr>\n<p>One option I'm thinking of would be to actually implement <em>both</em> methods in the cranelift back end.  Specifically, the back end could support both a \"vector big-endian\" and \"vector little-endian\" mode, where the \"big-endian\" mode would use lane numbers directly as defined by our ISA, while the \"little-endian\" mode would use the reverse ordering implemented by the current back end code.</p>\n<p>There's a slight complication in that we might have to support both big- and little-endian vector modes in load and store operations accessing any combination of big- and little-endian memory locations.  But that should be possible:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">mode</span><span class=\"w\">      </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\">    </span><span class=\"n\">load</span><span class=\"o\">/</span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">operation</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">direct</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">element</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">elements</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"mi\">16</span><span class=\"o\">-</span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(Starting with <code>z15</code> we actually can implement each of these operations using a single instruction, so that should also be efficient.)</p>\n<p>The one remaining question is, how to select between the \"vector big-endian\" and \"vector little-endian\" modes?   There are no attributes (like <code>MemFlags</code>) on the <code>extractlane</code> etc. operations, and that wouldn't even make sense: this is a global property, if you used big-endian mode to load the vector you must also use big-endian mode on all subsequent operations.</p>\n<p>So I guess this would have to be some sort of global flag, which wasmtime would set to always little-endian, and rustc would leave at native byte order.   Of course, this flag is actually ABI changing, so the same setting must be used for code to remain link-compatible.  But I think given the above use cases, that should actually be fine.</p>\n<hr>\n<p>FYI @cfallin - this is another problem I ran into while enabling <code>rustc_codegen_cranelift</code>  - I'd appreciate any comments or suggestions!</p>\n</blockquote>",
        "id": 296846449,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662133481
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Currently, <code>s390x</code> is the only big-endian platform supported by cranelift, which has already caused problems related to memory accesses in the past, since wasmtime defines all data in its memory to be in little-endian byte order.</p>\n<p>I had assumed that <em>register</em> contents are not affected by byte order, and while this is true for scalar types, it turns out this is not actually the case for vector registers.  This is because of a combination of two issues:</p>\n<ol>\n<li>There are IR instructions that directly refer to vector register _lanes_ by number; and</li>\n<li>There are IR instructions to re-interpret a vector register as any other vector type, including one with different lane numbers</li>\n</ol>\n<p>The combination of these two makes ISA byte order properties of vector registers visible to IR code, just like byte order in memory is visible via a combination of using memory addresses to access (parts of) a value in memory in a different type than it was stored.</p>\n<p>Specifically, in the Intel (or ARM) little-endian ISA, if you load e.g. a <code>I32X4</code> into a vector register, use <code>raw_bitcast</code> to re-interpret that register as <code>I8X16</code>, and retrieve lane 0 of the resulting value via <code>extractlane</code>, the result will be the <em>least</em>-significant byte of the <code>I32</code> in lane 0 of the original value.   And in fact, wasmtime <em>requires</em> this to be the case.</p>\n<p>On the other hand, on <code>s390x</code> the content of a vector register in <code>I32X4</code> mode will be a sequence of four <code>I32</code>, each in <em>big-endian</em> byte order (or else the arithmetic operations on the register will give wrong results).   Therefore, the same sequence of operations as above will return the <em>most</em>-significant byte of the <code>I32</code> in lane 0.   This actually caused many wasmtime tests to fail.</p>\n<hr>\n<p>To fix this, my current implementation of SIMD instructions on <code>s390x</code> uses a trick combining two different aspects:</p>\n<ul>\n<li>When loading the <code>I32X4</code> from little-endian memory into a vector register, I'm byte-reversing all 16 bytes of the loaded value.  This not only fixes each <code>I32</code> value to be in the correct big-endian order in the register so subsequent arithmetic will work, it <em>also</em> implicitly swaps the order of elements, i.e. the element in slot 0 in memory will end up in what the ISA considers slot 3 of the register etc.</li>\n<li>The implementation of all IR instructions that uses explicit lane numbers will be aware of this renumbering, and implicitly revert it to get back to the lanes the code intends to access, so e.g. using <code>extractlane</code> for lane 0 of a <code>I32X4</code> will actually at the ISA level extract lane 3 of the register.</li>\n</ul>\n<p>The combination of these two aspects makes accessing SIMD registers work correctly for wasmtime.  For example, in the above case, accessing lane 0 of a <code>I8X16</code> is converted to lane 15 of the register, which holds the <em>least</em>-significant byte of the <code>I32</code> in lane 3 of the register, which was loaded from lane 0 in memory -- so in the end we return the least-significant byte of the <code>I32</code> in lane 0 of the original value, as expected by wasmtime.</p>\n<hr>\n<p>However, in implementing support for <code>rustc_codegen_cranelift</code>, I noticed that the current implementation actually breaks when handling <em>big-endian</em> vectors in memory - this will be the case for rustc, since that uses native platform byte order everywhere.  Specifically, when loading a big-endian vector from memory, I'm just loading the bytes unchanged.  This means that e.g. lane 0 of a <code>I32X4</code> in memory ends up in its original byte order (which is OK since this is already big-endian) in lane 0 of the register - but the latter is a problem if subsequent code wants to extract that lane, since an <code>extractlane 0</code> will actually access lane 3 in the register as described above!</p>\n<p>To work around <em>that</em> problem, I've implemented a patch that will perform big-endian vector loads by swapping the order of the <em>elements</em>, but not the byte order within any single element.  This will cause lane 0 from memory to end up in lane 3 in the register, and makes <code>extractlane</code> work as expected again.</p>\n<p>With that fix, now <em>both</em> wasmtime and rustc_codegen_cranelift pass all their existing SIMD tests.   Unfortunately, I think this is still not quite a complete solution.</p>\n<hr>\n<p>Specifically, we can now run into two additional problems with big-endian code, which apparently are just never triggered by the existing rustc_codegen_cranelift tests.</p>\n<p>First, I guess it would be possible to re-interpret contents in a vector register in another type even in rustc.   Now, as opposed to wasmtime, rustc uses native endianness, presumably also w.r.t. vector contents.   Therefore, the semantics of such a re-interpretation would be platform-defined and differ between big- and little-endian platforms (which is probably why it's not frequently used).  However, users would expect this platform-specific behavior to be the <em>same</em> between the LLVM and cranelift back ends to rustc - which in the current implementation it would not be.</p>\n<p>Even more problematic, carrying vector elements in reverse order in vector registers actually affects the <em>ABI</em>, as vector types are passed in vector registers.   Code compiled by rustc using the LLVM back end would expect those to be in the \"normal\" platform order, while code compiled by rustc using the cranelift back end would expect them to be the \"reverse\" order.</p>\n<hr>\n<p>One option I'm thinking of would be to actually implement <em>both</em> methods in the cranelift back end.  Specifically, the back end could support both a \"vector big-endian\" and \"vector little-endian\" mode, where the \"big-endian\" mode would use lane numbers directly as defined by our ISA, while the \"little-endian\" mode would use the reverse ordering implemented by the current back end code.</p>\n<p>There's a slight complication in that we might have to support both big- and little-endian vector modes in load and store operations accessing any combination of big- and little-endian memory locations.  But that should be possible:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">mode</span><span class=\"w\">      </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\">    </span><span class=\"n\">load</span><span class=\"o\">/</span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">operation</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">direct</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">element</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">elements</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"mi\">16</span><span class=\"o\">-</span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(Starting with <code>z15</code> we actually can implement each of these operations using a single instruction, so that should also be efficient.)</p>\n<p>The one remaining question is, how to select between the \"vector big-endian\" and \"vector little-endian\" modes?   There are no attributes (like <code>MemFlags</code>) on the <code>extractlane</code> etc. operations, and that wouldn't even make sense: this is a global property, if you used big-endian mode to load the vector you must also use big-endian mode on all subsequent operations.</p>\n<p>So I guess this would have to be some sort of global flag, which wasmtime would set to always little-endian, and rustc would leave at native byte order.   Of course, this flag is actually ABI changing, so the same setting must be used for code to remain link-compatible.  But I think given the above use cases, that should actually be fine.</p>\n<hr>\n<p>FYI @cfallin - this is another problem I ran into while enabling <code>rustc_codegen_cranelift</code>  - I'd appreciate any comments or suggestions!</p>\n</blockquote>",
        "id": 296846450,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662133481
    },
    {
        "content": "<p>cfallin closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4566\">issue #4566</a>:</p>\n<blockquote>\n<p>Currently, <code>s390x</code> is the only big-endian platform supported by cranelift, which has already caused problems related to memory accesses in the past, since wasmtime defines all data in its memory to be in little-endian byte order.</p>\n<p>I had assumed that <em>register</em> contents are not affected by byte order, and while this is true for scalar types, it turns out this is not actually the case for vector registers.  This is because of a combination of two issues:</p>\n<ol>\n<li>There are IR instructions that directly refer to vector register _lanes_ by number; and</li>\n<li>There are IR instructions to re-interpret a vector register as any other vector type, including one with different lane numbers</li>\n</ol>\n<p>The combination of these two makes ISA byte order properties of vector registers visible to IR code, just like byte order in memory is visible via a combination of using memory addresses to access (parts of) a value in memory in a different type than it was stored.</p>\n<p>Specifically, in the Intel (or ARM) little-endian ISA, if you load e.g. a <code>I32X4</code> into a vector register, use <code>raw_bitcast</code> to re-interpret that register as <code>I8X16</code>, and retrieve lane 0 of the resulting value via <code>extractlane</code>, the result will be the <em>least</em>-significant byte of the <code>I32</code> in lane 0 of the original value.   And in fact, wasmtime <em>requires</em> this to be the case.</p>\n<p>On the other hand, on <code>s390x</code> the content of a vector register in <code>I32X4</code> mode will be a sequence of four <code>I32</code>, each in <em>big-endian</em> byte order (or else the arithmetic operations on the register will give wrong results).   Therefore, the same sequence of operations as above will return the <em>most</em>-significant byte of the <code>I32</code> in lane 0.   This actually caused many wasmtime tests to fail.</p>\n<hr>\n<p>To fix this, my current implementation of SIMD instructions on <code>s390x</code> uses a trick combining two different aspects:</p>\n<ul>\n<li>When loading the <code>I32X4</code> from little-endian memory into a vector register, I'm byte-reversing all 16 bytes of the loaded value.  This not only fixes each <code>I32</code> value to be in the correct big-endian order in the register so subsequent arithmetic will work, it <em>also</em> implicitly swaps the order of elements, i.e. the element in slot 0 in memory will end up in what the ISA considers slot 3 of the register etc.</li>\n<li>The implementation of all IR instructions that uses explicit lane numbers will be aware of this renumbering, and implicitly revert it to get back to the lanes the code intends to access, so e.g. using <code>extractlane</code> for lane 0 of a <code>I32X4</code> will actually at the ISA level extract lane 3 of the register.</li>\n</ul>\n<p>The combination of these two aspects makes accessing SIMD registers work correctly for wasmtime.  For example, in the above case, accessing lane 0 of a <code>I8X16</code> is converted to lane 15 of the register, which holds the <em>least</em>-significant byte of the <code>I32</code> in lane 3 of the register, which was loaded from lane 0 in memory -- so in the end we return the least-significant byte of the <code>I32</code> in lane 0 of the original value, as expected by wasmtime.</p>\n<hr>\n<p>However, in implementing support for <code>rustc_codegen_cranelift</code>, I noticed that the current implementation actually breaks when handling <em>big-endian</em> vectors in memory - this will be the case for rustc, since that uses native platform byte order everywhere.  Specifically, when loading a big-endian vector from memory, I'm just loading the bytes unchanged.  This means that e.g. lane 0 of a <code>I32X4</code> in memory ends up in its original byte order (which is OK since this is already big-endian) in lane 0 of the register - but the latter is a problem if subsequent code wants to extract that lane, since an <code>extractlane 0</code> will actually access lane 3 in the register as described above!</p>\n<p>To work around <em>that</em> problem, I've implemented a patch that will perform big-endian vector loads by swapping the order of the <em>elements</em>, but not the byte order within any single element.  This will cause lane 0 from memory to end up in lane 3 in the register, and makes <code>extractlane</code> work as expected again.</p>\n<p>With that fix, now <em>both</em> wasmtime and rustc_codegen_cranelift pass all their existing SIMD tests.   Unfortunately, I think this is still not quite a complete solution.</p>\n<hr>\n<p>Specifically, we can now run into two additional problems with big-endian code, which apparently are just never triggered by the existing rustc_codegen_cranelift tests.</p>\n<p>First, I guess it would be possible to re-interpret contents in a vector register in another type even in rustc.   Now, as opposed to wasmtime, rustc uses native endianness, presumably also w.r.t. vector contents.   Therefore, the semantics of such a re-interpretation would be platform-defined and differ between big- and little-endian platforms (which is probably why it's not frequently used).  However, users would expect this platform-specific behavior to be the <em>same</em> between the LLVM and cranelift back ends to rustc - which in the current implementation it would not be.</p>\n<p>Even more problematic, carrying vector elements in reverse order in vector registers actually affects the <em>ABI</em>, as vector types are passed in vector registers.   Code compiled by rustc using the LLVM back end would expect those to be in the \"normal\" platform order, while code compiled by rustc using the cranelift back end would expect them to be the \"reverse\" order.</p>\n<hr>\n<p>One option I'm thinking of would be to actually implement <em>both</em> methods in the cranelift back end.  Specifically, the back end could support both a \"vector big-endian\" and \"vector little-endian\" mode, where the \"big-endian\" mode would use lane numbers directly as defined by our ISA, while the \"little-endian\" mode would use the reverse ordering implemented by the current back end code.</p>\n<p>There's a slight complication in that we might have to support both big- and little-endian vector modes in load and store operations accessing any combination of big- and little-endian memory locations.  But that should be possible:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">vector</span><span class=\"w\"> </span><span class=\"n\">mode</span><span class=\"w\">      </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\">    </span><span class=\"n\">load</span><span class=\"o\">/</span><span class=\"n\">store</span><span class=\"w\"> </span><span class=\"n\">operation</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">direct</span><span class=\"w\"></span>\n<span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">       </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">each</span><span class=\"w\"> </span><span class=\"n\">element</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">big</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">           </span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"n\">order</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">elements</span><span class=\"w\"></span>\n<span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">    </span><span class=\"n\">little</span><span class=\"o\">-</span><span class=\"n\">endian</span><span class=\"w\">        </span><span class=\"n\">byte</span><span class=\"o\">-</span><span class=\"n\">reverse</span><span class=\"w\"> </span><span class=\"mi\">16</span><span class=\"o\">-</span><span class=\"n\">byte</span><span class=\"w\"> </span><span class=\"n\">input</span><span class=\"w\"></span>\n</code></pre></div>\n<p>(Starting with <code>z15</code> we actually can implement each of these operations using a single instruction, so that should also be efficient.)</p>\n<p>The one remaining question is, how to select between the \"vector big-endian\" and \"vector little-endian\" modes?   There are no attributes (like <code>MemFlags</code>) on the <code>extractlane</code> etc. operations, and that wouldn't even make sense: this is a global property, if you used big-endian mode to load the vector you must also use big-endian mode on all subsequent operations.</p>\n<p>So I guess this would have to be some sort of global flag, which wasmtime would set to always little-endian, and rustc would leave at native byte order.   Of course, this flag is actually ABI changing, so the same setting must be used for code to remain link-compatible.  But I think given the above use cases, that should actually be fine.</p>\n<hr>\n<p>FYI @cfallin - this is another problem I ran into while enabling <code>rustc_codegen_cranelift</code>  - I'd appreciate any comments or suggestions!</p>\n</blockquote>",
        "id": 308487011,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1667860873
    }
]