[
    {
        "content": "<p>jameysharp opened <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543\">PR #4543</a> from <code>lazy-bitcast</code> to <code>main</code>:</p>\n<blockquote>\n<p>For wasm programs using SIMD vector types, the type known at function<br>\nentry or exit may not match the type used within the body of the<br>\nfunction, so we have to bitcast them. We have to check all calls and<br>\nreturns for this condition, which involves comparing a subset of a<br>\nfunction's signature with the CLIF types we're trying to use. Currently,<br>\nthis check heap-allocates a short-lived Vec for the appropriate subset<br>\nof the signature.</p>\n<p>But most of the time none of the values need a bitcast. So this patch<br>\navoids allocating unless at least one bitcast is actually required, and<br>\nonly saves the pointers to values that need fixing up. I leaned heavily<br>\non iterators to keep space usage constant until we discover allocation<br>\nis necessary after all.</p>\n<p>I don't think it's possible to eliminate the allocation entirely,<br>\nbecause the function signature we're examining is borrowed from the<br>\nFuncBuilder, but we need to mutably borrow the FuncBuilder to insert the<br>\nbitcast instructions. Fortunately, the FromIterator implementation for<br>\nVec doesn't reserve any heap space if the iterator is empty, so we can<br>\nunconditionally collect into a Vec and still avoid unnecessary<br>\nallocations.</p>\n<p>Since the relationship between a function signature and a list of CLIF<br>\nvalues is somewhat complicated, I refactored all the uses of<br>\n<code>bitcast_arguments</code> and <code>wasm_param_types</code>. Instead there's<br>\n<code>bitcast_wasm_params</code> and <code>bitcast_wasm_returns</code> which share a helper<br>\nthat combines the previous pair of functions into one.</p>\n<p>According to DHAT, when compiling the Sightglass Spidermonkey benchmark,<br>\nthis avoids 52k allocations averaging about 9 bytes each, which are<br>\nfreed on average within 2k instructions.</p>\n<p>Most Sightglass benchmarks, including Spidermonkey, show no performance<br>\ndifference with this change. Only one has a slowdown, and it's small:</p>\n<p>compilation :: nanoseconds :: benchmarks/shootout-matrix/benchmark.wasm</p>\n<p>Δ = 689373.34 ± 593720.78 (confidence = 99%)</p>\n<p><a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a> is 0.94x to 1.00x faster than <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a>!<br>\n<a href=\"http://main-e121c209f.so\">main-e121c209f.so</a> is 1.00x to 1.06x faster than <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a>!</p>\n<p>[19741713 21375844.46 32976047] <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a><br>\n  [19345471 20686471.12 30872267] <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a></p>\n<p>But several Sightglass benchmarks have notable speed-ups, with smaller<br>\nimprovements for shootout-ed25519, meshoptimizer, and pulldown-cmark,<br>\nand larger ones as follows:</p>\n<p>compilation :: nanoseconds :: benchmarks/bz2/benchmark.wasm</p>\n<p>Δ = 20071545.47 ± 2950014.92 (confidence = 99%)</p>\n<p><a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a> is 1.26x to 1.36x faster than <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a>!<br>\n<a href=\"http://main-e121c209f.so\">main-e121c209f.so</a> is 0.73x to 0.80x faster than <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a>!</p>\n<p>[55995164 64849257.68 89083031] <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a><br>\n  [79382460 84920803.15 98016185] <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a></p>\n<p>compilation :: nanoseconds :: benchmarks/blake3-scalar/benchmark.wasm</p>\n<p>Δ = 16620780.61 ± 5395162.13 (confidence = 99%)</p>\n<p><a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a> is 1.14x to 1.28x faster than <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a>!<br>\n<a href=\"http://main-e121c209f.so\">main-e121c209f.so</a> is 0.77x to 0.88x faster than <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a>!</p>\n<p>[54604352 79877776.35 103666598] <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a><br>\n  [94011835 96498556.96 106200091] <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a></p>\n<p>compilation :: nanoseconds :: benchmarks/intgemm-simd/benchmark.wasm</p>\n<p>Δ = 36891254.34 ± 12403663.50 (confidence = 99%)</p>\n<p><a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a> is 1.12x to 1.24x faster than <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a>!<br>\n<a href=\"http://main-e121c209f.so\">main-e121c209f.so</a> is 0.79x to 0.90x faster than <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a>!</p>\n<p>[131610845 201289587.88 247341883] <a href=\"http://lazy-bitcast.so\">lazy-bitcast.so</a><br>\n  [232065032 238180842.22 250957563] <a href=\"http://main-e121c209f.so\">main-e121c209f.so</a></p>\n<p>&lt;!--</p>\n<p>Please ensure that the following steps are all taken care of before submitting<br>\nthe PR.</p>\n<ul>\n<li>\n<p>[ ] This has been discussed in issue #..., or if not, please tell us why<br>\n  here.</p>\n</li>\n<li>\n<p>[ ] A short description of what this does, why it is needed; if the<br>\n  description becomes long, the matter should probably be discussed in an issue<br>\n  first.</p>\n</li>\n<li>\n<p>[ ] This PR contains test cases, if meaningful.</p>\n</li>\n<li>[ ] A reviewer from the core maintainer team has been assigned for this PR.<br>\n  If you don't know who could review this, please indicate so. The list of<br>\n  suggested reviewers on the right can help you.</li>\n</ul>\n<p>Please ensure all communication adheres to the <a href=\"https://github.com/bytecodealliance/wasmtime/blob/master/CODE_OF_CONDUCT.md\">code of\nconduct</a>.<br>\n--&gt;<br>\n</p>\n</blockquote>",
        "id": 291107894,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658954778
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931586220\">PR review comment</a>:</p>\n<blockquote>\n<p>Can we split up this iterator chain a bit and give names to intermediates to make it easier to follow? I'm thinking perhaps <code>wasm_param_tys</code> for the first part up to grabbing <code>value_type</code>s; then another intermediate after <code>zip_eq</code>, with a comment that we're zipping with given wasm arg values and asserting length is equal; then do the last two filters on those, commenting that we're taking all vectors whose arg-type is not equal to the param's value type.</p>\n</blockquote>",
        "id": 291111236,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658956455
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931583320\">PR review comment</a>:</p>\n<blockquote>\n<p>Does it help at all to use a <code>SmallVec</code> here, tuned to some size that captures most cases?</p>\n</blockquote>",
        "id": 291111237,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658956455
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053229613\">PR review</a>.</p>",
        "id": 291111239,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658956456
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053229613\">PR review</a>.</p>",
        "id": 291111240,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658956456
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053234725\">PR review</a>.</p>",
        "id": 291111280,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658956477
    },
    {
        "content": "<p>jameysharp created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931596698\">PR review comment</a>:</p>\n<blockquote>\n<p>I thought about using <code>SmallVec</code> but figured first I'd try the experiment that doesn't require any tuning. I'm not sure: how would you suggest picking a size? In the past I've usually picked however many elements will fit in two <code>usize</code>, because that's the minimum size the inline part of a <code>SmallVec</code> will consume anyway. But in this case that's 1, which hardly seems worth doing.</p>\n</blockquote>",
        "id": 291112723,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957275
    },
    {
        "content": "<p>jameysharp submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053247451\">PR review</a>.</p>",
        "id": 291112724,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957276
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053249815\">PR review</a>.</p>",
        "id": 291113055,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957432
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931598423\">PR review comment</a>:</p>\n<blockquote>\n<p>The <code>SmallVec</code> in this case will be on-stack so we can be a bit looser with its size I think (and <code>sub rsp, 128</code> is almost always faster than <code>malloc(128)</code>). For some cases like this I have just picked a reasonable value but to be more objective about it we could try 1, 4, 16 and see what the difference is...</p>\n</blockquote>",
        "id": 291113056,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957433
    },
    {
        "content": "<p>cfallin deleted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931598423\">PR review comment</a>.</p>",
        "id": 291113077,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957449
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053250091\">PR review</a>.</p>",
        "id": 291113084,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957453
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931598621\">PR review comment</a>:</p>\n<blockquote>\n<p>The <code>SmallVec</code> in this case will be on-stack so we can be a bit looser with its size I think (and <code>sub rsp, 128</code> is almost always faster than <code>malloc(128)</code>). For some cases like this I have just picked a reasonable value but to be more objective about it we could try 1, 4, 16 and see what the difference is...</p>\n</blockquote>",
        "id": 291113087,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658957453
    },
    {
        "content": "<p>jameysharp submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053314876\">PR review</a>.</p>",
        "id": 291121629,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658962844
    },
    {
        "content": "<p>jameysharp created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931646511\">PR review comment</a>:</p>\n<blockquote>\n<p>On the intgemm-simd benchmark, Sightglass says plain <code>Vec</code> is 53-73% faster than a size-16 SmallVec, and 8-22% faster than a size-4 SmallVec. I don't understand that result, do you?</p>\n<p>Unless there's a simple explanation I'm not seeing, I'm inclined to not think further about SmallVec right now.</p>\n</blockquote>",
        "id": 291121630,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658962844
    },
    {
        "content": "<p>jameysharp updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543\">PR #4543</a> from <code>lazy-bitcast</code> to <code>main</code>.</p>",
        "id": 291121657,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658962863
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053317306\">PR review</a>.</p>",
        "id": 291122014,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658963097
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931648473\">PR review comment</a>:</p>\n<blockquote>\n<p>That's somewhat surprising, but I can hypothesize at least one potential explanation: if the return value is almost always an empty list, then the empty SmallVec takes more stack space than an empty Vec and hence creates a little more spread in the memory usage (so bad cache effects). I'm stretching a bit with that though.</p>\n<p>Anyway if it's rare enough then a simple <code>Vec</code> is totally fine here; it's certainly better than what we had before!</p>\n</blockquote>",
        "id": 291122016,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658963097
    },
    {
        "content": "<p>jameysharp submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#pullrequestreview-1053336051\">PR review</a>.</p>",
        "id": 291124814,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658965245
    },
    {
        "content": "<p>jameysharp created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543#discussion_r931664073\">PR review comment</a>:</p>\n<blockquote>\n<p>I decided to give size-1 SmallVec a shot too for completeness: if it's a matter of different stack frame sizes, then that should be no worse than Vec. But Vec was 44-58% faster on intgemm-simd than even size-1 SmallVec. So I remain thoroughly puzzled. <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>\n</blockquote>",
        "id": 291124815,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658965245
    },
    {
        "content": "<p>jameysharp merged <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4543\">PR #4543</a>.</p>",
        "id": 291124865,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658965292
    }
]