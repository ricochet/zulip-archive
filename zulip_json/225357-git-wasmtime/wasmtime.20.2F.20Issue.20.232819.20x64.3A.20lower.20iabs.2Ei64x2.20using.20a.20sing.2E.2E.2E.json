[
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-816023604\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>I'm introducing this PR as a draft to solicit opinions about how best to integrate this:</p>\n<ul>\n<li>any preference to switch to a builder pattern (e.g. <code>Evex::new().v128().prefix(...).map(...).reg(...).rm(...).w(true).opcode(0x1F).encode()</code> matching the manual's syntax, EVEX.128.66.0F38.W1 1F /r<code>) over the current </code>encode_evex(...)`?</li>\n<li>a better integration with <code>Inst</code> than <code>XmmUnaryRmREvex { op: Avx512Opcode, ...}</code>? I cannot just add a boolean <code>evex</code> field to <code>XmmUnaryRmR</code> because some AVX512 instructions (e.g. <code>VPABSQ</code>) don't exist so they should not be included in <code>SseOpcode</code>. But the <code>XmmUnaryRmREvex</code> approach is not going to scale to a bunch of other instructions well.</li>\n</ul>\n</blockquote>",
        "id": 233699759,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1617904622
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-816023604\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>I'm introducing this PR as a draft to solicit opinions about how best to integrate this:</p>\n<ul>\n<li>any preference to switch to a builder pattern (e.g. <code>Evex::new().v128().prefix(...).map(...).reg(...).rm(...).w(true).opcode(0x1F).encode()</code> matching the manual's syntax, <code>EVEX.128.66.0F38.W1 1F /r</code>) over the current <code>encode_evex(...)</code>?</li>\n<li>a better integration with <code>Inst</code> than <code>XmmUnaryRmREvex { op: Avx512Opcode, ...}</code>? I cannot just add a boolean <code>evex</code> field to <code>XmmUnaryRmR</code> because some AVX512 instructions (e.g. <code>VPABSQ</code>) don't exist so they should not be included in <code>SseOpcode</code>. But the <code>XmmUnaryRmREvex</code> approach is not going to scale to a bunch of other instructions well.</li>\n</ul>\n</blockquote>",
        "id": 233699878,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1617904658
    },
    {
        "content": "<p>bnjbvr <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-817645488\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<blockquote>\n<p>any preference to switch to a builder pattern (e.g. Evex::new().v128().prefix(...).map(...).reg(...).rm(...).w(true).opcode(0x1F).encode() matching the manual's syntax, EVEX.128.66.0F38.W1 1F /r) over the current encode_evex(...)?</p>\n</blockquote>\n<p>Yeah, this could be nice! If the flags don't have any relationship with each other, it might be possible to pass a <code>&amp;sink</code> to the <code>new()</code> function and encode it as we call the builder functions. Alternatively, deferring it all and building in <code>encode(&amp;sink)</code> sounds good too! And if this works out well, we could refactor a bit the previous encode functions; their API really looks a bit too C-ish.</p>\n<blockquote>\n<p>a better integration with Inst than XmmUnaryRmREvex { op: Avx512Opcode, ...}? I cannot just add a boolean evex field to XmmUnaryRmR because some AVX512 instructions (e.g. VPABSQ) don't exist so they should not be included in SseOpcode. But the XmmUnaryRmREvex approach is not going to scale to a bunch of other instructions well.</p>\n</blockquote>\n<p>Why wouldn't this scale well, out of curiosity? In general I think we should tend to APIs that make it impossible to create invalid instructions. It might not be the case for existing APIs, which should be refactored ideally...</p>\n</blockquote>",
        "id": 234128148,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618219459
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-818979722\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>@bnjbvr, the latest commit moves to the builder pattern. It's a hybrid of your idea: the EVEX 4-byte prefix is built up as the builder methods are called but we still need to call <code>.encode(sink)</code> to emit later because some methods, e.g. <code>.reg(...)</code>, modify both the prefix and the ModR/M byte, which are emitted at completely different times.</p>\n<p>Being a bit paranoid about performance, I benchmarked the <code>encode_evex</code> function approach and the current <code>EvexInstruction</code> builder approach by encoding the same instruction repeatedly inside bencher. For some reason, the builder approach turns out to be faster:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_function</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:          <span class=\"mi\">17</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"></span>\n<span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_builder</span><span class=\"w\">  </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:           <span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"></span>\n</code></pre></div>\n<p>I didn't dig too deep into this since @cfallin mentioned that emission is hardly the long pole in the tent. I was happy enough that this builder approach was not slower and left it at that. I think this is ok to review and merge understanding that there are still pieces coming (e.g. this only supports reg-reg addressing).</p>\n<blockquote>\n<p>Why wouldn't this scale well, out of curiosity?</p>\n</blockquote>\n<p>I mean mental scaling, not codegen performance or anything like that (some of us operate on limited brain RAM). Finding the right <code>Inst</code> variant when adding a new instruction can be tricky: \"so this is unary, right, so I'm going to use that... no wait, I need to use the Xmm form... no, hold on, this is AVX512 so I need to find the Evex form of that.\" It's a developer experience thing more than anything. I agree that we should restrict the inputs somehow to only generate valid instructions but this \"which Inst variant?\" question seems a bit different.</p>\n</blockquote>",
        "id": 234381687,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618340306
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-818979722\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>@bnjbvr, the latest commit moves to the builder pattern. It's a hybrid of your idea: the EVEX 4-byte prefix is built up as the builder methods are called but we still need to call <code>.encode(sink)</code> to emit later because some methods, e.g. <code>.reg(...)</code>, modify both the prefix and the ModR/M byte, which are emitted at different times.</p>\n<p>Being a bit paranoid about performance, I benchmarked the <code>encode_evex</code> function approach against the <code>EvexInstruction</code> builder approach by encoding the same instruction repeatedly inside bencher. For some reason, the builder approach turns out to be faster:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_function</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:          <span class=\"mi\">17</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"></span>\n<span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_builder</span><span class=\"w\">  </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:           <span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"></span>\n</code></pre></div>\n<p>I didn't dig too deep into this since @cfallin mentioned that emission is hardly the long pole in the tent. I was happy enough that this builder approach was not slower and left it at that. I think this is ok to review and merge understanding that there are still pieces coming (e.g. this only supports reg-reg addressing).</p>\n<blockquote>\n<p>Why wouldn't this scale well, out of curiosity?</p>\n</blockquote>\n<p>I mean mental scaling, not codegen performance or anything like that (some of us operate on limited brain RAM). Finding the right <code>Inst</code> variant when adding a new instruction can be tricky: \"so this is unary, right, so I'm going to use that... no wait, I need to use the Xmm form... no, hold on, this is AVX512 so I need to find the Evex form of that.\" It's a developer experience thing more than anything. I agree that we should restrict the inputs somehow to only generate valid instructions but this \"which Inst variant?\" question seems a bit different.</p>\n</blockquote>",
        "id": 234381800,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618340357
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-818979722\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>@bnjbvr, the latest commit moves to the builder pattern. It's a hybrid of your idea: the EVEX 4-byte prefix is built up as the builder methods are called but we still need to call <code>.encode(sink)</code> to emit later because some methods, e.g. <code>.reg(...)</code>, modify both the prefix and the ModR/M byte, which are emitted at different times.</p>\n<p>Being a bit paranoid about performance, I benchmarked the <code>encode_evex</code> function approach against the <code>EvexInstruction</code> builder approach by encoding the same instruction repeatedly inside bencher. For some reason, the builder approach turns out to be faster:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_function</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:          <span class=\"mi\">17</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"></span>\n<span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">isa</span>::<span class=\"n\">x64</span>::<span class=\"n\">inst</span>::<span class=\"n\">encoding</span>::<span class=\"n\">evex</span>::<span class=\"n\">tests</span>::<span class=\"n\">encode_with_builder</span><span class=\"w\">  </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"n\">bench</span>:           <span class=\"mi\">6</span><span class=\"w\"> </span><span class=\"n\">ns</span><span class=\"o\">/</span><span class=\"n\">iter</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"o\">+/-</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">)</span><span class=\"w\"></span>\n</code></pre></div>\n<p>I didn't dig too deep into this since @cfallin mentioned that emission is hardly the long pole in the tent. I was happy enough that this builder approach was not slower and left it at that. I think this is OK to review and merge understanding that there are still pieces coming (e.g. this only supports reg-reg addressing).</p>\n<blockquote>\n<p>Why wouldn't this scale well, out of curiosity?</p>\n</blockquote>\n<p>I mean mental scaling, not codegen performance or anything like that (some of us operate on limited brain RAM). Finding the right <code>Inst</code> variant when adding a new instruction can be tricky: \"so this is unary, right, so I'm going to use that... no wait, I need to use the Xmm form... no, hold on, this is AVX512 so I need to find the Evex form of that.\" It's a developer experience thing more than anything. I agree that we should restrict the inputs somehow to only generate valid instructions but this \"which Inst variant?\" question seems a bit different.</p>\n</blockquote>",
        "id": 234381871,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618340396
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-819638249\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<p>@bnjbvr, can you take another look at this when you get a chance?</p>\n</blockquote>",
        "id": 234527731,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618416591
    },
    {
        "content": "<p>bnjbvr <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819#issuecomment-819645346\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2819\">Issue #2819</a>:</p>\n<blockquote>\n<blockquote>\n<p>@bnjbvr, can you take another look at this when you get a chance?</p>\n</blockquote>\n<p>Yep, happy to take a look in the next few days!</p>\n</blockquote>",
        "id": 234529463,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1618417220
    }
]