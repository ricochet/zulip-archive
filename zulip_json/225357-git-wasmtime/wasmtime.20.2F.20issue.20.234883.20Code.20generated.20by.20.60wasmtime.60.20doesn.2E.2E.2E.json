[
    {
        "content": "<p>koute opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 297725227,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662623647
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883#issuecomment-1240944137\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<p>Thanks for tracking this down, @koute! Yes, I agree that aligning loop headers to cache-line boundaries makes sense. Probably as a compile-time option, when opts are enabled (debug code is going to be substantially more bloated for other reasons so we don't want to inflate further, and is going to be slow anyway).</p>\n</blockquote>",
        "id": 297818733,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662654371
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883#issuecomment-1241003183\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<p>This might be a good starter issue for someone to tackle. The main steps I see this taking are:</p>\n<ul>\n<li>Convey a notion of \"loop header block\" to lowered blocks in the VCode. This information can be obtained from the loop analysis, or perhaps more simply and with less overhead, by detecting backedges (branch from higher-index block to lower-index block) when lowering code and marking the target as a header. (The latter is precise for reducible control flow and approximate but pretty good for irreducible control flow.) This would probably best be done somewhere around <a href=\"https://github.com/bytecodealliance/wasmtime/blob/13c78468159033c637323801d2dc09460bbd71e2/cranelift/codegen/src/machinst/lower.rs#L906\">here</a> and could insert the block index into a set held by the VCode.</li>\n<li>When we reach a loop header block in <code>VCode::emit</code>, use the stricter loop-header alignment (64 bytes probably?) <a href=\"https://github.com/bytecodealliance/wasmtime/blob/13c78468159033c637323801d2dc09460bbd71e2/cranelift/codegen/src/machinst/vcode.rs#L852-L857\">here</a> rather than the default basic-block alignment, which is 1 byte on x86-64.</li>\n</ul>\n<p>If no one else wants to take it, I can do this at some point but I thought I would put this out there first!</p>\n</blockquote>",
        "id": 297829125,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662657687
    },
    {
        "content": "<p>cfallin labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 297829161,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662657700
    },
    {
        "content": "<p>cfallin labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 297829191,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662657710
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 298347070,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662976078
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 298347071,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662976078
    },
    {
        "content": "<p>akirilov-arm labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4883\">issue #4883</a>:</p>\n<blockquote>\n<h2>The problem</h2>\n<p>Currently <code>wasmtime</code>/<code>cranelift</code> (unlike e.g. LLVM which doesn't have this problem AFAIK) doesn't cache-align the loops it generates, leading to potentially huge performance regressions if a hot loop ends up accidentally spanning over multiple cache lines.</p>\n<h2>Background</h2>\n<p>Recently we were updating from <code>wasmtime</code> 0.38 to 0.40 and we saw a peculiar performance regression when doing so. One of our benchmarks took almost 2x the time to run, with a lot of them taking around ~45% more time. A huge regression. Ultimately it ended up being unrelated to the 0.38 -&gt; 0.40 upgrade. We tracked the problem down to <code>memset</code> within the WASM (we're currently not using the bulk memory ops extension) suddenly taking a lot more time to run for no apparent reason. Depending on which exact address <code>wasmtime</code> decided to generate the code for <code>memset</code> at (which is essentially random, although consistent for the same code with the same flags in the same environment) the benchmarks were either slow, or fast, and it all boiled down to whether the hot loop of the <code>memset</code> spanned multiple cache lines or not.</p>\n<p>You can find a detailed analysis of the problem in <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1238225600\">this comment</a> and <a href=\"https://github.com/paritytech/substrate/pull/12096#issuecomment-1239560799\">this comment</a> of mine.</p>\n</blockquote>",
        "id": 298347072,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662976078
    }
]