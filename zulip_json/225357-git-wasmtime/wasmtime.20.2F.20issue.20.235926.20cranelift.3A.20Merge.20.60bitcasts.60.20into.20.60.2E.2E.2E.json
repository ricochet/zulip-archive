[
    {
        "content": "<p>afonso360 <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926#issuecomment-1458140725\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926\">issue #5926</a>:</p>\n<blockquote>\n<p>That is unfortunate <span aria-label=\"oh no\" class=\"emoji emoji-1f615\" role=\"img\" title=\"oh no\">:oh_no:</span> . And yeah, It looks like egraphs is not the right place to do it (for now!).</p>\n<blockquote>\n<p>The new load must be placed at the same point in the side-effecting skeleton as the original, or we could be changing where traps are detected. We don't have any way to guarantee that in egraph rules right now.</p>\n</blockquote>\n<blockquote>\n<p>It's only an improvement if all users of the value want the bitcasted type. If any want the original type then you'd need to insert a bitcast in the other direction, or worse, keep both loads. We can't tell in the egraph whether a value is used until the elaboration step at the end, which I think is too late for this.</p>\n</blockquote>\n<p>Oh yeah! I was sort of expecting that it wouldn't perform the rewrite if there was more than one user for the load, doing the load twice doesn't seem like a great option.</p>\n<p>I think we can keep all those constraints if we do this via <code>simple_preopt</code> (maybe, I haven't thought a lot about this!). But I think it would be nice to have some numbers on how much this affects perf before adding more stuff there.</p>\n<p>Thank you guys for looking at this though!</p>\n</blockquote>",
        "id": 340104604,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1678194457
    },
    {
        "content": "<p>afonso360 edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926#issuecomment-1458140725\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926\">issue #5926</a>:</p>\n<blockquote>\n<p>That is unfortunate <span aria-label=\"oh no\" class=\"emoji emoji-1f615\" role=\"img\" title=\"oh no\">:oh_no:</span> . And yeah, It looks like egraphs is not the right place to do it (for now!).</p>\n<blockquote>\n<p>The new load must be placed at the same point in the side-effecting skeleton as the original, or we could be changing where traps are detected. We don't have any way to guarantee that in egraph rules right now.</p>\n</blockquote>\n<blockquote>\n<p>It's only an improvement if all users of the value want the bitcasted type. If any want the original type then you'd need to insert a bitcast in the other direction, or worse, keep both loads. We can't tell in the egraph whether a value is used until the elaboration step at the end, which I think is too late for this.</p>\n</blockquote>\n<p>Oh yeah! I was sort of expecting that it wouldn't perform the rewrite if there was more than one user for the load, doing the load twice doesn't seem like a great option.</p>\n<p>I think we can keep all those constraints if we do this via <code>simple_preopt</code> (Maybe. I haven't thought a lot about this!). But I think it would be nice to have some numbers on how much this affects perf before adding more stuff there.</p>\n<p>Thank you guys for looking at this though!</p>\n</blockquote>",
        "id": 340137680,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1678202588
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926#issuecomment-1458589180\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926\">issue #5926</a>:</p>\n<blockquote>\n<p>I'm curious whether the backends can do this optimization, if it's just about load-sinking. I'm not sure what it would take to get the load-sinking machinery to \"see through\" bitcasts.</p>\n<p>I think the most general bitcast optimizations would be target-specific anyway. Something like, if both types are stored in the same register class, then the lowering for bitcast can just return the input register. I'm not sure how endianness interacts with that and I've probably missed other important details, but maybe there's something easy to try in there.</p>\n</blockquote>",
        "id": 340173966,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1678211517
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926#issuecomment-1458635763\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/5926\">issue #5926</a>:</p>\n<blockquote>\n<blockquote>\n<p>I'm curious whether the backends can do this optimization, if it's just about load-sinking. I'm not sure what it would take to get the load-sinking machinery to \"see through\" bitcasts.</p>\n</blockquote>\n<p>We could possibly do the same thing that we do on conditional branches with the <code>maybe_uextend</code> extractor: basically, build a little helper manually to do that \"seeing through\". It seems like a pretty reasonable manageable (i.e., not too high) level of complexity to me, vs. trying to reason about the combination in the mid-end.</p>\n</blockquote>",
        "id": 340182484,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1678213727
    }
]