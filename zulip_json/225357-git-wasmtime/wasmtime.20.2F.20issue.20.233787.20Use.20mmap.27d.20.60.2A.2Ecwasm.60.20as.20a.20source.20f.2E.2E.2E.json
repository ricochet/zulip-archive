[
    {
        "content": "<p>github-actions[bot] <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1034504616\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<h4>Subscribe to Label Action</h4>\n<p>cc @peterhuene</p>\n<p>&lt;details&gt;<br>\nThis issue or pull request has been labeled: \"wasmtime:api\"</p>\n<p>Thus the following users have been cc'd because of the following labels:</p>\n<ul>\n<li>peterhuene: wasmtime:api</li>\n</ul>\n<p>To subscribe or unsubscribe from this label, edit the &lt;code&gt;.github/subscribe-to-label.json&lt;/code&gt; configuration file.</p>\n<p><a href=\"https://github.com/bytecodealliance/subscribe-to-label-action\">Learn more.</a><br>\n&lt;/details&gt;</p>\n</blockquote>",
        "id": 271387505,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644470456
    },
    {
        "content": "<p>tschneidereit <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1034733947\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<blockquote>\n<p>A very conservative answer to the above risk would be a new Module constructor that is something like Module::map_file_direct(File), and then explicitly avoid the direct-mmap for the existing API that just takes a filename -- though I'm ambivalent about that as it would mean perf benefits are hidden in a non-default place that the average user might not find either.</p>\n</blockquote>\n<p>Given that as you say this already is a bad idea, I think the downside you point out here weighs heavy. Is there any kind of actual safety downside to this relative to the current situation? If not, then we should either make the current behavior safer by default, or continue making use of the benefits we get from this approach. (I also think that it's fine to assume continued existence of files like this, with the argument being \"don't shared libraries work this way, too\" or something similarly handwavy in that direction.)</p>\n</blockquote>",
        "id": 271410254,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644487975
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035093729\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<p>For performance numbers I actually naively assumed it wouldn't really matter here. I don't think our microbenchmarks will really show much today though since it's all just hitting the kernel's page cache. I don't know enough about mmap performance from files to know whether this is what we'd continue to see out in the wild though.</p>\n<p>What I got though for \"instantiate large module\" is below. In this benchmark it was purely instantiation so only setting up vma mappings and not actually doing anything with them:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">parallel</span><span class=\"o\">/</span><span class=\"n\">pooling</span><span class=\"o\">/</span><span class=\"n\">rustpython</span><span class=\"p\">.</span><span class=\"n\">wasm</span>: <span class=\"nc\">with</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"n\">thread</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"n\">time</span>:   <span class=\"p\">[</span><span class=\"mf\">5.1166</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"w\"> </span><span class=\"mf\">5.1196</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"w\"> </span><span class=\"mf\">5.1226</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"p\">]</span><span class=\"w\"></span>\n\n<span class=\"n\">parallel</span><span class=\"o\">/</span><span class=\"n\">pooling</span><span class=\"o\">/</span><span class=\"n\">rustpython</span><span class=\"p\">.</span><span class=\"n\">wasm</span>: <span class=\"nc\">with</span><span class=\"w\"> </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"n\">thread</span><span class=\"w\"> </span><span class=\"p\">(</span><span class=\"n\">loaded</span><span class=\"w\"> </span><span class=\"n\">from</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"p\">.</span><span class=\"n\">cwasm</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"n\">time</span>:   <span class=\"p\">[</span><span class=\"mf\">5.0117</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"w\"> </span><span class=\"mf\">5.0143</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"w\"> </span><span class=\"mf\">5.0170</span><span class=\"w\"> </span><span class=\"n\">us</span><span class=\"p\">]</span><span class=\"w\"></span>\n<span class=\"err\">````</span><span class=\"w\"></span>\n\n<span class=\"n\">I</span><span class=\"w\"> </span><span class=\"n\">then</span><span class=\"w\"> </span><span class=\"n\">modified</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">benchmark</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">write</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">from</span><span class=\"w\"> </span><span class=\"n\">Rust</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">every</span><span class=\"w\"> </span><span class=\"n\">single</span><span class=\"w\"> </span><span class=\"n\">page</span><span class=\"w\"> </span><span class=\"n\">of</span><span class=\"w\"> </span><span class=\"n\">memory</span><span class=\"w\"> </span><span class=\"n\">after</span><span class=\"w\"> </span><span class=\"n\">instantiation</span><span class=\"w\"> </span><span class=\"n\">succeeded</span><span class=\"w\"> </span><span class=\"n\">and</span><span class=\"w\"> </span><span class=\"n\">I</span><span class=\"w\"> </span><span class=\"n\">got</span>:\n</code></pre></div>\n<p>parallel/pooling/rustpython.wasm: with 1 thread<br>\n                        time:   [4.0414 ms 4.0418 ms 4.0422 ms]</p>\n<p>parallel/pooling/rustpython.wasm: with 1 thread (loaded from *.cwasm)<br>\n                        time:   [4.0682 ms 4.0686 ms 4.0690 ms]</p>\n<p><div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">Running</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"n\">few</span><span class=\"w\"> </span><span class=\"n\">times</span><span class=\"w\"> </span><span class=\"n\">this</span><span class=\"w\"> </span><span class=\"n\">seemed</span><span class=\"w\"> </span><span class=\"n\">consistent</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">although</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"s\">\"load all the pages\"</span><span class=\"w\"> </span><span class=\"n\">had</span><span class=\"w\"> </span><span class=\"n\">some</span><span class=\"w\"> </span><span class=\"n\">variance</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">time</span><span class=\"w\"> </span><span class=\"n\">to</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">point</span><span class=\"w\"> </span><span class=\"n\">that</span><span class=\"w\"> </span><span class=\"n\">I</span><span class=\"w\"> </span><span class=\"n\">think</span><span class=\"w\"> </span><span class=\"n\">they</span><span class=\"w\"> </span><span class=\"n\">were</span><span class=\"w\"> </span><span class=\"n\">roughly</span><span class=\"w\"> </span><span class=\"n\">equivalent</span><span class=\"p\">.</span><span class=\"w\"></span>\n\n<span class=\"n\">The</span><span class=\"w\"> </span><span class=\"n\">full</span><span class=\"w\"> </span><span class=\"n\">diff</span><span class=\"w\"> </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">the</span><span class=\"w\"> </span><span class=\"n\">benchmark</span><span class=\"w\"> </span><span class=\"n\">was</span><span class=\"w\"> </span><span class=\"n\">https</span>:<span class=\"c1\">//gist.github.com/alexcrichton/7e555a405f2815ec69fcac659b5d85de and the first numbers were collected without the changes to the `instantiate` function which write to memory.</span>\n<span class=\"o\">~~~</span><span class=\"w\"></span>\n</code></pre></div><br>\n</p>\n</blockquote>",
        "id": 271452072,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644508840
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035095472\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<p>In terms of safety, <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Module.html#method.deserialize_file\"><code>Module::deserialize_file</code></a> is already <code>unsafe</code> because loading arbitrary data is not memory safe, so adding to the list of requirements \"this needs to stay as-expected for the entire duration of the lifetime of the <code>Module</code> doesn't seem so bad to add. I don't think it makes the safety any worse relative to what we have today?</p>\n</blockquote>",
        "id": 271452340,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644508923
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035145355\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<p>Hm something I just thought of, I know that on Linux you can't write to an executable that's currently in use in some other process, which is exactly what we want here. I found that <code>MAP_DENYWRITE</code> seems like it would do this as an option to mmap but the man page says that it's an ignored flag nowadays due to denial-of-service attacks (I guess it lets you just exclusively lock files for yourself against everyone else's will). Do others know how we could get this behavior, though? That might help the prevent-future-writes problem a bit.</p>\n</blockquote>",
        "id": 271458285,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644511388
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035208873\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<blockquote>\n<p>In terms of safety, <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Module.html#method.deserialize_file\"><code>Module::deserialize_file</code></a> is already <code>unsafe</code> because loading arbitrary data is not memory safe, so adding to the list of requirements \"this needs to stay as-expected for the entire duration of the lifetime of the <code>Module</code> doesn't seem so bad to add. I don't think it makes the safety any worse relative to what we have today?</p>\n</blockquote>\n<p>Yup, that sounds like the right path to me; the risk was already there, it's just good to warn about it now :-)</p>\n<p>Re: benchmarking -- a thought occurred to me: this is mostly improving module-load performance, so it would be interesting to benchmark module loading! Perhaps a measured inner loop of (module load, instantiate, terminate). In theory, with a module that has a very large heap (ahem SpiderMonkey), we should see load times that are O(heap size) without this PR, and O(1)-ish with this PR.</p>\n<p>The above isn't really necessary to get this in I think -- with no negative impacts to instantiation or pagefault cost during runtime, and with the RSS benefit, I'm already convinced it's a good thing; but it would be a good way to demonstrate the benefit if you want to do that.</p>\n</blockquote>",
        "id": 271465238,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644514277
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035224024\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<blockquote>\n<p>Hm something I just thought of, I know that on Linux you can't write to an executable that's currently in use in some other process, which is exactly what we want here. I found that <code>MAP_DENYWRITE</code> seems like it would do this as an option to mmap but the man page says that it's an ignored flag nowadays due to denial-of-service attacks (I guess it lets you just exclusively lock files for yourself against everyone else's will). Do others know how we could get this behavior, though? That might help the prevent-future-writes problem a bit.</p>\n</blockquote>\n<p>This sent me down a very interesting rabbithole -- apparently, until recently, <code>MAP_DENYWRITE</code> did work. Indeed if I strace <code>/bin/ls</code> on my system I see the flag included in the mmaps of system libraries. A quick test shows that while one binary executes on my system, I get ETXTBSY when trying to open the file <code>O_RDWR</code> from another process. (Superficially one can \"write\" it by copying over it or editing with a text editor, but this really just replaces the directory entry, and doesn't open the existing file for writing.)</p>\n<p>But it seems that MAP_DENYWRITE is <a href=\"https://lwn.net/Articles/866493/\">going away</a> -- was removed from the kernel last August -- and so this same issue, if it is one, will exist for system binaries/libraries too.</p>\n<p>So just the warning and the fact that the API is <code>unsafe</code> seems enough to me at least!</p>\n</blockquote>",
        "id": 271466964,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644515034
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035408901\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<blockquote>\n<p>a thought occurred to me: this is mostly improving module-load performance, so it would be interesting to benchmark module loading</p>\n</blockquote>\n<p>This is a great idea and something I forgot! I was inspired to write this up in a benchmark from this -- <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3790\">https://github.com/bytecodealliance/wasmtime/pull/3790</a>. My first attempt at benchmarking this showed no improvement from this PR but I was alarmed at the relatively slow deserialize time, which spawned <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3789\">https://github.com/bytecodealliance/wasmtime/pull/3789</a>. Upon further thought though I remembered that memfd creation is lazy and consequently not affected by what I was benchmarking (purely deserialization, not deserialization plus instantiation). </p>\n<p>I then updated the existing code to more eagerly construct the memfd, and that regressed relative to this PR by ~10x, with most of the time spent in <code>write</code> and <code>memcpy</code> (movment from data segments to the image). So it looks like this can definitely help improve first-instantiate time and we can probably make memfd creation un-lazy after this.</p>\n<hr>\n<p>Anyway I will get to the rest of the review in a moment now...</p>\n</blockquote>",
        "id": 271483819,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644522128
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787#issuecomment-1035523285\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3787\">issue #3787</a>:</p>\n<blockquote>\n<blockquote>\n<p>I then updated the existing code to more eagerly construct the memfd, and that regressed relative to this PR by ~10x, with most of the time spent in <code>write</code> and <code>memcpy</code> (movment from data segments to the image). So it looks like this can definitely help improve first-instantiate time and we can probably make memfd creation un-lazy after this.</p>\n</blockquote>\n<p>This is great! And yeah, I agree, given that the memfd state is now cheap to create on load (a wrapper around the <code>Arc&lt;File&gt;</code> with some metadata basically) there's no reason for it to be lazy anymore.</p>\n</blockquote>",
        "id": 271495066,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1644527575
    }
]