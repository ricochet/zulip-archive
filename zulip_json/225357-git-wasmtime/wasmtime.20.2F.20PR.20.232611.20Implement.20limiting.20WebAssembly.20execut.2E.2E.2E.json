[
    {
        "content": "<p>alexcrichton opened <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224258425,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611786777
    },
    {
        "content": "<p><strong>alexcrichton</strong> requested <a href=\"https://github.com/cfallin\">cfallin</a> for a review on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a>.</p>",
        "id": 224258588,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611786862
    },
    {
        "content": "<p>alexcrichton updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224259512,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611787447
    },
    {
        "content": "<p>fitzgen submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-577878992\">PR Review</a>.</p>",
        "id": 224268195,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611792896
    },
    {
        "content": "<p>fitzgen created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r565726520\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Maybe worth noting somewhere around here that, for the purposes of fuel, we don't care about (implicit) branches due to traps in the middle of a block?</p>\n</blockquote>",
        "id": 224268196,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611792896
    },
    {
        "content": "<p>fitzgen submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-577878992\">PR Review</a>.</p>",
        "id": 224268197,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611792896
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-577874372\">PR Review</a>.</p>",
        "id": 224268365,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611793013
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-577874372\">PR Review</a>.</p>",
        "id": 224268366,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611793013
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r565722540\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Is there any reason we can't add to the existing <code>fuel_adj</code> value here, in order to continue accumulating the consumed-fuel count and return the true total from <code>fuel_consumed()</code>?</p>\n<p>(In that case I might also call this <code>add_fuel()</code>, and adjust existing rather than overwrite the fuel-consumed counter...)</p>\n</blockquote>",
        "id": 224268368,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611793014
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r565730365\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Can you say more about the expected way to run this in an executor-loop system with timeslicing (as in Lucet's fuel implementation)?</p>\n<p>Specifically, is the common case that we'll run for a timeslice and then unwind here using the trap mechanism back to the Wasm entry point, at which point some higher-level wrapper might yield a future or similar?</p>\n<p>My two concerns are:</p>\n<ul>\n<li>Efficiency: invoking the unwind mechanism and heap-allocating an error is somewhat heavyweight;</li>\n<li>Ability to resume: it looks like <code>raise_lib_trap</code> eventually invokes <code>Unwind</code> in wasmtime-runtime's helpers.c, which uses longjmp to escape the Wasm stack frames. Does this mean that we can't resume at the point where fuel was exhausted (i.e., it's a terminating trap rather than a resumable one)?</li>\n</ul>\n<p>All of my concerns above go away if we have a way to plug in a custom out-of-gas handler; I couldn't find an API that would let one do this (one would need to pass in a custom <code>TrapInfo</code> trait impl I think?) though I may have missed it. Or alternately, is the more complete interface coming with later async work?</p>\n</blockquote>",
        "id": 224268369,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611793014
    },
    {
        "content": "<p>alexcrichton submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578437026\">PR Review</a>.</p>",
        "id": 224339877,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611846947
    },
    {
        "content": "<p>alexcrichton created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566172854\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Oh sure yeah, the \"raise a trap\" implementation here is primarily just so we can test it in this PR without all the async bits landed yet. Additionally it helps us fuzz the implementation well by ensuring wasm is always consuming fuel when executing. For an async yield-every-so-often implementation my plan is to:</p>\n<ul>\n<li>Still have this bake into a <code>Store</code> without the ability to register a custom handler (although that's still possible, but fraught with correctness issues on the caller's part)</li>\n<li>Instead of raising a trap here this would simply switch off the fiber. With async we are guaranteed that all wasm is always executing on a fiber, so this is possible.</li>\n<li>The <code>Store</code> would have some sort of flag/configuration where in async mode you could request that N fuel is used up and when finished it yields to the current future and then injects N more fuel when it comes back.</li>\n</ul>\n<p>The implementation would be relatively simple, basically <a href=\"https://github.com/bytecodealliance/wasmtime/blob/64ab442767789571b69a49caacf6aae2967664f6/crates/wasmtime/src/store.rs#L532-L534\">calling suspend</a> here aftter notifying ourselves to the future executor saying we're already ready for another <code>poll</code>. I would imagine that this would all be guarded by a basic <code>if</code> in this out-of-gas handler which either traps or yields.</p>\n<p>Efficiency-wise I think it should be quite fast because it's a fiber switch and no unwinding happens (not even longjmp). Upon resumption we'd simply return from this function and wasm would keep going. Resumption-wise we should be good as well due to fibers and whatnot. Basically the trap stuff won't happen at for the timeslicing, it's just a way for me to land this PR before the async fiddly bits are here.</p>\n</blockquote>",
        "id": 224339879,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611846947
    },
    {
        "content": "<p>alexcrichton submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578438062\">PR Review</a>.</p>",
        "id": 224340050,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611847006
    },
    {
        "content": "<p>alexcrichton created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566173592\">PR Review Comment</a>:</p>\n<blockquote>\n<p>I was a tiny bit worried that a long-lived store might overflow the <code>i64</code> counter but that may not be too realistic. Do you think that'd be rare enough that we should just switch this to an add instead of a set?</p>\n</blockquote>",
        "id": 224340051,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611847006
    },
    {
        "content": "<p>alexcrichton submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578438690\">PR Review</a>.</p>",
        "id": 224340127,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611847044
    },
    {
        "content": "<p>alexcrichton created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566174086\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Ah indeed, good point!</p>\n</blockquote>",
        "id": 224340129,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611847044
    },
    {
        "content": "<p>alexcrichton updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224340815,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611847336
    },
    {
        "content": "<p>alexcrichton updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224374288,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611859931
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578649697\">PR Review</a>.</p>",
        "id": 224375794,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611860510
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566336666\">PR Review Comment</a>:</p>\n<blockquote>\n<p>IMHO it's nicer to not have the \"fuel-used value that we return is only since the last set\" property -- it has the potential to become a subtle stats bug later.</p>\n<p>Doing some quick math, a 2^63 max count, at 1B Wasm ops per second, gives us 2^33 or 8B seconds of runtime before overflow, which is ~250 years. Sometime before the year 2270 we can come back and upgrade to an <code>i128</code> :-)</p>\n</blockquote>",
        "id": 224375795,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611860510
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578651161\">PR Review</a>.</p>",
        "id": 224376057,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611860628
    },
    {
        "content": "<p>cfallin created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566337752\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Makes sense! Happy to see this go in as-is, then.</p>\n</blockquote>",
        "id": 224376058,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611860628
    },
    {
        "content": "<p>alexcrichton updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224396994,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611870385
    },
    {
        "content": "<p>alexcrichton submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578767746\">PR Review</a>.</p>",
        "id": 224397011,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611870404
    },
    {
        "content": "<p>alexcrichton created <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#discussion_r566428622\">PR Review Comment</a>:</p>\n<blockquote>\n<p>Heh good point!</p>\n</blockquote>",
        "id": 224397012,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611870404
    },
    {
        "content": "<p>cfallin submitted <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611#pullrequestreview-578773701\">PR Review</a>.</p>",
        "id": 224397912,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611870916
    },
    {
        "content": "<p>alexcrichton updated <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a> from <code>fuel</code> to <code>main</code>:</p>\n<blockquote>\n<p>This PR lifts a feature from Lucet to wasmtime where generated code can count instructions or account for \"fuel\" during execution. The purpose of this feature is similar to the interrupt support via <code>InterruptHandle</code>, but it mainly allows deterministically interrupting a wasm module instead of relying on a timer. Additionally a future goal of this PR is to extend the <code>async</code> support of wasmtime to leverage fuel to periodically \"interrupt\" executing wasm code to yield back to the host. This would enable wasmtime futures to never take \"too long\" in <code>Future::poll</code> since if they would otherwise take awhile they'd yield back to the host and allow preemption and/or other things like future timeouts.</p>\n<p>Thee implementation here is nearly copied verbatim from Lucet itself, with tweaks as appropriate for the different vmctx representation in Wasmtime. The main difference is that Wasmtime's fuel counter is two levels of indirection away from the vmctx rather than one in Lucet. To help with this a new <code>Variable</code> stores the <code>VMInterrupts</code> pointer value to avoid reloading the same value each time from the vmctx.</p>\n<p>Support for this feature is exposed through a few new APIs:</p>\n<ul>\n<li><code>Config::consume_fuel</code> - enables codegen options for wasm to consume fuel, and behaves similar to <code>interruptable</code>.</li>\n<li><code>Store::set_fuel_remaining</code> - this is how fuel is injected into a <code>Store</code> for execution of wasm. Note that stores always start with 0 fuel so this is required to be called.</li>\n<li><code>Store::fuel_consumed</code> - this can be used to check how much fuel has been consumed so far.</li>\n</ul>\n<p>The current behavior, which cannot be changed, is that when fuel runs out a wasm trap is generated. I hope to make this configurable in the future so that for async stores when fuel runs out it's automatically re-injected with fuel but only after a yield back to the host happens.</p>\n<p>I've done a bit of benchmarking with this using criterion and the benchmarks here -- <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks-next</a>. The benchmarks are relatively limited at this time but were able to produce some useful data in the meantime. This shows to be a 35-45% slowdown on my personal laptop for the runtime execution of the benchmarked porttion of the code for blake3-scalar and shootout-ackermann. At least for ackermann this is somewhat expected because the loops/function calls are all tiny, so the overhead is quite noticeable. For blake3-scalar I assume it's similar but haven't dug in yet. Note that these numbers were with the new backend since the old x86 backend seems significantly worse than the x64 one.</p>\n<p>I do think there might be some relatively low-hanging fruit with respect to performance, but further tweaks would require changes to cranelift itself to optimize instruction selection. For example one optimization might be to not have a <code>fuel_var</code> and instead periodically do <code>addq $fuel_consumed, offset(%vminterrupts_ptr)</code> which avoids consuming extra registers. Similarly <code>cmpq $0, offset(%vminterrupts_ptr)</code> could be generated as well. I couldn't get the x64 backend to emit those forms of instructions at this time though. I'm also not 100% certain that it'll be faster.</p>\n<p>Note that for now this doesn't depend on the <code>async</code> PR, but I plan on having a future PR after these two land which implements the periodically-yield option.</p>\n</blockquote>",
        "id": 224400677,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611871800
    },
    {
        "content": "<p>alexcrichton merged <a href=\"https://github.com/bytecodealliance/wasmtime/pull/2611\">PR #2611</a>.</p>",
        "id": 224481262,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1611932239
    }
]