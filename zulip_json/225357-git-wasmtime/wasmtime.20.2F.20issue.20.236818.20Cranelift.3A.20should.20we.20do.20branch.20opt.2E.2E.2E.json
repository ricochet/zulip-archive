[
    {
        "content": "<p>cfallin opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>@alexcrichton brought up in #6810 </p>\n<blockquote>\n<p>And again to clarify I'm not advocating for here-and-now removing branch optimizations from the mach buffer. I realize it's a deep refactoring and would take quite some work and that additionally this is the result of historical work and balancing efforts. I still do believe though that this probably isn't the best place to do this because it's extremely late in the pipeline and we're already unable to perform optimization such as constant-branch-folding with knock-on effects from that. For example I'd imagine that if constant-branch-folding were implemented then many of the optimizations that the mach buffer does would probably fall out of that, where in such a situation it may not be necessary for the mach buffer to be as clever as it is today.</p>\n</blockquote>\n<p>This issue is meant to answer the question: should we do this refactor, and why or why not?</p>\n<p>First, addressing some specific points:</p>\n<blockquote>\n<p>extremely late in the pipeline and we're already unable to perform optimization such as constant-branch-folding with knock-on effects from that.</p>\n</blockquote>\n<p>It's unclear to me why this is the case -- could you clarify? Constant-branch folding can be done on CLIF in earlier stages; nothing in <code>MachBuffer</code> precludes replacing a <code>brif</code> with a <code>jump</code> when we know the conditional is constant (and we hope to do that optimization in the future!).</p>\n<blockquote>\n<p>For example I'd imagine that if constant-branch-folding were implemented then many of the optimizations that the mach buffer does would probably fall out of that</p>\n</blockquote>\n<p>Unfortunately this is also not quite the case I think, for several reasons:</p>\n<ul>\n<li>The <code>MachBuffer</code>'s rearranging of branches requires knowledge of block order, because it is taking advantage of fallthroughs. We don't know block order when we're doing midend optimizations, and the flexibility is important because...</li>\n<li>... we also don't know if some blocks will become empty or not, as a result of optimizations or regalloc. For example, we need to split critical edges so regalloc has a place to put spills/reloads in all cases; but many of those split edges end up being an empty block, and <code>MachBuffer</code> can then eat it (chomp the one jump in the body and redirect the label).</li>\n</ul>\n<p>So basically pass ordering and regalloc needs mean that block ordering is only known late, and this means that block-order-dependent changes cannot happen in the mid-end.</p>\n<hr>\n<p>I think both of the above are possibly springing from a slight mis-interpretation of what purpose the <code>MachBuffer</code>'s branch folding rules actually serve. It is not an <em>optimization</em> (in the sense of an optional thing); it is a <em>lowering step</em> that takes us from N-target branches (every block terminator always specifies all destination labels) to branch-or-fallthrough \"machine-style branches\". The former is the standard CFG representation in most SSA compilers and is convenient to work with, all the way down into regalloc2. The latter is known as \"EBBs\" (extended basic blocks) and was formerly used in Cranelift. Removing the lowering step means propagating the output side's invariants and properties (EBBs) upward into all VCode.</p>\n<p>EBBs were removed 4 years or so ago (I think? it was before my time), for good reason: it requires subtle and not-well-understood tweaks to common algorithms, it's hard to reason about, and it infects all of the compiler backend. Basically moving back to EBBs would require a careful audit and refactor of regalloc2 and the ~30k lines of code in Cranelift that touch VCode, and that's a nonstarter.</p>\n<p>EBBs also require knowledge of, and lock in, the block order, which is a weird nonlocal invariant thing that precludes a bunch of other optimizations as noted above.</p>\n<p>So both branch-folding in machine-independent code <em>and</em> the lowering from N-target form to fallthrough form are useful transforms, but they serve different purposes. The former is an optimization and is optional; the latter is fundamental to the IR design, in that it lets us reason at a slightly higher semantic level and avoid huge complexities.</p>\n<hr>\n<p>Finally, the original motivation for this discussion came from a perceived inability to make the branch simplifications work with a more complex forward-reference label resolution algorithm. I don't think this is necessarily or fundamentally the case. The label resolution (island/veneer insertion) and branch optimizations interact in subtle ways, but they are separate, tied by the invariant: the buffer of most-recent branches continguous to the end of the buffer (this is the visibility of the peephole opts) must correspond to the latest fixups in the fixup list.</p>\n<p>The veneer insertion happens only at island generation, and islands clear the \"most recent branches\" list (because none are contiguous to the end of buffer anymore), so actually we can do whatever we want with more complex data structures and algorithms, without violating the invariant. The only requirement is that between islands, we do keep a linear list of most recent fixups (we can clear it whenever we emit a non-branch instruction).</p>\n<hr>\n<p>So from my perspective, there is a proposal for a large refactor of the compiler backend, with high risk, motivated by two reasons that I don't think are really the case (branch constant folding gets better? --&gt; no, different and orthogonal things; precludes more advanced veneer fixup? --&gt; no, the invariant still allows this). It's entirely possible I've missed something or misunderstood some part of the proposal though -- curious what others think!</p>\n</blockquote>",
        "id": 382735784,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691435146
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1668433225\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>(Thanks to @jameysharp, @elliottt and others for talking through this a bit offline and especially Jamey for noting the implications on block order above. @alexcrichton if you want to discuss further we can definitely do so in the next Cranelift meeting, if that's easier!)</p>\n</blockquote>",
        "id": 382736031,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691435202
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1670324315\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>Thanks for taking the time to write this up! I've added this to the <a href=\"https://github.com/bytecodealliance/meetings/pull/130\">agenda for tomorrow</a> to go over if there's anything remaining, mostly because I'm still curious to dig into more details if you and others are willing!</p>\n<blockquote>\n<blockquote>\n<div class=\"codehilite\"><pre><span></span><code>extremely late in the pipeline and we&#39;re already unable to perform optimization such as constant-branch-folding with knock-on effects from that.\n</code></pre></div>\n\n</blockquote>\n<p>It's unclear to me why this is the case -- could you clarify?</p>\n</blockquote>\n<p>My gut is that this level of optimization is best done earlier in the pipeline which is where my thinking stems from, but there's other concrete issues which I think would rely on doing branch-related optimizations earlier rather than at the very end:</p>\n<ul>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6154\">https://github.com/bytecodealliance/wasmtime/issues/6154</a> - this is where current lowering rules won't match across blocks and while the <code>jump</code> isn't present in the final compiled output it's thwarting other things.</li>\n<li><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6094\">https://github.com/bytecodealliance/wasmtime/issues/6094</a> - ignoring the spectre parts of that, GVN-ing bounds checks to eliminate dominated bounds checks can result in a bunch of dead code which would ideally be removed rather than simply having branches fused in the MachBuffer</li>\n</ul>\n<p>Basically my thinking is that while we could make MachBuffer fancier related to branching it seems like much of the benefit should come from the mid-end optimizations and their knock-on effects.</p>\n<blockquote>\n<p>I think both of the above are possibly springing from a slight mis-interpretation of what purpose the MachBuffer's branch folding rules actually serve. It is not an optimization (in the sense of an optional thing); it is a lowering step</p>\n</blockquote>\n<p>This is a good point yeah and I think a good way to help me frame my thinking. On one hand we as a compiler have the problem of optimizing a CFG, for example A-&gt;B-&gt;C could be come A+B -&gt; C under some conditions and things like that. Also things like <code>br_if true a, b</code> can become <code>jump a</code> which might enable further CFG simplifications. This, in my mind, is all about taking a messy CFG to a \"clean\" CFG which would handle the issues I described above (e.g. no <code>ret</code>-in-its-own-block and DCE would fall out of CFG rewriting). There is however still the problem of taking a perfect CFG and lowering it to optimal machine code.</p>\n<p>I feel like MachBuffer has historically conflated these two operations, performing both CFG optimization and optimal linear layout of a CFG at the same time. My thinking has been that the CFG-optimizing parts of MachBuffer would ideally be removed into an independent pass in Cranelift to get executed at some point, perhaps intertwined with egraph optimizations somehow (e.g. to make use of constant propagation and/or GVN).</p>\n<p>I'll also clarify that I barely know what an EBB is much less advocate for it. And again if anything I'm thinking comes with a fundamental compile-time or runtime performance penalty then it's not worth it, I'm trying to see if we can have our cake and eat it too.</p>\n<p>I'll definitely admit that this may all be stemming from me misunderstanding MachBuffer and its optimizations. If all it's doing is the optimal linear layout of a CFG without extra optimizations then there's no escaping that class of problem so there's nothing more that can be done.</p>\n<hr>\n<p>All that being said your observation about the recent branches list being empty on islands I think is a great one and would be a way to solve the suboptimal branch generation from <a href=\"https://github.com/bytecodealliance/wasmtime/pull/6804\">https://github.com/bytecodealliance/wasmtime/pull/6804</a>. I might try to give that a stab in the future!</p>\n</blockquote>",
        "id": 383081976,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691529692
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671800959\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>Ok I talked more with folks at the Cranelift meeting today and the conclusion I took away was that the MachBuffer optimizations are all required at this time to have an optimal linear layout of a CFG we input. In that sense what I was mentioning above about CFG optimizations and optimal CFG layout the MachBuffer only deals with the latter which all sounds good. </p>\n<p>In that sense I believe this issue is resolved as the answer is \"yes, the MachBuffer should continue to produce high-quality code\".</p>\n<p>As for the one remaining issue of the eager promotion of veneers I think @cfallin's idea will solve it well. I mentioned today I had a branch (<a href=\"https://github.com/alexcrichton/wasmtime/commit/223926a1eeca76cd747fcd5ca72c370ba1cf41db\">which is here</a>) which implemented the <code>BinaryHeap</code> idea although it only works by disabling optimization, so not landable as-is of course but wanted to share as it had the bits about removing precalculation of the island deadline.</p>\n</blockquote>",
        "id": 383357418,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691600113
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671828874\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>Given that there are a small ISA-specific constant number of possible deadline-distances (e.g. 2^20, 2^27, 2^32) it occurs to me a priority queue isn't strictly necessary. We could keep one <code>VecDeque</code> per distance instead. Then all the labels that are at their deadlines are together at the beginning of their respective lists; you can still remove the last-added labels efficiently if needed; and nothing needs to repeatedly visit labels in the middle. Does that help?</p>\n</blockquote>",
        "id": 383362411,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691600959
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671902062\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>I think that would work as well yeah, but I think that'd still require the \"flush\" behavior during island insertion right? Otherwise I'm at least not too worried about overhead with a <code>BinaryHeap</code> and it feels like a simpler alternative to reach for, but I think I'm on a bit of a one-track mind right now...</p>\n</blockquote>",
        "id": 383378542,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691604330
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671918536\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>It's possible we can make do with just <code>Vec</code>s actually. The key thing is that (i) as fixups are pushed prior to an island, the only operation we need is \"chomp\" (so push/pop on a vec suffices); and after the island, we can't chomp anymore, so it suffices to sort by deadline. As you're observing, for a given class we will have monotonically increasing deadlines, so we can put the \"long-term vecs\" per class in reverse-deadline order and pop off the back of all of them.</p>\n<p>That said, and as I mentioned in the earlier thread, I worry a lot about complexity here so I'd want to be careful about premature optimization. One \"deadline-keyed heap\" that we pop from is a lot simpler than a radix-sort-like thing with N vecs, and it's not clear to me how to parameterize the latter on <code>LabelUse</code> arms either (they are different per architecture), strictly in terms of generic programming in Rust. (I guess the trait on the enum could map the kinds into an integer index space, with each concrete implementation a <code>repr(u8)</code> or whatever, but now we're way down the rabbit hole.) So maybe it's best to try the simpler thing and then see whether we need anything more...</p>\n</blockquote>",
        "id": 383381997,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691605125
    },
    {
        "content": "<p>cfallin edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671918536\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>It's possible we can make do with just <code>Vec</code>s actually. The key thing is that (i) as fixups are pushed prior to an island, the only operation we need is \"chomp\" (so push/pop on a vec suffices); and after the island, we can't chomp anymore, so it suffices to sort by deadline. As you're observing, for a given class we will have monotonically increasing deadlines, so we can put the \"long-term vecs\" per class in reverse-deadline order and pop off the back of all of them.</p>\n<p>That said, and as I mentioned in the earlier thread, I worry a lot about complexity here so I'd want to be careful about premature optimization. One \"deadline-keyed heap\" that we pop from is a lot simpler than a radix-sort-like thing with N vecs, and it's not clear to me how to parameterize the latter on <code>LabelUse</code> arms either (they are different per architecture), strictly in terms of generic programming in Rust. (I guess the trait on the enum could map the kinds into an integer index space, with each concrete implementation a <code>repr(u8)</code> or whatever, but now we're way down the rabbit hole.) So maybe it's best to try the simpler thing (EDIT for clarity: that would be @alexcrichton 's <code>BinaryHeap</code> suggestion) and then see whether we need anything more...</p>\n</blockquote>",
        "id": 383382141,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691605156
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818#issuecomment-1671963182\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>I figured we'd just have what amounts to a map keyed on the <code>CodeOffset</code> (which is a <code>u32</code>) from <code>MachInstLabelUse::max_pos_range</code>. We don't actually care what kind of label it is for this purpose; we care what maximum offset it has. There are no more than four distinct max offsets on any current target, so even linear-scan in an array-of-pairs-based \"map\" is asymptotically O(1) and the constant factors might be better than a HashMap.</p>\n<p>But I don't quite understand the interaction between veneer emission and label chomping and I'll take your word for it, both of you, that the binary heap is fine.</p>\n</blockquote>",
        "id": 383390550,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1691607153
    },
    {
        "content": "<p>cfallin closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6818\">issue #6818</a>:</p>\n<blockquote>\n<p>@alexcrichton brought up in #6810 </p>\n<blockquote>\n<p>And again to clarify I'm not advocating for here-and-now removing branch optimizations from the mach buffer. I realize it's a deep refactoring and would take quite some work and that additionally this is the result of historical work and balancing efforts. I still do believe though that this probably isn't the best place to do this because it's extremely late in the pipeline and we're already unable to perform optimization such as constant-branch-folding with knock-on effects from that. For example I'd imagine that if constant-branch-folding were implemented then many of the optimizations that the mach buffer does would probably fall out of that, where in such a situation it may not be necessary for the mach buffer to be as clever as it is today.</p>\n</blockquote>\n<p>This issue is meant to answer the question: should we do this refactor, and why or why not?</p>\n<p>First, addressing some specific points:</p>\n<blockquote>\n<p>extremely late in the pipeline and we're already unable to perform optimization such as constant-branch-folding with knock-on effects from that.</p>\n</blockquote>\n<p>It's unclear to me why this is the case -- could you clarify? Constant-branch folding can be done on CLIF in earlier stages; nothing in <code>MachBuffer</code> precludes replacing a <code>brif</code> with a <code>jump</code> when we know the conditional is constant (and we hope to do that optimization in the future!).</p>\n<blockquote>\n<p>For example I'd imagine that if constant-branch-folding were implemented then many of the optimizations that the mach buffer does would probably fall out of that</p>\n</blockquote>\n<p>Unfortunately this is also not quite the case I think, for several reasons:</p>\n<ul>\n<li>The <code>MachBuffer</code>'s rearranging of branches requires knowledge of block order, because it is taking advantage of fallthroughs. We don't know block order when we're doing midend optimizations, and the flexibility is important because...</li>\n<li>... we also don't know if some blocks will become empty or not, as a result of optimizations or regalloc. For example, we need to split critical edges so regalloc has a place to put spills/reloads in all cases; but many of those split edges end up being an empty block, and <code>MachBuffer</code> can then eat it (chomp the one jump in the body and redirect the label).</li>\n</ul>\n<p>So basically pass ordering and regalloc needs mean that block ordering is only known late, and this means that block-order-dependent changes cannot happen in the mid-end.</p>\n<hr>\n<p>I think both of the above are possibly springing from a slight mis-interpretation of what purpose the <code>MachBuffer</code>'s branch folding rules actually serve. It is not an <em>optimization</em> (in the sense of an optional thing); it is a <em>lowering step</em> that takes us from N-target branches (every block terminator always specifies all destination labels) to branch-or-fallthrough \"machine-style branches\". The former is the standard CFG representation in most SSA compilers and is convenient to work with, all the way down into regalloc2. The latter is known as \"EBBs\" (extended basic blocks) and was formerly used in Cranelift. Removing the lowering step means propagating the output side's invariants and properties (EBBs) upward into all VCode.</p>\n<p>EBBs were removed 4 years or so ago (I think? it was before my time), for good reason: it requires subtle and not-well-understood tweaks to common algorithms, it's hard to reason about, and it infects all of the compiler backend. Basically moving back to EBBs would require a careful audit and refactor of regalloc2 and the ~30k lines of code in Cranelift that touch VCode, and that's a nonstarter.</p>\n<p>EBBs also require knowledge of, and lock in, the block order, which is a weird nonlocal invariant thing that precludes a bunch of other optimizations as noted above.</p>\n<p>So both branch-folding in machine-independent code <em>and</em> the lowering from N-target form to fallthrough form are useful transforms, but they serve different purposes. The former is an optimization and is optional; the latter is fundamental to the IR design, in that it lets us reason at a slightly higher semantic level and avoid huge complexities.</p>\n<hr>\n<p>Finally, the original motivation for this discussion came from a perceived inability to make the branch simplifications work with a more complex forward-reference label resolution algorithm. I don't think this is necessarily or fundamentally the case. The label resolution (island/veneer insertion) and branch optimizations interact in subtle ways, but they are separate, tied by the invariant: the buffer of most-recent branches continguous to the end of the buffer (this is the visibility of the peephole opts) must correspond to the latest fixups in the fixup list.</p>\n<p>The veneer insertion happens only at island generation, and islands clear the \"most recent branches\" list (because none are contiguous to the end of buffer anymore), so actually we can do whatever we want with more complex data structures and algorithms, without violating the invariant. The only requirement is that between islands, we do keep a linear list of most recent fixups (we can clear it whenever we emit a non-branch instruction).</p>\n<hr>\n<p>So from my perspective, there is a proposal for a large refactor of the compiler backend, with high risk, motivated by two reasons that I don't think are really the case (branch constant folding gets better? --&gt; no, different and orthogonal things; precludes more advanced veneer fixup? --&gt; no, the invariant still allows this). It's entirely possible I've missed something or misunderstood some part of the proposal though -- curious what others think!</p>\n</blockquote>",
        "id": 387182485,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1692923832
    }
]