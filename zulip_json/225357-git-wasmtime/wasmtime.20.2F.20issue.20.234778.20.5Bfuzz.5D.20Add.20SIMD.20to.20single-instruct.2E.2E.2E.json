[
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226605375\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>There are a couple of issues to resolve before merging this:</p>\n<ul>\n<li>someone (@alexcrichton?) had mentioned previously that it would be good to expand the number of V128 known values so that we can find bugs faster. There are a lot of known values that could be interesting, though: 6 kinds of V128 (i8x16, i16x8, ..., f64x2) x up to 8 values (NaN, Inf, -Inf, ..., 1, MAX). Any suggestions on a nice way to generate all of these?</li>\n<li>when run on this branch, the <code>differential</code> fuzz target will eventually find NaN canonicalization issues for the V128 values--e.g., the spec will canonicalize them but the single-instruction generator does not know how to do this. I'm wondering how best to tackle this:<br>\n  a. try to add canonicalization to single-inst modules to match wasm-smith; I haven't looked into this much... does wasm-smith even canonicalize V128s?<br>\n  b. try to teach the <code>impl PartialEq for DiffValue</code> to ignore NaNs for V128s; this already happens for F32 and F64, but for V128 this is trickier because we don't know how to split up the lanes (is it an F32x4? No, an I8x16?) and there is actually no easy way to know this from the WebAssembly function signature itself--the information is lost. But perhaps we could first try <code>==</code>, then <code>F32x4</code> NaNs, then <code>F64x2</code> NaNs, then fail (something like that).</li>\n</ul>\n<p>Thoughts on these two questions?</p>\n</blockquote>",
        "id": 295142494,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661384625
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226605375\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>There are a couple of issues to resolve before merging this:</p>\n<ul>\n<li>someone (@alexcrichton?) had mentioned previously that it would be good to expand the number of V128 known values so that we can find bugs faster. There are a lot of known values that could be interesting, though: 6 kinds of V128 (i8x16, i16x8, ..., f64x2) x up to 8 values (NaN, Inf, -Inf, ..., 1, MAX). Any suggestions on a nice way to generate all of these?</li>\n<li>when run on this branch, the <code>differential</code> fuzz target will eventually find NaN canonicalization issues for the V128 values--e.g., the spec will canonicalize them but the single-instruction generator does not know how to do this. I'm wondering how best to tackle this:<br>\n  a) try to add canonicalization to single-inst modules to match wasm-smith; I haven't looked into this much... does wasm-smith even canonicalize V128s?<br>\n  b) try to teach the <code>impl PartialEq for DiffValue</code> to ignore NaNs for V128s; this already happens for F32 and F64, but for V128 this is trickier because we don't know how to split up the lanes (is it an F32x4? No, an I8x16?) and there is actually no easy way to know this from the WebAssembly function signature itself--the information is lost. But perhaps we could first try <code>==</code>, then <code>F32x4</code> NaNs, then <code>F64x2</code> NaNs, then fail (something like that).</li>\n</ul>\n<p>Thoughts on these two questions?</p>\n</blockquote>",
        "id": 295142614,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661384716
    },
    {
        "content": "<p>github-actions[bot] <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226616920\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<h4>Subscribe to Label Action</h4>\n<p>cc @fitzgen</p>\n<p>&lt;details&gt;<br>\nThis issue or pull request has been labeled: \"fuzzing\"</p>\n<p>Thus the following users have been cc'd because of the following labels:</p>\n<ul>\n<li>fitzgen: fuzzing</li>\n</ul>\n<p>To subscribe or unsubscribe from this label, edit the &lt;code&gt;.github/subscribe-to-label.json&lt;/code&gt; configuration file.</p>\n<p><a href=\"https://github.com/bytecodealliance/subscribe-to-label-action\">Learn more.</a><br>\n&lt;/details&gt;</p>\n</blockquote>",
        "id": 295144187,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661385991
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226617955\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<blockquote>\n<p>There are a couple of issues to resolve before merging this:</p>\n<ul>\n<li>someone (@alexcrichton?) had mentioned previously that it would be good to expand the number of V128 known values so that we can find bugs faster. There are a lot of known values that could be interesting, though: 6 kinds of V128 (i8x16, i16x8, ..., f64x2) x up to 8 values (NaN, Inf, -Inf, ..., 1, MAX). Any suggestions on a nice way to generate all of these?</li>\n</ul>\n</blockquote>\n<p>To make sure I'm looking at the right thing: you're talking about <code>DiffValue::arbitrary_of_type</code> in <code>crates/fuzzing/src/generators/value.rs</code>, right?</p>\n<p>I'm thinking that <code>arbitrary_of_type</code> could first pick a vector kind (f32x4 etc), then call itself once for each lane, requesting the right lane type. For example, 4 calls to <code>DiffValue::arbitrary_of_type(u, F32)</code>, then pack the bits from each call into a <code>u128</code>. Is that too simplistic? I guess it doesn't quite work for vectors with lanes narrower than 32 bits.</p>\n<blockquote>\n<ul>\n<li>when run on this branch, the <code>differential</code> fuzz target will eventually find NaN canonicalization issues for the V128 values--e.g., the spec will canonicalize them but the single-instruction generator does not know how to do this. I'm wondering how best to tackle this:</li>\n</ul>\n</blockquote>\n<p>The cranelift-fuzzgen target turns on a \"nan_canonicalization\" pass inside Cranelift. I see there's a Wasmtime config option, <code>config.cranelift_nan_canonicalization(true)</code>, that should do the same thing. Does that help here?</p>\n</blockquote>",
        "id": 295144284,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661386087
    },
    {
        "content": "<p>afonso360 <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226863420\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<blockquote>\n<p>The cranelift-fuzzgen target turns on a \"nan_canonicalization\" pass inside Cranelift. I see there's a Wasmtime config option, config.cranelift_nan_canonicalization(true), that should do the same thing. Does that help here?</p>\n</blockquote>\n<p>If I understand this correctly, this fuzz target can fuzz against engines other than Wasmtime, right? They might not have an equivalent nan canonicalization pass. So we would have to run that pass before sending the wasm code to the engines.</p>\n</blockquote>",
        "id": 295173107,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661411318
    },
    {
        "content": "<p>afonso360 edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1226863420\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<blockquote>\n<p>The cranelift-fuzzgen target turns on a \"nan_canonicalization\" pass inside Cranelift. I see there's a Wasmtime config option, config.cranelift_nan_canonicalization(true), that should do the same thing. Does that help here?</p>\n</blockquote>\n<p>If I understand this correctly, this fuzz target can fuzz against engines other than Wasmtime, right? They might not have an equivalent nan canonicalization pass. So we would have to run an equivalent pass in wasm before sending the wasm code to the engines.</p>\n</blockquote>",
        "id": 295173147,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661411341
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1227566902\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p><code>wasm-smith</code> has an option to canonicalize NaNs today, not sure if it is complete for SIMD stuff or not tho: <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/de47b042d93a6e28208e9a83c10304b3d64db625/crates/wasm-smith/src/core/code_builder.rs#L867\">https://github.com/bytecodealliance/wasm-tools/blob/de47b042d93a6e28208e9a83c10304b3d64db625/crates/wasm-smith/src/core/code_builder.rs#L867</a></p>\n</blockquote>",
        "id": 295276766,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661448590
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1227659108\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Yeah, maybe we could update which instructions can have their outputs canonicalized in wasm-smith (thanks @fitzgen for the link, was wondering about that) but the other big issue is that we would have to build similar canonicalization infrastructure in the single-instruction module generator for all the same instructions.</p>\n<p>I'm actually thinking through option B above which is to implement fail-overs in <code>PartialEq for DiffValue</code>--why? The first N bits of an FP NaN are set: for f32, it's the first 10 bits (<code>0b0_11111111_1</code>... sign, exponent, first bit of mantissa)&lt;sup&gt;<a href=\"#nan\">1</a>&lt;/sup&gt;. If we compare two V128s and they do not match because a single F32 lane contains a NaN with differing payload, then the bits of those V128s can differ by up to 22 bits / 128 bits = ~17%. If in fact the difference in the V128s was not due to NaN canonicalization, would we really want to take that 17% risk of ignoring a bug?</p>\n<p>So now I'm leaning towards canonicalizing certain instructions in the single-instruction generator as done <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/6c127a6b2913c6be410372bd48c6710022f0c1e4/crates/wasm-smith/src/core/code_builder.rs#L927\">here</a>.</p>\n<hr>\n<p>&lt;a name=\"nan\"&gt;#1&lt;/a&gt;: as a reminder, after the first <code>1</code> bit in the mantissa, canonical NaNs are filled with 0s whereas arithmetic NaNs, the problem here, are any arbitrary bits, see <a href=\"https://webassembly.github.io/spec/core/bikeshed/#floating-point%E2%91%A0\">the Wasm spec</a>+</p>\n</blockquote>",
        "id": 295294275,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661454770
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1227659108\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Yeah, maybe we could update which instructions can have their outputs canonicalized in wasm-smith (thanks @fitzgen for the link, was wondering about that) but the other big issue is that we would have to build similar canonicalization infrastructure in the single-instruction module generator for all the same instructions.</p>\n<p>I'm actually thinking through option B above which is to implement fail-overs in <code>PartialEq for DiffValue</code>--why? The first N bits of an FP NaN are set: for f32, it's the first 10 bits (<code>0b0_11111111_1</code>... sign, exponent, first bit of mantissa)&lt;sup&gt;<a href=\"#nan\">1</a>&lt;/sup&gt;. If we compare two V128s and they do not match because a single F32 lane contains a NaN with differing payload, then the bits of those V128s can differ by up to 22 bits / 128 bits = ~17%. If in fact the difference in the V128s was not due to NaN canonicalization, would we really want to take that 17% risk of ignoring a bug?</p>\n<p>So now I'm leaning towards canonicalizing certain instructions in the single-instruction generator as done <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/6c127a6b2913c6be410372bd48c6710022f0c1e4/crates/wasm-smith/src/core/code_builder.rs#L927\">here</a>.</p>\n<hr>\n<p>&lt;a name=\"nan\"&gt;#1&lt;/a&gt;: as a reminder, after the first <code>1</code> bit in the mantissa, canonical NaNs are filled with 0s whereas arithmetic NaNs, the problem here, are any arbitrary bits, see <a href=\"https://webassembly.github.io/spec/core/bikeshed/#floating-point%E2%91%A0\">the Wasm spec</a>).</p>\n</blockquote>",
        "id": 295298221,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661456241
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1227659108\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Yeah, maybe we could update which instructions can have their outputs canonicalized in wasm-smith (thanks @fitzgen for the link, was wondering about that) but the other big issue is that we would have to build similar canonicalization infrastructure in the single-instruction module generator for all the same instructions.</p>\n<p>I'm actually thinking through option B above which is to implement fail-overs in <code>PartialEq for DiffValue</code>--why? The first N bits of an FP NaN are set: for f32, it's the first 10 bits (<code>0b0_11111111_1</code>... sign, exponent, first bit of mantissa)&lt;sup&gt;<a href=\"#nan\">1</a>&lt;/sup&gt;. If we compare two V128s and they do not match because a single F32 lane contains a NaN with differing payload, then the bits of those V128s can differ by up to 22 bits / 128 bits = ~17%. If in fact the difference in the V128s was not due to NaN canonicalization, would we really want to take that 17% risk of ignoring a bug?</p>\n<p>So now I'm leaning towards canonicalizing certain instructions in the single-instruction generator as done <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/6c127a6b2913c6be410372bd48c6710022f0c1e4/crates/wasm-smith/src/core/code_builder.rs#L927\">here</a>.</p>\n<hr>\n<p>&lt;a name=\"nan\"&gt;#1&lt;/a&gt;: as a reminder, after the first <code>1</code> bit in the mantissa, canonical NaNs are filled with 0s whereas arithmetic NaNs, the problem here, are any arbitrary bits, see <a href=\"https://webassembly.github.io/spec/core/bikeshed/#floating-point%E2%91%A0\">the Wasm spec</a>.</p>\n</blockquote>",
        "id": 295298271,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661456257
    },
    {
        "content": "<p>abrown edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1227659108\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Yeah, maybe we could update which instructions can have their outputs canonicalized in wasm-smith (thanks @fitzgen for the link, was wondering about that) but the other big issue is that we would have to build similar canonicalization infrastructure in the single-instruction module generator for all the same instructions.</p>\n<p>I'm actually thinking through option B above which is to implement fail-overs in <code>PartialEq for DiffValue</code>--why? The first N bits of an FP NaN are set: for f32, it's the first 10 bits (<code>0b0_11111111_1</code>... sign, exponent, first bit of mantissa)&lt;sup&gt;<a href=\"#nan\">1</a>&lt;/sup&gt;. If we compare two V128s and they do not match because a single F32 lane contains a NaN with differing payload, then the bits of those V128s can differ by up to 22 bits / 128 bits = ~17%. If in fact the difference in the V128s was not due to NaN canonicalization, would we really want to take that 17% risk of ignoring a bug?</p>\n<p>So now I'm leaning towards canonicalizing certain instructions in the single-instruction generator as done <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/6c127a6b2913c6be410372bd48c6710022f0c1e4/crates/wasm-smith/src/core/code_builder.rs#L927\">here</a>.</p>\n<hr>\n<p>&lt;a name=\"nan\"&gt;#1&lt;/a&gt;: as a reminder, after the first <code>1</code> bit in the mantissa, canonical NaNs are filled with 0s whereas arithmetic NaNs (which are the problem here) can contain any arbitrary bits. Also see <a href=\"https://webassembly.github.io/spec/core/bikeshed/#floating-point%E2%91%A0\">the Wasm spec</a>.</p>\n</blockquote>",
        "id": 295298452,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661456315
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1229079472\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Let me see if I have this right: a wasm-level NaN canonicalization pass would append a type-specific fixed sequence of instructions immediately after every instruction that pushes a newly-computed floating-point value on the stack, and you can tell which sequence to use by looking only at the instruction, without any surrounding context.</p>\n<p>That does sound better than ignoring possible-NaN differences at the end, after all type information is lost.</p>\n</blockquote>",
        "id": 295534347,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661561947
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1229087256\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Yeah, that's right.</p>\n</blockquote>",
        "id": 295535267,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661563036
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1231735925\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>I think it's ok to expand the set of interesting v128 values later, and I think it's ok to be a bit verbose and just list them all out rather than procedurally generating them (basically I don't have a better idea).</p>\n<p>Otherwise though with NaN issues I think the best solution is to add code to <code>wasm-smith</code> to do the same canonicalization that happens for f32 and f64. I think the sequences of instructions are basically going to be the same, just for vectors instead.</p>\n</blockquote>",
        "id": 296128628,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1661869180
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1238670588\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<blockquote>\n<p>Seems like a good start to me! I personally think that the nan canonicalization code would go better in wasm-smith itself along the lines of f32/f64 canonicalization that's already in there. I'm ok landing this first though and updating that afterwards.</p>\n</blockquote>\n<p>I don't get what you mean. How would that work?</p>\n</blockquote>",
        "id": 297490128,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662499887
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1238680450\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Wasm-smith based canonicalication is <a href=\"https://github.com/bytecodealliance/wasm-tools/blob/fc2a190720f3a8d66ff9fc2af17bade898599da5/crates/wasm-smith/src/core/code_builder.rs#L861-L920\">currently here</a>. Actually reading over that it looks like there's already affordances for simd-based float operations. If your differential fuzzing here found issues with nans though then it may actually just be a case of extending the opcode listings there to canonicalize on a few more operations.</p>\n</blockquote>",
        "id": 297491136,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662500351
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1238694347\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Ah, no, the NaN canonicalization problem I observed was with a <code>SingleInstModule</code>, which <code>wasm-smith</code> does not generate. So my solution was to bring over that same NaN canonicalization logic over from <code>wasm-smith</code> to <code>SingleInstModule</code>. For now, I have not observed a scalar failure though it seems possible one day that this could happen (which is why I ported the scalar canonicalization as well); when it happens we can enable the same scalar instructions that you pointed to. So only SIMD canonicalization is actually enabled in c6bb6c0.</p>\n<p>When I run this locally with V8 disabled (still haven't figured out what is going on with the segfaults there), I have not seen a failure yet:</p>\n<div class=\"codehilite\" data-code-language=\"Bash Session\"><pre><span></span><code><span class=\"gp\">$ </span><span class=\"nv\">ALLOWED_ENGINES</span><span class=\"o\">=</span>-v8 cargo +nightly fuzz run -s none differential\n<span class=\"go\">...</span>\n<span class=\"go\">=== Execution rate (1152302 successes / 2313000 attempted modules): 49.82% ===</span>\n<span class=\"go\">        wasmi: 8.06%, spec: 8.46%, wasmtime: 83.48%, v8: 0.00%</span>\n<span class=\"go\">        wasm-smith: 72.32%, single-inst: 27.68%</span>\n</code></pre></div>\n<p>I guess I'll merge it and we can see if anything is found by oss-fuzz.</p>\n</blockquote>",
        "id": 297492919,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662501258
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778#issuecomment-1238713445\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4778\">issue #4778</a>:</p>\n<blockquote>\n<p>Oh wow sorry I completely forgot that this isn't wasm-smith related at all. Unsure how I missed that for so long... Disregard me and this is definitely good to land <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> </p>\n</blockquote>",
        "id": 297496309,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1662503101
    }
]