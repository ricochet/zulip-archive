[
    {
        "content": "<p>alexcrichton opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>Some local fuzzing found today that this module:</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (memory 65536)\n  (data (i32.const 0) \"a\")\n  (data (i32.const 1_000_000_000) \"b\")\n)\n</code></pre></div>\n<p>produces a nearly 1GB large artifact, almost entirely consisting of the heap image. Additionally compile-time memory usage is 1GB or so large because we create the in-memory image at compile time.</p>\n<p>I think that during <a href=\"https://github.com/bytecodealliance/wasmtime/blob/db9e3ce9d94adcbf380cafd1cf4506cfc7752064/crates/environ/src/module.rs#L314-L461\">static memory initialization</a> we'll want to be more clever about creating the heap image. For example the paged memory initialization is sparse in the sense of it only keeps track of initialized pages, and for this form of initialization we probably also want to do something sparse like that and determine at the end based on nonzero-ranges whether the image is one-memfd-mmap compatible.</p>\n</blockquote>",
        "id": 272167863,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645040457
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042102385\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>Interesting, so there is an explicit limit of 1GiB exactly on memfd image size: <a href=\"https://github.com/bytecodealliance/wasmtime/blob/db9e3ce9d94adcbf380cafd1cf4506cfc7752064/crates/environ/src/module.rs#L320\">here</a>; the fuzzer figured out how to turn the knob all the way up I guess.</p>\n<p>We could definitely reduce that limit, especially since we support an \"image and leftovers\" initialization technique now -- a CoW image for \"most\" of the heap down in a reasonable range (16MiB? 128MiB?) and explicit eager instantiation for whatever bytes are way up high.</p>\n<p>We could also think about segmented/sparse approaches where we have multiple pieces, each of which has to be mmap'd, but I'm much more hesitant to go there as it makes the mapping path significantly more complex and adds mmap syscalls and increases the size of the in-kernel address space tree, making pagefaults marginally more expensive.</p>\n<p>I'm leaning toward just lowering the limit given the above, but: thoughts?</p>\n</blockquote>",
        "id": 272169132,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645041004
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042117455\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>I feel like the most robust and simple fix for now might be to, when switching to a static init, do paged init first and if that succeeds only transform to a static initialization scheme if the initialized pages fit within a smaller range than 1GB. </p>\n<p>Ideally though the limit on the memfd image should be somewhat proportional to the size of the data segements in the original module. We naturally shouldn't blow up 2 bytes (above) to 1GB but at the same time if you provide a 1GB data section we should presumably still allow that because memfd is still going to be a ton faster than eagerly copying a gigabyte of data.</p>\n<p>I definitely think we should avoid adding complication to the current initialization scheme. For example I don't think we should support multiple mmaps nor one mmap plus extra initialization. I don't think we have any modules in the wild which actually need that so all we need to do is get the one-image technique working well but also accounting for esoteric edge cases that avoid stressing the system.</p>\n<p>So given all that, I would propose:</p>\n<ul>\n<li>Delegate to <code>try_paged_init</code> from <code>try_static_init</code>. Only proceed if paged initialization took hold.</li>\n<li>Discard all entirely-zero pages</li>\n<li>Calculate the min/max and if it's less than 2x (?) the size of the original data segments then write all those pages to an in-memory vector as an initialization image.</li>\n</ul>\n<p>I think that would solve the above module (we'd create two pages and then realize their limits are way too big: 1GB vs 2 bytes). It would also handle LLVM-produced Rust modules where the heap starts with a megabyte of zeros for the stack, we'd never actually create those zeros and we'd only create the one heap image. Additionally we'd handle modules that already have very large data segments by avoiding making them too much larger but still speeding up their initialization. I believe this would enable us to remove the size limit as well because paged initialization doesn't currently have a size limit and the memory usage is all proportional to the number of data sections in the original wasm module.</p>\n</blockquote>",
        "id": 272171430,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645042062
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042200359\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>One thing to note re: above</p>\n<blockquote>\n<p>where the heap starts with a megabyte of zeros for the stack, we'd never actually create those zeros and we'd only create the one heap image.</p>\n</blockquote>\n<p>We actually already do this; we trim the zeroes off the front and back of the image, and use anonymous zero memory when mapping. So \"real-world\" use-cases will I think almost always be OK -- it's just zeroes \"in the middle\" (with initialized content on both sides) that cause bloat.</p>\n<p>Re: the rest, I'm not opposed to heuristics like this, but I would like to inject a little caution at inventing rules that create performance cliffs. Otherwise, e.g., if layout heuristics in some toolchain change, or someone adds or removes static global data, or whatever, they could potentially find inexplicable speedups or slowdowns. I'd rather just have a maximum image size, based on what we think is reasonable (that's also a cliff but an easier-to-understand one). Seems to go better with the Wasm ethos of explicitness and lack of complex heuristics/cliffs as well. But I'm not completely tied to this, just an (admittedly somewhat strong) preference.</p>\n</blockquote>",
        "id": 272173486,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645043146
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042300938\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>We only trim zeros at the end, however. The entire image is built in-memory and then before finalizing and serializing to disk (or memfd) it's trimmed. This means that today we have a 1MB overhead for Rust-based modules which have a leading 1MB stack.</p>\n<p>I agree about performance cliffs, but no matter how you slice it it's always a performance cliff. If we set the limit to 128MB then as soon as someone has a 129MB heap image their instantiation becomes much slower. I think our goal is to try to make sure the cliff is hit as rarely as possible, and using the initial heap size as a gauge instead of a static constant I think will be less surprising in the long run.</p>\n</blockquote>",
        "id": 272176746,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645044816
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042304486\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<blockquote>\n<p>We only trim zeros at the end, however</p>\n</blockquote>\n<p>Ah, yes, sorry, you're right here; I had forgotten that we start the <em>mmap</em> from the first nonzero page, but we don't shift the data down to remove the front matter that's never mapped.</p>\n<p>So I think my main concern was with very small modules, such that crossing below a 1/2-full threshold results in a sudden degradation. E.g., I have a 128K memory image; I previously had 65K of static data; I remove a few constant arrays, now I'm at 63K, and suddenly my instantiations are a lot slower.</p>\n<p>Perhaps we could take some hybrid approach? Images in a \"small\" category (1MiB or less?) always get to use memfd; that takes care of the above. Then beyond a certain size, we start caring about density, and check for some ratio of nonzero to total pages, as you suggest. Does that seem reasonable?</p>\n</blockquote>",
        "id": 272177478,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645045108
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815#issuecomment-1042370089\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>Seems reasonable to me, I've pushed that as <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3819\">https://github.com/bytecodealliance/wasmtime/pull/3819</a></p>\n</blockquote>",
        "id": 272188083,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645050349
    },
    {
        "content": "<p>alexcrichton closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3815\">issue #3815</a>:</p>\n<blockquote>\n<p>Some local fuzzing found today that this module:</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (memory 65536)\n  (data (i32.const 0) \"a\")\n  (data (i32.const 1_000_000_000) \"b\")\n)\n</code></pre></div>\n<p>produces a nearly 1GB large artifact, almost entirely consisting of the heap image. Additionally compile-time memory usage is 1GB or so large because we create the in-memory image at compile time.</p>\n<p>I think that during <a href=\"https://github.com/bytecodealliance/wasmtime/blob/db9e3ce9d94adcbf380cafd1cf4506cfc7752064/crates/environ/src/module.rs#L314-L461\">static memory initialization</a> we'll want to be more clever about creating the heap image. For example the paged memory initialization is sparse in the sense of it only keeps track of initialized pages, and for this form of initialization we probably also want to do something sparse like that and determine at the end based on nonzero-ranges whether the image is one-memfd-mmap compatible.</p>\n</blockquote>",
        "id": 272285815,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1645115838
    }
]