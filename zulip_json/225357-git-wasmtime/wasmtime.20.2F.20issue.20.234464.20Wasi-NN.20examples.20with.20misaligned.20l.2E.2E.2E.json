[
    {
        "content": "<p>gusye1234 opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4464\">issue #4464</a>:</p>\n<blockquote>\n<p>First of all, thanks for the great implementation of Wasi-NN!<br>\nI found something misaligned while I tried to read the OpenVINO backend and the corresponding example.</p>\n<p>In the example, we passed an image in form of a tensor with the shape <code>(1, 3, 224, 224)</code>:<br>\n<a href=\"https://github.com/bytecodealliance/wasmtime/blob/3032e3fcfbb818dd567f85561fce7813f5979747/crates/wasi-nn/examples/classification-example/src/main.rs#L29-L33\">https://github.com/bytecodealliance/wasmtime/blob/3032e3fcfbb818dd567f85561fce7813f5979747/crates/wasi-nn/examples/classification-example/src/main.rs#L29-L33</a><br>\nHowever, in the OpenVINO backend, the layout of input is fixed to <code>NHWC</code>, which I believe means <code>(Batch, Height, Width, Channel)</code>.<br>\n<a href=\"https://github.com/bytecodealliance/wasmtime/blob/3032e3fcfbb818dd567f85561fce7813f5979747/crates/wasi-nn/src/openvino.rs#L88\">https://github.com/bytecodealliance/wasmtime/blob/3032e3fcfbb818dd567f85561fce7813f5979747/crates/wasi-nn/src/openvino.rs#L88</a></p>\n<p>Does that mean the model will treat our input as an image with a height of 3 pixels, width of 224 pixels, and channel of 224 pixels? But why we can still get the correct prediction?</p>\n</blockquote>",
        "id": 289979677,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1658157299
    }
]