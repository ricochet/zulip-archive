[
    {
        "content": "<p>alexcrichton opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>I... don't really know how we want to handle this. It appears that the spec interpreter is showing extremely slow behavior when processing nested blocks. For example this module (reduce from a fuzz case):</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (func\n    global.get 0\n    i32.eqz\n    if\n      unreachable\n    end\n    global.get 0\n    i32.const 1\n    i32.sub\n    global.set 0\n\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    call 0\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    )\n  (global (mut i32) (i32.const 1000))\n  (export \"\" (func 0)))\n</code></pre></div>\n<p>takes many dozens of seconds to run in the interpreter. If the <code>block ... end</code> is all removed though it finishes near instantaneously.</p>\n<p>In some sense this may be something we can fix in the interpreter (not that I have any idea how to really read or write ocaml), but in the more general sense this is probably something we'll want to protect against in the fuzzers. AFAIK the interpreter isn't built to be fast, it's just built to run, so we're probably going to run into a lot more of these where \"simple\" modules take disproportionately long to run in the interpreter.</p>\n<p>My only guess, though, of how to do this would be to fork a process with the interpreter and get the results back via a pipe or something like that, giving us the ability to SIGKILL if it times out. Apart from that though I don't know how we'd time out the interpreter...</p>\n</blockquote>",
        "id": 249412903,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1628887993
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-898749777\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>I can take a look at the OCaml side next week to see why this so slow, but, yeah, in general the in-process interpreter execution is going to be prone to this type of thing. Let's talk more about a general solution in the Wasmtime meeting?</p>\n</blockquote>",
        "id": 249421386,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1628893440
    },
    {
        "content": "<p>abrown assigned <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>I... don't really know how we want to handle this. It appears that the spec interpreter is showing extremely slow behavior when processing nested blocks. For example this module (reduce from a fuzz case):</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (func\n    global.get 0\n    i32.eqz\n    if\n      unreachable\n    end\n    global.get 0\n    i32.const 1\n    i32.sub\n    global.set 0\n\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    call 0\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    )\n  (global (mut i32) (i32.const 1000))\n  (export \"\" (func 0)))\n</code></pre></div>\n<p>takes many dozens of seconds to run in the interpreter. If the <code>block ... end</code> is all removed though it finishes near instantaneously.</p>\n<p>In some sense this may be something we can fix in the interpreter (not that I have any idea how to really read or write ocaml), but in the more general sense this is probably something we'll want to protect against in the fuzzers. AFAIK the interpreter isn't built to be fast, it's just built to run, so we're probably going to run into a lot more of these where \"simple\" modules take disproportionately long to run in the interpreter.</p>\n<p>My only guess, though, of how to do this would be to fork a process with the interpreter and get the results back via a pipe or something like that, giving us the ability to SIGKILL if it times out. Apart from that though I don't know how we'd time out the interpreter...</p>\n</blockquote>",
        "id": 249421427,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1628893447
    },
    {
        "content": "<p>alexcrichton labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a> (assigned to abrown):</p>\n<blockquote>\n<p>I... don't really know how we want to handle this. It appears that the spec interpreter is showing extremely slow behavior when processing nested blocks. For example this module (reduce from a fuzz case):</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (func\n    global.get 0\n    i32.eqz\n    if\n      unreachable\n    end\n    global.get 0\n    i32.const 1\n    i32.sub\n    global.set 0\n\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    call 0\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    )\n  (global (mut i32) (i32.const 1000))\n  (export \"\" (func 0)))\n</code></pre></div>\n<p>takes many dozens of seconds to run in the interpreter. If the <code>block ... end</code> is all removed though it finishes near instantaneously.</p>\n<p>In some sense this may be something we can fix in the interpreter (not that I have any idea how to really read or write ocaml), but in the more general sense this is probably something we'll want to protect against in the fuzzers. AFAIK the interpreter isn't built to be fast, it's just built to run, so we're probably going to run into a lot more of these where \"simple\" modules take disproportionately long to run in the interpreter.</p>\n<p>My only guess, though, of how to do this would be to fork a process with the interpreter and get the results back via a pipe or something like that, giving us the ability to SIGKILL if it times out. Apart from that though I don't know how we'd time out the interpreter...</p>\n</blockquote>",
        "id": 249602902,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629127247
    },
    {
        "content": "<p>alexcrichton labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a> (assigned to abrown):</p>\n<blockquote>\n<p>I... don't really know how we want to handle this. It appears that the spec interpreter is showing extremely slow behavior when processing nested blocks. For example this module (reduce from a fuzz case):</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (func\n    global.get 0\n    i32.eqz\n    if\n      unreachable\n    end\n    global.get 0\n    i32.const 1\n    i32.sub\n    global.set 0\n\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    call 0\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    )\n  (global (mut i32) (i32.const 1000))\n  (export \"\" (func 0)))\n</code></pre></div>\n<p>takes many dozens of seconds to run in the interpreter. If the <code>block ... end</code> is all removed though it finishes near instantaneously.</p>\n<p>In some sense this may be something we can fix in the interpreter (not that I have any idea how to really read or write ocaml), but in the more general sense this is probably something we'll want to protect against in the fuzzers. AFAIK the interpreter isn't built to be fast, it's just built to run, so we're probably going to run into a lot more of these where \"simple\" modules take disproportionately long to run in the interpreter.</p>\n<p>My only guess, though, of how to do this would be to fork a process with the interpreter and get the results back via a pipe or something like that, giving us the ability to SIGKILL if it times out. Apart from that though I don't know how we'd time out the interpreter...</p>\n</blockquote>",
        "id": 249602904,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629127247
    },
    {
        "content": "<p>github-actions[bot] <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-899597323\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<h4>Subscribe to Label Action</h4>\n<p>cc @fitzgen</p>\n<p>&lt;details&gt;<br>\nThis issue or pull request has been labeled: \"fuzzing\"</p>\n<p>Thus the following users have been cc'd because of the following labels:</p>\n<ul>\n<li>fitzgen: fuzzing</li>\n</ul>\n<p>To subscribe or unsubscribe from this label, edit the &lt;code&gt;.github/subscribe-to-label.json&lt;/code&gt; configuration file.</p>\n<p><a href=\"https://github.com/bytecodealliance/subscribe-to-label-action\">Learn more.</a><br>\n&lt;/details&gt;</p>\n</blockquote>",
        "id": 249602933,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629127261
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-899637116\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>Personally I don't want to get into the business of maintaining, optimizing, etc, the spec interpreter. If others want to take up that mantle though that can work! (it's why we have a fork after all...)</p>\n<p>To clarify, though, I don't think this is an interpreter-vs-compiler slowdown. That certainly has a slowdown but something here is clearly quadratic or greater behavior in the interpreter. I expect timeouts between wasmtime and the interpreter are all likely to fall in this category where it's bugs to egregiously slow behavior in the interpreter rather than \"oh well interpretation is a bit slower\". The fuel limit we have in each module is only at 1000 right now which severly limits the actual amount of executed wasm to the point that it shouldn't ever actually time out, even in a slow interpreter.</p>\n<p>Unless OCaml provides the native ability to interrupt and exit actively running OCaml code though I don't think that we really have a great recourse here because I don't think the subprocess idea is really that feasible. This'd end up meaning that the spec fuzzer is less useful because it will end up fuzzing less as it hits bugs like this.</p>\n</blockquote>",
        "id": 249609932,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629130489
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-902327323\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>I dug into this a bit more today, just to understand if it was something we could easily fix or if it was more fundamental.</p>\n<p>The basic issue seems to be that the interpreter has <code>O(n^2)</code> behavior because of the way it steps configurations when it is deep in a nested labels-and-callframes configuration. Specifically, if in the <a href=\"https://github.com/WebAssembly/spec/blob/ed0f0194b50bafd79bafa6156de7dfaa9572d3f6/interpreter/exec/eval.ml#L147\">step function</a> we start with a configuration <code>Block (Block (Block (Block ...)))</code>, we will step through <code>Label (Plain Block (Block (Block ...)))</code>, then <code>Label (Label (Plain Block (Block ...)))</code>, then <code>Label (Label (Label (Block ...)))</code>, etc. This much is fine: there are <code>O(n)</code> steps to execute the above example, i.e., the number of steps per Wasm instruction executed is asymptotically constant.</p>\n<p><em>However</em>, the way that the <code>step</code> function operates causes <em>each</em> step to take <code>O(|config|)</code> time, where <code>|config|</code> is the current size of the \"configuration\" (the term trees above). Specifically, when a <code>(Label ...)</code> is at the root, we recurse into the sub-configuration with a recursive call to <code>step</code>, and step the inner configuration once; then we <em>rebuild</em> the outer configuration, which ends up allocating a new heap object. This happens <a href=\"https://github.com/WebAssembly/spec/blob/ed0f0194b50bafd79bafa6156de7dfaa9572d3f6/interpreter/exec/eval.ml#L499-L501\">here</a>:</p>\n<div class=\"codehilite\" data-code-language=\"OCaml\"><pre><span></span><code>    <span class=\"o\">|</span> <span class=\"nc\">Label</span> <span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"n\">es0</span><span class=\"o\">,</span> <span class=\"n\">code'</span><span class=\"o\">),</span> <span class=\"n\">vs</span> <span class=\"o\">-&gt;</span>\n      <span class=\"k\">let</span> <span class=\"n\">c'</span> <span class=\"o\">=</span> <span class=\"n\">step</span> <span class=\"o\">{</span><span class=\"n\">c</span> <span class=\"k\">with</span> <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">code'</span><span class=\"o\">}</span> <span class=\"k\">in</span>\n      <span class=\"n\">vs</span><span class=\"o\">,</span> <span class=\"o\">[</span><span class=\"nc\">Label</span> <span class=\"o\">(</span><span class=\"n\">n</span><span class=\"o\">,</span> <span class=\"n\">es0</span><span class=\"o\">,</span> <span class=\"n\">c'</span><span class=\"o\">.</span><span class=\"n\">code</span><span class=\"o\">)</span> <span class=\"o\">@@</span> <span class=\"n\">e</span><span class=\"o\">.</span><span class=\"n\">at</span><span class=\"o\">]</span>\n</code></pre></div>\n<p>The end result is the <code>O(n^2)</code> behavior we observe. Note that Wasm calls are handled by putting a <code>Frame</code> term in the configuration and stepping within that (i.e., the Wasm callstack is embedded in the configuration tree) -- see <a href=\"https://github.com/WebAssembly/spec/blob/ed0f0194b50bafd79bafa6156de7dfaa9572d3f6/interpreter/exec/eval.ml#L512-L514\">here</a> -- so the 1000-deep recursive calls in the example above contribute to the quadratic term as well.</p>\n<p>When I profiled an optimized build of the Wasm spec interpreter running the above example, I saw about 15% of time spent in the code snippet above, and about 50% of time in the various parts of the garbage collector + allocator.</p>\n<p>I think that we could fix this by replacing the recursive <code>step</code> invocations with effectively a <code>step*</code>, i.e., \"step to completion\". This would cause issues for any resource-limiting (\"run for exactly this many steps\") built on top of the <code>step</code> function, but for our use case we only care about the final result. Alternately we could have a <code>stepN</code> that takes a nonzero <code>N</code>. This might not be terrible to do; I'd be willing to try it out and then file an issue on WebAssembly/spec; but there's also the risk that this would not be accepted upstream for clarity or other reasons. Thoughts?</p>\n</blockquote>",
        "id": 250062841,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629417181
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-902350030\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>Well, I went and got nerd-sniped... I fixed the issue in <a href=\"https://github.com/cfallin/spec/tree/fix-quadratic-interpreter\">this branch</a> of the spec interpreter. I'll see about contributing this back to WebAssembly/spec tomorrow.</p>\n<p>In the meantime we could potentially put this in our fork. (Happy to start a longer conversation about maintenance effort of doing actual fixes on our fork, vs. just merging new specs or whatnot -- I hope that bugfixes such as this don't become common!)</p>\n</blockquote>",
        "id": 250066332,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629420856
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-902735621\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>Oh wow, thanks for digging into that @cfallin! Fingers crossed for how it goes upstream <span aria-label=\"fingers crossed\" class=\"emoji emoji-1f91e\" role=\"img\" title=\"fingers crossed\">:fingers_crossed:</span> </p>\n</blockquote>",
        "id": 250125447,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629470016
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-902814408\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>Yeah, nice work! What if we create a <code>fuzzing</code> branch on <a href=\"https://github.com/bytecodealliance/wasm-spec-mirror\">https://github.com/bytecodealliance/wasm-spec-mirror</a> that contains fixes like this and, eventually, any proposals we merge in? If your commit gets merged upstream then <code>fuzzing</code> can match <code>main</code>?</p>\n</blockquote>",
        "id": 250141137,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629477121
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-902821629\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>Sure, I can push a fuzzing branch and we can switch to that for now!</p>\n</blockquote>",
        "id": 250142620,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1629477915
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186#issuecomment-912752811\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a>:</p>\n<blockquote>\n<p>I'm going to close this in favor of <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3251\">https://github.com/bytecodealliance/wasmtime/issues/3251</a> </p>\n</blockquote>",
        "id": 251928646,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1630696252
    },
    {
        "content": "<p>alexcrichton closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/3186\">issue #3186</a> (assigned to abrown):</p>\n<blockquote>\n<p>I... don't really know how we want to handle this. It appears that the spec interpreter is showing extremely slow behavior when processing nested blocks. For example this module (reduce from a fuzz case):</p>\n<div class=\"codehilite\" data-code-language=\"wasm\"><pre><span></span><code>(module\n  (func\n    global.get 0\n    i32.eqz\n    if\n      unreachable\n    end\n    global.get 0\n    i32.const 1\n    i32.sub\n    global.set 0\n\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    block\n    call 0\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    end\n    )\n  (global (mut i32) (i32.const 1000))\n  (export \"\" (func 0)))\n</code></pre></div>\n<p>takes many dozens of seconds to run in the interpreter. If the <code>block ... end</code> is all removed though it finishes near instantaneously.</p>\n<p>In some sense this may be something we can fix in the interpreter (not that I have any idea how to really read or write ocaml), but in the more general sense this is probably something we'll want to protect against in the fuzzers. AFAIK the interpreter isn't built to be fast, it's just built to run, so we're probably going to run into a lot more of these where \"simple\" modules take disproportionately long to run in the interpreter.</p>\n<p>My only guess, though, of how to do this would be to fork a process with the interpreter and get the results back via a pipe or something like that, giving us the ability to SIGKILL if it times out. Apart from that though I don't know how we'd time out the interpreter...</p>\n</blockquote>",
        "id": 251928648,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1630696252
    }
]