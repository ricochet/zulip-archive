[
    {
        "content": "<p>jameysharp opened <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>When we store a <code>Vec&lt;T&gt;</code> inside another data structure, but never change its length, we can instead store a <code>Box&lt;[T]&gt;</code>.</p>\n<h4>Benefit</h4>\n<p>The size of <code>Vec</code> in memory is three machine words, but a boxed slice is only two machine words long. This doesn't really matter if the array is only stored on the stack. But if it's part of another data structure, switching to boxed slices can reduce the amount of heap memory we allocate. That may improve cache locality and have other performance benefits.</p>\n<h4>Implementation</h4>\n<p>I did a quick experiment along these lines several months ago in commit 68d2ac2a1471a096d021be7f2cb2734843648ab8. That commit has merge conflicts with <code>main</code> now, but it illustrates the basics of how to make this change for one type, <code>Vec&lt;ArgPair&gt;</code>. I suspect there are many other uses of <code>Vec</code> in Cranelift that could have equally simple changes. There may be some in Wasmtime as well, though I'm personally focused on cases in Cranelift.</p>\n<p>Pull requests addressing this issue should ideally include some measurements showing what effect the change has, because it's theoretically possible that this could make performance worse. I think it's more likely that there won't be much visible effect at all, but these changes shouldn't make the implementation any more complicated and could potentially improve performance. We won't know unless we try it and measure the results.</p>\n<p>There are two kinds of measurements that would be great to do, with Wasmtime built in <code>--release</code> mode.</p>\n<ol>\n<li>\n<p>Run <code>valgrind --tool=dhat target/release/wasmtime compile</code> on some WebAssembly module, both with the version of <code>main</code> you started from and with your patched version. I like to use our <a href=\"https://github.com/bytecodealliance/sightglass/blob/main/benchmarks/pulldown-cmark/benchmark.wasm\">pulldown-cmark</a> benchmark program for this because it's not too small but not too big, so even with the overhead of DHAT's instrumentation it doesn't take too long.</p>\n</li>\n<li>\n<p>Run our <a href=\"https://github.com/bytecodealliance/sightglass\">Sightglass</a> benchmark suite to compare the speed of compiling some benchmark programs with and without your changes. See the instructions in that project's README. For testing this issue, the <code>--stop-after compilation</code> option is useful; these changes should have no effect on the generated code or execution time, so you don't need to measure those.</p>\n</li>\n</ol>\n<h4>Alternatives</h4>\n<p>It's fine to keep using <code>Vec</code>.</p>\n<p>There might be cases where either <code>SmallVec</code>, or our <code>ListPool</code> type from cranelift-entity, are more appropriate than a boxed slice. <code>SmallVec</code> is an especially good choice if most of the time the array would fit in about two machine words, but it occasionally needs to be bigger. <code>ListPool</code> may be a good choice if we have a lot of the same type of array allocated at the same time, and the array elements implement <code>EntityRef</code>, which generally means they're 32-bit indices into an array somewhere else.</p>\n</blockquote>",
        "id": 336564765,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677266573
    },
    {
        "content": "<p>jameysharp labeled <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<h4>Feature</h4>\n<p>When we store a <code>Vec&lt;T&gt;</code> inside another data structure, but never change its length, we can instead store a <code>Box&lt;[T]&gt;</code>.</p>\n<h4>Benefit</h4>\n<p>The size of <code>Vec</code> in memory is three machine words, but a boxed slice is only two machine words long. This doesn't really matter if the array is only stored on the stack. But if it's part of another data structure, switching to boxed slices can reduce the amount of heap memory we allocate. That may improve cache locality and have other performance benefits.</p>\n<h4>Implementation</h4>\n<p>I did a quick experiment along these lines several months ago in commit 68d2ac2a1471a096d021be7f2cb2734843648ab8. That commit has merge conflicts with <code>main</code> now, but it illustrates the basics of how to make this change for one type, <code>Vec&lt;ArgPair&gt;</code>. I suspect there are many other uses of <code>Vec</code> in Cranelift that could have equally simple changes. There may be some in Wasmtime as well, though I'm personally focused on cases in Cranelift.</p>\n<p>Pull requests addressing this issue should ideally include some measurements showing what effect the change has, because it's theoretically possible that this could make performance worse. I think it's more likely that there won't be much visible effect at all, but these changes shouldn't make the implementation any more complicated and could potentially improve performance. We won't know unless we try it and measure the results.</p>\n<p>There are two kinds of measurements that would be great to do, with Wasmtime built in <code>--release</code> mode.</p>\n<ol>\n<li>\n<p>Run <code>valgrind --tool=dhat target/release/wasmtime compile</code> on some WebAssembly module, both with the version of <code>main</code> you started from and with your patched version. I like to use our <a href=\"https://github.com/bytecodealliance/sightglass/blob/main/benchmarks/pulldown-cmark/benchmark.wasm\">pulldown-cmark</a> benchmark program for this because it's not too small but not too big, so even with the overhead of DHAT's instrumentation it doesn't take too long.</p>\n</li>\n<li>\n<p>Run our <a href=\"https://github.com/bytecodealliance/sightglass\">Sightglass</a> benchmark suite to compare the speed of compiling some benchmark programs with and without your changes. See the instructions in that project's README. For testing this issue, the <code>--stop-after compilation</code> option is useful; these changes should have no effect on the generated code or execution time, so you don't need to measure those.</p>\n</li>\n</ol>\n<h4>Alternatives</h4>\n<p>It's fine to keep using <code>Vec</code>.</p>\n<p>There might be cases where either <code>SmallVec</code>, or our <code>ListPool</code> type from cranelift-entity, are more appropriate than a boxed slice. <code>SmallVec</code> is an especially good choice if most of the time the array would fit in about two machine words, but it occasionally needs to be bigger. <code>ListPool</code> may be a good choice if we have a lot of the same type of array allocated at the same time, and the array elements implement <code>EntityRef</code>, which generally means they're 32-bit indices into an array somewhere else.</p>\n</blockquote>",
        "id": 336564766,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677266574
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879#issuecomment-1444316502\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<p>Note that converting from Vec to boxed slice may reallocate to shrink capacity, which may dwarf the benefit.</p>\n</blockquote>",
        "id": 336565643,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677266841
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879#issuecomment-1444349680\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<p>Yeah, that's one reason why measuring the results is important.</p>\n<p>Whether the reallocation occurs depends on how they're constructed. I believe that using <code>Iterator::collect</code> to produce a boxed slice won't reallocate as long as the iterator gives exact results from <code>size_hint</code>, which I think is fairly common in Cranelift. If someone picks up this issue I'll look at specific cases and help figure out whether boxed slices are likely to be a good fit on a case-by-case basis.</p>\n<p>Also, I don't know how expensive it is to reallocate to a smaller layout with Rust's default allocator. My mental model of general-purpose heap allocators is that realloc to a smaller size doesn't copy the memory, just updates metadata in O(1) time. But that's not based on looking at any modern allocators and could be completely wrong. Do you know off-hand?</p>\n</blockquote>",
        "id": 336568869,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677267990
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879#issuecomment-1444369339\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<p>Most allocators divide the heap in different size classes and use mmap directly for very large allocations. If resizing brings you to a smaller size class I wouldn't be surprised if it is necessary to copy the data to a chunk in this new size class. If it doesn't go to a smaller size class, it won't save any memory (except for the capacity field missing) at all as allocation sizes are rounded to the nearest size class. For mmap backed allocations shrinking will perform an expensive munmap syscall. When collecting an iterator directly into a boxed slice where the size hint is correct, collecting it into a vec instead doesn't save any space apart from the capacity field.</p>\n</blockquote>",
        "id": 336570610,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677268681
    },
    {
        "content": "<p>bjorn3 edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879#issuecomment-1444369339\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<p>Most allocators divide the heap in different size classes and use mmap directly for very large allocations. If resizing brings you to a smaller size class I wouldn't be surprised if it is necessary to copy the data to a chunk in this new size class. (At least one allocator I looked at didn't save any size information in the allocation header, but instead derives it from the size class of the chunk in which the allocation is stored) If it doesn't go to a smaller size class, it won't save any memory (except for the capacity field missing) at all as allocation sizes are rounded to the nearest size class. For mmap backed allocations shrinking will perform an expensive munmap syscall. When collecting an iterator directly into a boxed slice where the size hint is correct, collecting it into a vec instead doesn't save any space apart from the capacity field.</p>\n</blockquote>",
        "id": 336570908,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1677268783
    },
    {
        "content": "<p>OLUWAMUYIWA <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879#issuecomment-1687124549\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/5879\">issue #5879</a>:</p>\n<blockquote>\n<p>Hi @jameysharp, I'd like to pick this up. First time here, but I'm up to it.</p>\n</blockquote>",
        "id": 386483074,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1692656210
    }
]