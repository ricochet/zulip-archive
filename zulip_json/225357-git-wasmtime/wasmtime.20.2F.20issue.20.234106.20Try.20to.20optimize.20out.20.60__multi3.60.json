[
    {
        "content": "<p>shamatar <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106#issuecomment-1120115056\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106\">issue #4106</a>:</p>\n<blockquote>\n<p>Now it can match the full body of __multi3 by logical sequence (with allowed variations over parameters in symmetrical opcodes) and replaces it with \"imul\" over I128 type </p>\n</blockquote>",
        "id": 281514134,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1651890845
    },
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106#issuecomment-1423417287\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106\">issue #4106</a>:</p>\n<blockquote>\n<p>@shamatar I'm going through old open PRs and found this; at this point we now have a new mid-end optimization framework that allows rewrites to be written in a more <a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/opts/algebraic.isle\">pattern-matchy way</a>. Would you be willing to try reworking your pattern-matching using that? (No worries if not, we can close this if we're not actively pursuing the optimization any more, or have a tracking issue if we are)</p>\n</blockquote>",
        "id": 326711072,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1675902307
    },
    {
        "content": "<p>shamatar <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106#issuecomment-1424199901\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106\">issue #4106</a>:</p>\n<blockquote>\n<p>Hey @cfallin </p>\n<p>I can try to change to another matcher, but to be able to efficiently use this optimization it's necessary to also be able to inline this function call after internal optimization. Was it added during the time I opened a PR?</p>\n</blockquote>",
        "id": 326816051,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1675949640
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106#issuecomment-1424499791\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106\">issue #4106</a>:</p>\n<blockquote>\n<p>No, we don't have inlining yet, and yes that would help a lot. But we're finding there are a lot of opportunities for peephole optimizations. If we could reduce the body of <code>__multi3</code> to a single CLIF <code>imul.i128</code> instruction, that might still make a big difference, even with call overhead and missing opportunities from some inputs always being zero. If we can do that using more general peephole optimizations, then we can improve performance of other code besides <code>__multi3</code>, making the effort even more worth-while.</p>\n<p>I was recently investigating performance improvements for big-integer math. I added <a href=\"https://github.com/bytecodealliance/sightglass/tree/main/benchmarks/blind-sig\">https://github.com/bytecodealliance/sightglass/tree/main/benchmarks/blind-sig</a> as a small benchmark that we can study. And indeed, <code>__multi3</code> was a huge hotspot there. So I'd love to explore how people can get better performance from this stuff.</p>\n<p>One thing I learned is that the <code>u64_digit</code> feature of the <a href=\"https://crates.io/crates/num-bigint-dig\">num-bigint-dig</a> crate is quite bad for WebAssembly targets. That feature makes the \"limbs\" of a big integer 64-bits wide, which means it needs 128-bit integers for math on intermediate results, which leads to calling <code>__multi3</code>. Disabling that feature makes limbs 32-bit and intermediate products 64-bit, which means all values fit in native wasm types, and LLVM stops using <code>__multi3</code> to simulate wider types. I saw something like 8-15% performance improvements from that change alone in my little benchmark.</p>\n<p>Other ways to eliminate this function specifically might be worth investigating. Inlining <code>__multi3</code> in the wasm binary could be an option, either by changing LLVM to not do a libcall here, or by making some specialized wasm inliner using something like binaryen. In either case we wouldn't be doing the inlining in Cranelift, but encouraging developers to produce more efficient wasm in the first place.</p>\n<p>In short: I think there's a lot we can improve even without making Cranelift support inlining, and this PR is a good start which I'd love to get finished up.</p>\n</blockquote>",
        "id": 326864015,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1675961358
    },
    {
        "content": "<p>shamatar <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106#issuecomment-1433755397\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/4106\">issue #4106</a>:</p>\n<blockquote>\n<p>As practice shows integer math in WASM is still better to be u32 words based one (recent ZPrize works). It'll be nice to have an option to match our __mul subroutine, but inlining is very desirable </p>\n</blockquote>",
        "id": 328342476,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1676584044
    }
]