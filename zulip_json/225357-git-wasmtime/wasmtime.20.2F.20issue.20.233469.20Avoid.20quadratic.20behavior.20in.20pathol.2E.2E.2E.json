[
    {
        "content": "<p>cfallin <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3469#issuecomment-948983692\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3469\">issue #3469</a>:</p>\n<blockquote>\n<blockquote>\n<p>Out of further curiosity, even 70ms for a function like this seems somewhat high, is that still due to MachBuffer things or is it general \"too much elbow grease is needed to bring that down further\"</p>\n</blockquote>\n<p>I think it is mostly in the middle-end (analyses and optimizations), which will see the huge CFG with all the loops before it's reduced. The backend stages that are specifically broken out in the <code>clif-util wasm -T</code> output show: 3ms in CLIF -&gt; VCode lowering; 4ms in regalloc; and 4ms in binary emission (MachBuffer + cpu-specific instruction encoding code). So only 10ms in the \"backend\" and the rest in attempted optimization.</p>\n<p>A <code>perf</code> profile of the compilation shows a lot of time in the kernel's pagefault path, so I think that just writing out the data structures has some overhead (for the large function body). I imagine we could probably be smarter about early optimizations that cut down the amount of work the later stages have to do; but nothing immediately obviously or anomalously bad is happening here, I think. </p>\n</blockquote>",
        "id": 258613109,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1634848545
    },
    {
        "content": "<p>cfallin edited a <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3469#issuecomment-948983692\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3469\">issue #3469</a>:</p>\n<blockquote>\n<blockquote>\n<p>Out of further curiosity, even 70ms for a function like this seems somewhat high, is that still due to MachBuffer things or is it general \"too much elbow grease is needed to bring that down further\"</p>\n</blockquote>\n<p>I think it is mostly in the middle-end (analyses and optimizations), which will see the huge CFG with all the loops before it's reduced. The backend stages that are specifically broken out in the <code>clif-util wasm -T</code> output show: 3ms in CLIF -&gt; VCode lowering; 4ms in regalloc; and 4ms in binary emission (MachBuffer + cpu-specific instruction encoding code). So only 11ms (EDIT: I can add I promise) in the \"backend\" and the rest in attempted optimization.</p>\n<p>A <code>perf</code> profile of the compilation shows a lot of time in the kernel's pagefault path, so I think that just writing out the data structures has some overhead (for the large function body). I imagine we could probably be smarter about early optimizations that cut down the amount of work the later stages have to do; but nothing immediately obviously or anomalously bad is happening here, I think. </p>\n</blockquote>",
        "id": 258613248,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1634848599
    }
]