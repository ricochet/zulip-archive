[
    {
        "content": "<p>fitzgen edited <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<blockquote>\n<p>I'm having a hard time figuring out the details of s390x here, so I am going to disable support for the <code>tail</code> calling convention on s390x (with a loud assertion) to land this PR. We can get s390x working in follow ups.</p>\n</blockquote>\n<p>_Originally posted by @fitzgen in <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6500#issuecomment-1579427510_\">https://github.com/bytecodealliance/wasmtime/issues/6500#issuecomment-1579427510_</a></p>\n</blockquote>",
        "id": 376747812,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1689789209
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-1642510442\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Hey @uweigand, would really appreciate your help here. There are two things that need to be done (or at least, I have done it with these two different steps for the other backends):</p>\n<ol>\n<li>\n<p><strong>Get regular, non-tail calls working with the <code>tail</code> calling convention.</strong></p>\n<p>This has involved modifying the calling convention such that callees (rather than callers) pop stack arguments as part of their function epilogue and before/at the same time as returning to their caller.</p>\n<p>There is <a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/filetests/filetests/runtests/tail-call-conv.clif\">a runtest that use the <code>tail</code> calling convention without actually doing tail calls</a>, it is currently disabled on s390x but would presumably be enabled during this step. I also recommend copying that test to <code>filetests/isa/x390x</code> and turning it into a <code>compile precise-output</code> test as well, which the other backends have done too.</p>\n</li>\n<li>\n<p><strong>Implement tail calls.</strong></p>\n<p>These are only valid CLIF when both the caller and callee use the <code>tail</code> calling convention, so that is something we can rely upon.</p>\n<p>None of the other backends have been doing parallel move solving during tail calls to make sure new arguments end up in the correct locations without overwriting old arguments that are on the stack but become new arguments elsewhere on the stack in the tail call. Instead, they bump SP and construct a temporary frame and then move the frame down on top of the current frame and then initialize SP for the callee. I recommend starting with this simple approach, and we can later do parallel move solving as an optimization, but whatever works for you.</p>\n<p>There are a few runtests for exercising tail calls: <code>filetests/runtests/return-call{.clif,-indirect.clif,-loop.clif}</code>. Each backend also has a copy of <code>return-call.clif</code> (which actually covers both colocated and not calls) to their ISA-specific tests as <code>compile precise-output</code> tests, and I recommend that s390x has a copy as well.</p>\n<p>I've been adding <code>emit_return_call</code> methods to each backend's <code>abi::CallSite&lt;M&gt;</code> instantiation, so that the top-level entry is arch-specific rather than going through a common generic helper. The ISLE lowering calls the external <code>gen_return_call[_indirect]</code> constructor, which each backend implements. This external constructor creates an <code>abi::CallSite&lt;MyBackend&gt;</code> and then calls its <code>emit_return_call</code> method. There is a generic helper to create the temporary tail call frame that you can use if you want, but in general you have direct control of everything we do here, you don't have to fit into the shape of generic hooks and callbacks. I think it is easier to read and write the code this way, hopefully you find the same.</p>\n<p>For reference, the last commit in <a href=\"https://github.com/bytecodealliance/wasmtime/pull/6749\">https://github.com/bytecodealliance/wasmtime/pull/6749</a> shows what implementing tail calls for riscv64 entailed. It was pretty straightforward, and hopefully can serve as a template to reference and crib from for s390x.</p>\n</li>\n</ol>\n<p>Don't hesitate to reach out with any questions or clarifications or anything like that! Thanks very much!</p>\n</blockquote>",
        "id": 376747822,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1689789214
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-1642511982\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Oh also, since Wasmtime will use the <code>tail</code> calling convention for all Wasm functions, I think we need to mark the <code>tail</code> calling convention as having little endian lane ordering on s390x. I am not sure where that change needs to be made.</p>\n</blockquote>",
        "id": 376748107,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1689789288
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-1644131763\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<blockquote>\n<p>This has involved modifying the calling convention such that callees (rather than callers) pop stack arguments as part of their function epilogue and before/at the same time as returning to their caller.</p>\n</blockquote>\n<p>This is probably the core of the problem - in the current s390x ABI, <em>neither</em> callers nor callees pop stack arguments as part of the calling sequence.  Instead, the stack pointer stays constant around calls, and the space for all arguments for all calls the current function may ever make is statically allocated in its prologue.   Therefore the tail calling convention will have to be implemented differently, either by switching over to a completely different convention that actually pushes/pops argument space around calls, or by some other means like allowing calls to not preserve the stack pointer (which in turn would enforce use of a frame pointer, which we also currently do not have on s390x ...).</p>\n<p>I'll need to look into those options a bit more, but I won't get to this before I'm back from vacation in early August.<br>\n</p>\n</blockquote>",
        "id": 377022787,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1689866721
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2112837917\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Here's finally my current design of a tail-call ABI for s390x.</p>\n<p>The SystemV ABI has the following stack layout:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//! CFA                  -----&gt;  | stack args                |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | 160 bytes reg save area   |</span>\n<span class=\"sd\">//!                              | (used to save GPRs)       |</span>\n<span class=\"sd\">//! SP at function entry -----&gt;  | (incl. caller's backchain)|</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | clobbered callee-saves    |</span>\n<span class=\"sd\">//!                              | (used to save FPRs)       |</span>\n<span class=\"sd\">//! unwind-frame base     ----&gt;  | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | spill slots               |</span>\n<span class=\"sd\">//!                              | (accessed via nominal SP) |</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | stack slots               |</span>\n<span class=\"sd\">//!                              | (accessed via nominal SP) |</span>\n<span class=\"sd\">//! nominal SP ---------------&gt;  | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | outgoing calls return buf |</span>\n<span class=\"sd\">//!                              | outgoing calls args       |</span>\n<span class=\"sd\">//!                              | outgoing reg save area    |</span>\n<span class=\"sd\">//!                              | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//! SP during function  ------&gt;  | (incl. callee's backchain)|</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n</code></pre></div>\n<p>The new tail-call ABI would instead use this layout:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//! CFA                  -----&gt;  | (caller's frame)          |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | 160 bytes reg save area   |</span>\n<span class=\"sd\">//!                              | (used to save GPRs)       |</span>\n<span class=\"sd\">//! SP at function return-----&gt;  | (incl. caller's backchain)|</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | incoming stack args       |</span>\n<span class=\"sd\">//! SP at function entry -----&gt;  | (incl. backchain copy)    |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | outgoing tail call args   |</span>\n<span class=\"sd\">//!                              | (overlaps incoming args)  |</span>\n<span class=\"sd\">//!                              | (incl. backchain copy)    |</span>\n<span class=\"sd\">//! SP at tail cail       ----&gt;  | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | clobbered callee-saves    |</span>\n<span class=\"sd\">//!                              | (used to save FPRs)       |</span>\n<span class=\"sd\">//! unwind-frame base     ----&gt;  | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | spill slots               |</span>\n<span class=\"sd\">//!                              | (accessed via nominal SP) |</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | stack slots               |</span>\n<span class=\"sd\">//!                              | (accessed via nominal SP) |</span>\n<span class=\"sd\">//! nominal SP ---------------&gt;  | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | outgoing calls return buf |</span>\n<span class=\"sd\">//!                              | outgoing reg save area    |</span>\n<span class=\"sd\">//!                              | (alloc'd by prologue)     |</span>\n<span class=\"sd\">//! SP during function  ------&gt;  | (incl. callee's backchain)|</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n<span class=\"sd\">//!                              |          ...              |</span>\n<span class=\"sd\">//!                              | outgoing stack args       |</span>\n<span class=\"sd\">//!                              | (alloc'd by call sequence)|</span>\n<span class=\"sd\">//! SP at non-tail call  -----&gt;  | (incl. backchain copy)    |</span>\n<span class=\"sd\">//!                              +---------------------------+</span>\n</code></pre></div>\n<p>Notably, the handling of the stack backchain with this tail-call ABI remains fully compatible with the SystemV ABI.  Existing unwinder routines should be able to correctly unwind through any combination of SystemV and tail-call ABI frames.  To enable asynchronous unwinding during the call sequence, we store copies of the innermost backchain value at the bottom of the outgoing (or tail-call) argument area.  These only remain live during the call sequence, they are no longer accessed after the call sequence is completed by the callee setting up it's own stack frame.  Note that if unwinding during that period is not required, it would be possible to omit storing those copies to avoid some overhead.</p>\n<p>In addition, the tail-call ABI would use both <code>r6</code> and <code>r7</code> as argument registers, and make them both non-callee-saved.  (<code>r6</code> is a callee-saved argument register in the SystemV ABI, which is incompatible with tail calls.  As we're making changes anway, it makes sense to also change <code>r7</code> so we have 6 argument registers instead of 5.)</p>\n<p>To implement the new ABI, the following changes would need to be made:</p>\n<ol>\n<li>Tail-call ABI prologue:</li>\n</ol>\n<ul>\n<li>Save callee-saved GPRs into incoming reg save area</li>\n<li>Compute size of tail-call argument area (extending incoming argument area)</li>\n<li>Allocate local stack frame, including<ul>\n<li>tail-call argument area</li>\n<li>clobbered callee-saves area</li>\n<li>spill slots</li>\n<li>stack slots</li>\n<li>outgoing calls return buffer</li>\n<li>outgoing reg save area</li>\n</ul>\n</li>\n<li>Store backchain, pointing to caller's backchain (not the copy!)</li>\n<li>Save callee-saved FPRs into callee-saves area</li>\n</ul>\n<p>(Overhead compared to SystemV ABI: compute backchain value; none if no incoming stack args)</p>\n<ol start=\"2\">\n<li>Tail-call ABI epilogue:</li>\n</ol>\n<ul>\n<li>Restore callee-saved FPRs from callee-saves area</li>\n<li>Restore callee-saved GPRs (except SP, including %r14) from incoming reg save area</li>\n<li>Restore SP to value at function return (popping incoming args area)</li>\n<li>Return by branching to (restored) %r14</li>\n</ul>\n<p>(Overhead compared to SystemV ABI: compute restored SP; none if no incoming stack args)</p>\n<ol start=\"3\">\n<li>Tail-call sequence:</li>\n</ol>\n<ul>\n<li>(If present) Construct outgoing args into (possibly extended) incoming args area<ul>\n<li>Includes storing copy of caller's backchain to the bottom of the outgoing args</li>\n</ul>\n</li>\n<li>Load up arguments into registers</li>\n<li>(If present) restore return buffer address register to incoming value</li>\n<li>Restore callee-saved FPRs from callee-saves area</li>\n<li>Restore callee-saved GPRs (except SP, including %r14) from incoming reg save area</li>\n<li>Set SP to bottom of outgoing args area for this call</li>\n<li>Jump to target address</li>\n</ul>\n<p>(Overhead compared to SystemV ABI: n/a, doesn't have tail calls)</p>\n<ol start=\"4\">\n<li>Non-tail calls:</li>\n</ol>\n<ul>\n<li>(If present) Set up outgoing args area<ul>\n<li>Allocate area by decrementing stack pointer</li>\n<li>Store copy of callee's backchain to the bottom of the outgoing args</li>\n<li>Construct outgoing args into outgoing args area</li>\n</ul>\n</li>\n<li>Load up arguments into register</li>\n<li>(If present) set up return buffer address register to return buffer</li>\n<li>Perform function call (storing return address into %r14)</li>\n<li>Retrieve return values from registers and/or return buffer</li>\n</ul>\n<p>(Overhead compared to SystemV ABI: allocating outgoing args area &amp; storing backchain copy; none if no outgoing stack args)</p>\n<p>Cross-calling-convention calls would also be possible:</p>\n<ol>\n<li>SystemV ABI to tail-call ABI</li>\n</ol>\n<ul>\n<li>mostly the same as tail-call to tail-call calls</li>\n<li>GPRs 6 and 7 must be considered clobbered by callee</li>\n</ul>\n<ol start=\"2\">\n<li>tail-call ABI to SystemV ABI</li>\n</ol>\n<ul>\n<li>allocate outgoing args in caller's frame as for SystemV ABI</li>\n</ul>\n<p>CC @elliottt @jameysharp @cfallin </p>\n</blockquote>",
        "id": 438828607,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1715786313
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2112994803\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Noting my comment from today's Cranelift meeting for posterity: the async stack walking doesn't seem too important (can be relegated to a default off setting, imo) if we preserve the invariant on s390x that other backends have that we don't interleave argument evaluation with calling convention code. This would be easy to do, and wouldn't require moving s390x to the shared ABI framework code, by having s390x's calling convention code in ISLE take <code>Reg</code>s rather than <code>Value</code>s, forcing the evaluation to happen at the boundary before we begin calling convention stuff.</p>\n<p>Ulrich, you mentioned that this would prevent us from performing an existing sign-/zero-extend optimization. I guess my question then is which has more overhead: missing that optimization or storing a copy of the backchain?</p>\n</blockquote>",
        "id": 438843988,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1715790899
    },
    {
        "content": "<p>fitzgen edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2112994803\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Noting my comment from today's Cranelift meeting for posterity: the async stack walking doesn't seem too important (can be relegated to a default off setting, imo) if we preserve the invariant on s390x that other backends have that we don't interleave argument evaluation with calling convention code (since argument evaluation can trap, and we <em>must</em> be able to walk the stack at trap sites. This would be easy to do, and wouldn't require moving s390x to the shared ABI framework code, by having s390x's calling convention code in ISLE take <code>Reg</code>s rather than <code>Value</code>s, forcing the evaluation to happen at the boundary before we begin calling convention stuff.</p>\n<p>Ulrich, you mentioned that this would prevent us from performing an existing sign-/zero-extend optimization. I guess my question then is which has more overhead: missing that optimization or storing a copy of the backchain?</p>\n</blockquote>",
        "id": 438844095,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1715790941
    },
    {
        "content": "<p>fitzgen edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2112994803\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>Noting my comment from today's Cranelift meeting for posterity: the async stack walking doesn't seem too important (can be relegated to a default off setting, imo) if we preserve the invariant on s390x that other backends have that we don't interleave argument evaluation with calling convention code (since argument evaluation can trap, and we <em>must</em> be able to walk the stack at trap sites). This would be easy to do, and wouldn't require moving s390x to the shared ABI framework code, by having s390x's calling convention code in ISLE take <code>Reg</code>s rather than <code>Value</code>s, forcing the evaluation to happen at the boundary before we begin calling convention stuff.</p>\n<p>Ulrich, you mentioned that this would prevent us from performing an existing sign-/zero-extend optimization. I guess my question then is which has more overhead: missing that optimization or storing a copy of the backchain?</p>\n</blockquote>",
        "id": 438844211,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1715790971
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2252796096\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>I've now completed a prototype implementation of the above design.  This sucessfully passes all tests (including the wasm tail-call tests), with one execption: <code>gc_and_tail_calls_and_stack_arguments</code>.</p>\n<p>Unfortunately, this indicates a fundamental problem: the above design requires dynamic stack adjustments around calls.  However, common code support for that was removed recently.  I thought I could work around this in the back-end, and that does indeed work fine for code generation - but then common code gets the stack maps at call sites wrong, as it no longer takes this dynamic adjustment into account.</p>\n<p>So at this point we can either add that common code support back, or else re-design the ABI to avoid dynamic stack adjustments.  The latter is a bit tricky if we want to avoid frequent copying of the back chain value.  I'll need to think about that more.<br>\n</p>\n</blockquote>",
        "id": 454301712,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722001407
    },
    {
        "content": "<p>jameysharp <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2253399909\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>I haven't been able to focus on this enough to understand what problem you're solving with dynamic stack adjustments, but I think we wanted to do something similar enough someday in other backends that it may be worth talking through how to get this right in common code.</p>\n<p>In particular, to keep things simple, @elliottt and I placed outgoing arguments at the bottom of the outgoing argument area, so the stack pointer is always in the same place on entry to a call. But we planned eventually to place those arguments at the top of the outgoing argument area instead and move the stack pointer before and after the call, to reduce stack usage in deeply nested call stacks. I'm not sure but perhaps that would mean we would run into the same issue you're seeing with stack maps.</p>\n<p>Of course, @fitzgen is currently working on significant changes to the stack map infrastructure, which might also change this situation, I'm not sure.</p>\n</blockquote>",
        "id": 454361677,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722023996
    },
    {
        "content": "<p>fitzgen <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2253691233\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<p>While walking the stack to identify on-stack GC roots, the runtime is given a series of frame pointers (backchains on s390x) and PCs for each frame. It looks up the appropriate stack map metadata based on the PC. The stack map provides the offset-from-SP of every GC root in the stack frame and the size of the stack frame that it is mapping. The runtime takes the frame's FP, subtracts the stack map's frame size from FP, which yields the SP. It then uses the stack map and the SP to note all of the live, on-stack GC roots.</p>\n<p>(I have a branch that is <em>just</em> not quite ready yet to move Wasmtime over from the \"old\" stack maps (current situation) to the new \"user\" stack maps (stuff myself and Trevor have been poking at the last couple weeks). But it shouldn't actually change anything with regards to the above; all that should be just as true for the new system as it is for the old system.)</p>\n<p>All this to say: If you are adjusting the SP at call sites, then it is possible (likely?) that the frame size noted in the stack maps have gotten out of sync with the frame's actual size, which could explain why that test is failing.</p>\n<p>Some relevant bits of code:</p>\n<ul>\n<li>The method that the new \"user\" stack maps use to get the frame size: <a href=\"https://github.com/bytecodealliance/wasmtime/blob/3767f76b487959194b10ec9e17ddb8d1c3a37116/cranelift/codegen/src/machinst/abi.rs#L986\">https://github.com/bytecodealliance/wasmtime/blob/3767f76b487959194b10ec9e17ddb8d1c3a37116/cranelift/codegen/src/machinst/abi.rs#L986</a></li>\n<li>The open-coded version of getting the frame size for the \"old\" stack maps: <a href=\"https://github.com/bytecodealliance/wasmtime/blob/3767f76b487959194b10ec9e17ddb8d1c3a37116/cranelift/codegen/src/machinst/abi.rs#L1661\">https://github.com/bytecodealliance/wasmtime/blob/3767f76b487959194b10ec9e17ddb8d1c3a37116/cranelift/codegen/src/machinst/abi.rs#L1661</a></li>\n</ul>\n<p>The stack maps are then passed to the <code>EmitState</code> via the <code>pre_safepoint</code> method. Then they are taken out of the <code>EmitState</code> during via <code>take_stack_map</code> calls when emitting a call/call-indirect instruction in the backends. It seems like maybe updating the frame size of the stack map in this call-emit code, if you adjust the SP for the call, might be the easiest solution here.</p>\n</blockquote>",
        "id": 454401137,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722042973
    },
    {
        "content": "<p>uweigand <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2256037782\">commented</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<blockquote>\n<p>While walking the stack to identify on-stack GC roots, the runtime is given a series of frame pointers (backchains on s390x) and PCs for each frame. It looks up the appropriate stack map metadata based on the PC. The stack map provides the offset-from-SP of every GC root in the stack frame and the size of the stack frame that it is mapping. The runtime takes the frame's FP, subtracts the stack map's frame size from FP, which yields the SP. It then uses the stack map and the SP to note all of the live, on-stack GC roots.</p>\n</blockquote>\n<p>Thanks for the explanation!  With this approach, \"local\" SP manipulations around call sites should actually not affect use of the stack map at all, as long as runtime unwinding provides correct frame pointer values and the stack map provides the correct size of the \"nominal\" stack.</p>\n<blockquote>\n<p>All this to say: If you are adjusting the SP at call sites, then it is possible (likely?) that the frame size noted in the stack maps have gotten out of sync with the frame's actual size, which could explain why that test is failing.</p>\n</blockquote>\n<p>And this was indeed the case, but not because of SP adjusting, but because the frame size of tail call frames was just generally wrong.  In my approach, incoming tail call arguments are part of the <em>callee</em>'s frame (as opposed to the caller's), and therefore must be accounted as part of the callee's frame size.</p>\n<p>With this fixed, I now see the GC test (and all other tests) pass.</p>\n<p>I'll have to do a bit more cleanup, and then I should be ready to post a PR.</p>\n<blockquote>\n<p>I haven't been able to focus on this enough to understand what problem you're solving with dynamic stack adjustments, but I think we wanted to do something similar enough someday in other backends that it may be worth talking through how to get this right in common code.</p>\n</blockquote>\n<p>To elaborate on that: in the s390x ABI we do not have a frame pointer, but instead stack backtracing works by having a stack \"backchain\" that is always present directly at the location the stack pointer points to.   This is usually quite efficient, but has the drawback that any adjustment of the stack pointer requires also updating the back chain field - unless you can prove it must have already been set in the past.  In particular, for function return in the current ABI, we know that we'll restore SP back to where the caller already placed the correct backchain value, so we do not have to re-write the backchain on every return.</p>\n<p>With the approach you're currently taking for tail calls on Intel and ARM, however, incoming tail call arguments are part of the caller's frame, and so are outgoing arguments.  This may require growing the <em>caller</em>'s frame.  If we were to do that on s390x, that growing stack frame would overwrite the caller's backchain value, and would require us to re-write a backchain on every return (actually only on every return from a tail-call chain that somewhere grew the frame, but as we don't know whether this is the case, we'd in fact have to re-write on every return).  This would be quite some overhead, which I'm avoiding by making tail call arguments always part of the <em>callee</em>'s frame.  But that means the caller has to start allocated that bit of the callee's frame and therefore temporarily adjust SP around the call site.<br>\n</p>\n</blockquote>",
        "id": 454844500,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722261853
    },
    {
        "content": "<p>uweigand edited a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530#issuecomment-2256037782\">comment</a> on <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<blockquote>\n<p>While walking the stack to identify on-stack GC roots, the runtime is given a series of frame pointers (backchains on s390x) and PCs for each frame. It looks up the appropriate stack map metadata based on the PC. The stack map provides the offset-from-SP of every GC root in the stack frame and the size of the stack frame that it is mapping. The runtime takes the frame's FP, subtracts the stack map's frame size from FP, which yields the SP. It then uses the stack map and the SP to note all of the live, on-stack GC roots.</p>\n</blockquote>\n<p>Thanks for the explanation!  With this approach, \"local\" SP manipulations around call sites should actually not affect use of the stack map at all, as long as runtime unwinding provides correct frame pointer values and the stack map provides the correct size of the \"nominal\" stack.</p>\n<blockquote>\n<p>All this to say: If you are adjusting the SP at call sites, then it is possible (likely?) that the frame size noted in the stack maps have gotten out of sync with the frame's actual size, which could explain why that test is failing.</p>\n</blockquote>\n<p>And this was indeed the case, but not because of SP adjusting, but because the frame size of tail call frames was just generally wrong.  In my approach, incoming tail call arguments are part of the <em>callee</em>'s frame (as opposed to the caller's), and therefore must be accounted as part of the callee's frame size.</p>\n<p>With this fixed, I now see the GC test (and all other tests) pass.</p>\n<p>I'll have to do a bit more cleanup, and then I should be ready to post a PR.</p>\n<blockquote>\n<p>I haven't been able to focus on this enough to understand what problem you're solving with dynamic stack adjustments, but I think we wanted to do something similar enough someday in other backends that it may be worth talking through how to get this right in common code.</p>\n</blockquote>\n<p>To elaborate on that: in the s390x ABI we do not have a frame pointer, but instead stack backtracing works by having a stack \"backchain\" that is always present directly at the location the stack pointer points to.   This is usually quite efficient, but has the drawback that any adjustment of the stack pointer requires also updating the back chain field - unless you can prove it must have already been set in the past.  In particular, for function return in the current ABI, we know that we'll restore SP back to where the caller already placed the correct backchain value, so we do not have to re-write the backchain on every return.</p>\n<p>With the approach you're currently taking for tail calls on Intel and ARM, however, incoming tail call arguments are part of the caller's frame, and so are outgoing arguments.  This may require growing the <em>caller</em>'s frame.  If we were to do that on s390x, that growing stack frame would overwrite the caller's backchain value, and would require us to re-write a backchain on every return (actually only on every return from a tail-call chain that somewhere grew the frame, but as we don't know whether this is the case, we'd in fact have to re-write on every return).  This would be quite some overhead, which I'm avoiding by making tail call arguments always part of the <em>callee</em>'s frame.  But that means the caller has to start allocating that bit of the callee's frame and therefore temporarily adjust SP around the call site.<br>\n</p>\n</blockquote>",
        "id": 454845117,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722261974
    },
    {
        "content": "<p>fitzgen closed <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6530\">issue #6530</a>:</p>\n<blockquote>\n<blockquote>\n<p>I'm having a hard time figuring out the details of s390x here, so I am going to disable support for the <code>tail</code> calling convention on s390x (with a loud assertion) to land this PR. We can get s390x working in follow ups.</p>\n</blockquote>\n<p>_Originally posted by @fitzgen in <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6500#issuecomment-1579427510_\">https://github.com/bytecodealliance/wasmtime/issues/6500#issuecomment-1579427510_</a></p>\n</blockquote>",
        "id": 455750136,
        "sender_full_name": "Wasmtime GitHub notifications bot",
        "timestamp": 1722543764
    }
]