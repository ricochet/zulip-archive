[
    {
        "content": "<p>glandium opened <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>This is especially a problem when building with opt-level=2, since cargo doesn't know to apply the optimization level only to target code, while cranelift-codegen-meta is host code.</p>\n<p>Interestingly, the build time for the cranelift-codegen-meta is dominated by LLVM (80 to 90% of the time), mostly spend between multiple LLVM module passes, LTO passes and codegen passes.</p>\n<p>This seems to be mostly caused by the size of <code>shared::instructions::define</code> and <code>shared::legalize::define</code>.</p>\n<p>Cc: @alexcrichton </p>\n</blockquote>",
        "id": 184989801,
        "sender_full_name": "GitHub",
        "timestamp": 1578384452
    },
    {
        "content": "<p>glandium edited <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>This is especially a problem when building with opt-level=2, since cargo doesn't know to apply the optimization level only to target code, while cranelift-codegen-meta is host code.</p>\n<p>Interestingly, the build time for the cranelift-codegen-meta is dominated by LLVM (80 to 90% of the time), mostly spent between multiple LLVM module passes, LTO passes and codegen passes.</p>\n<p>This seems to be mostly caused by the size of <code>shared::instructions::define</code> and <code>shared::legalize::define</code>.</p>\n<p>Cc: @alexcrichton </p>\n</blockquote>",
        "id": 184989882,
        "sender_full_name": "GitHub",
        "timestamp": 1578384524
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-571629446\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-571629446\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>I don't know much about this crate and haven't really analyzed it much before, but massive functions are known to cause perfomance issues in LLVM, mostly because we can't parallelize anything about them. Crates have been found in the past to be 90% dominated by one function, and the compile time of the crate drastically increases when the functions become smaller. If the two functions there are abnormally large the best thing to do for compile times is probably to figure out a way to shrink the functions and let LLVM take care of inlining and such as necessary.</p>\n</blockquote>",
        "id": 185019584,
        "sender_full_name": "GitHub",
        "timestamp": 1578410116
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-571709749\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-571709749\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>Those functions (and maybe also ISA-specific ones like <code>isa::x86::encodings::define</code>) could probably be split up into smaller functions; any suggestions on how to organize the instructions?</p>\n</blockquote>",
        "id": 185038431,
        "sender_full_name": "GitHub",
        "timestamp": 1578421434
    },
    {
        "content": "<p>bnjbvr <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-572025551\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-572025551\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>Fwiw, I've looked into this a bit today. Unfortunately I misread the initial comment and thought that <code>x86::encodings::define</code> was the biggest offender. I started splitting <code>shared::instructions::define</code> though, to get an idea of what it would take.</p>\n<p>@glandium How did you find out this function was the biggest offender? I found about <code>rustc -Z self-profile</code> (<a href=\"https://github.com/rust-lang/measureme/blob/master/summarize/Readme.md\" target=\"_blank\" title=\"https://github.com/rust-lang/measureme/blob/master/summarize/Readme.md\">this</a>, but it gives a very high-level information about which passes took time, and it doesn't seem to work on Nightly right away.</p>\n<p>I tried to group x86 encodings by <a href=\"https://github.com/bnjbvr/cranelift/blob/split-define-encodings/cranelift-codegen/meta/src/isa/x86/encodings.rs#L2362-L2371\" target=\"_blank\" title=\"https://github.com/bnjbvr/cranelift/blob/split-define-encodings/cranelift-codegen/meta/src/isa/x86/encodings.rs#L2362-L2371\">instruction category</a>. Names and groups to be bikeshedded of course, but it seems fairly consistent.</p>\n<p>Regarding instruction definitions, things needs to be done carefully there: bindings for typevars and operands are consistently rewritten in the file (which was a shortcut taken when porting the meta code from Python). So I've tried to make it so that the split function wouldn't redefine these bindings, by reducing their lifetimes (through the use of smaller block scopes), and define typevars/operands very closely to the instruction definition. If anybody wanted to pick up this work, they should do the same to clean this technical debt.</p>\n<p>Diffing the output of the meta crate generated folder before/after the patch only showed differences of orderings in Encodings, and not a single difference in instructions. It's a bit unfortunate we can't just sort the encodings once they're defined, because they store their index into the containing vector (not sure why...).</p>\n<p>This is dumb, repetitive work, but wallclock measurements show a 3% speedup in compile time (with Rust stable), so it's definitely worth continuing. If anybody wants to take the rest of this over, please feel free to do so!</p>\n</blockquote>",
        "id": 185104343,
        "sender_full_name": "GitHub",
        "timestamp": 1578486250
    },
    {
        "content": "<p>abrown <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-572179003\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-572179003\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>Yeah, definitely not fun work. I merged #1322 and here are things that I think remain:</p>\n<ul>\n<li>[ ] finish separating out <code>shared::instructions::define</code> into <code>alu</code>, <code>fpu</code>, <code>memory</code>, <code>move</code>, <code>simd</code> (others?)</li>\n<li>[ ] separate out shared legalizations <code>shared::legalize::define</code></li>\n<li>[ ] separate out x86 legalizations <code>x86::legalize::define</code></li>\n</ul>\n</blockquote>",
        "id": 185137498,
        "sender_full_name": "GitHub",
        "timestamp": 1578505396
    },
    {
        "content": "<p>alexcrichton <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-573251388\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-573251388\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>I was digging in to this a bit today, and to give a bit of an idea of what's going on, here's some data for this:</p>\n<p>First I executed the following to gather data:</p>\n<div class=\"codehilite\"><pre><span></span>$ cargo +nightly rustc --release -p cranelift-codegen-meta -- -Z self-profile -C save-temps -Z time-passes <span class=\"m\">2</span>&gt;<span class=\"p\">&amp;</span><span class=\"m\">1</span> <span class=\"p\">|</span> tee out.log\n</pre></div>\n\n\n<p>That basically compiled this crate with a bunch of extra flags to help debugging later. Next I used the <a href=\"https://github.com/rust-lang/measureme/\" target=\"_blank\" title=\"https://github.com/rust-lang/measureme/\"><code>measurme</code> repository's <code>crox</code> tool</a> to generate some data in chrome:</p>\n<div class=\"codehilite\"><pre><span></span>$ ../measureme/target/release/crox ./cranelift_codegen_meta-17489 --collapse-threads --minimum-duration <span class=\"m\">10</span>\n</pre></div>\n\n\n<p>which gave this picture:</p>\n<p>![image](<a href=\"https://user-images.githubusercontent.com/64996/72193990-7e65be80-33d1-11ea-9f6b-6a4d90adf19b.png\" target=\"_blank\" title=\"https://user-images.githubusercontent.com/64996/72193990-7e65be80-33d1-11ea-9f6b-6a4d90adf19b.png\">https://user-images.githubusercontent.com/64996/72193990-7e65be80-33d1-11ea-9f6b-6a4d90adf19b.png</a>)</p>\n<p>From this it's clear that there's 1 CGU which is taking forever. Thread 11 performs initial optimizations and Thread 2 later picks it up for ThinLTO passes. Because it's taking so long your machine is basically sitting idle while it's optimizing that CGU except for one core, which generally isn't great. </p>\n<p>Unfortunately I don't know of a great way to go from this graph to <em>which</em> CGU that is. To do that I cross-referenced the graphical timing data with the output of <code>-Ztime-passes</code>  which led me to conclude that <code>cranelift_codegen_meta.d20hpyi0-cgu.8</code> is the offending CGU here. I passed <code>-C save-temps</code> so next I ran <code>find target -name '*cranelift_codegen_meta.d20hpyi0-cgu.8*'</code> and then ran <code>llvm-dis</code> over that file.</p>\n<p>Next I had a different tool which I wrote for something else a long time ago which yielded the number of instructions per function in this CGU:</p>\n<div class=\"codehilite\"><pre><span></span>        core::ptr::real_drop_in_place::h8a707b6e0f5fa37b: 27\n        core::ptr::real_drop_in_place::he03fad37f2658b56: 69\n        core::ptr::real_drop_in_place::h61e657fcd74d9eb5: 87\n        core::ptr::real_drop_in_place::hc09e686cac34d126: 188\n        cranelift_codegen_meta::shared::instructions::define_control_flow::hb9bff9385b83a94b: 13458\n        cranelift_codegen_meta::shared::instructions::define::h304f7623765f3c04: 71636\n</pre></div>\n\n\n<p>so clearly the <code>define</code> function is huge! There's only 6 functions in this CGU and it still takes forever to optimize :).</p>\n<p>In any case that's at least one way to find offenders for what takes so long in a crate.</p>\n<p>Also FWIW, some reasons why <a href=\"https://github.com/bytecodealliance/cranelift/blob/b7a16569037a2123f76e16210042f4203af7c9d8/cranelift-codegen/meta/src/shared/instructions.rs#L484-L3717\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/blob/b7a16569037a2123f76e16210042f4203af7c9d8/cranelift-codegen/meta/src/shared/instructions.rs#L484-L3717\"><code>instructions::define</code></a> is likely slow to compile:</p>\n<ul>\n<li>It's a 3kloc function, so it's already huge!</li>\n<li>There's a lot of local variables, all of which require destructors. There's then a huge number of function calls, each of which needs a landing pad for all the previous destructors. That's a lot of destructors!</li>\n<li>Using the builder pattern, while convenient, generates a lot of function calls which introduces more places destructor landing pads need generating.</li>\n<li>There's quite a few temporary <code>Vec&lt;T&gt;</code> instances, all of which require destructors as well</li>\n</ul>\n<p>Overall it's just a really really big function that LLVM wastes tons of time trying to optimize when in fact it's probably only called once-per-program and there's really no reason to optimize it. The best way to fix it is likely to break it up into many more little functions which should be much more digestable for LLVM.</p>\n</blockquote>",
        "id": 185362970,
        "sender_full_name": "GitHub",
        "timestamp": 1578700741
    },
    {
        "content": "<p>bjorn3 <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-573296548\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-573296548\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<blockquote>\n<p>There's then a huge number of function calls, each of which needs a landing pad for all the previous destructors.</p>\n</blockquote>\n<p>Maybe set <code>panic=abort</code>?</p>\n</blockquote>",
        "id": 185381051,
        "sender_full_name": "GitHub",
        "timestamp": 1578732338
    },
    {
        "content": "<p>bnjbvr <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-577879432\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318#issuecomment-577879432\">commented</a> on <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>Thanks for the detailed approach @alexcrichton !<br>\nAlso I just discovered <a href=\"https://github.com/dtolnay/cargo-llvm-lines\" target=\"_blank\" title=\"https://github.com/dtolnay/cargo-llvm-lines\">cargo-llvm-lines</a>, which gives the number of LLVM IR lines per function across all instantiations (for generic functions). It yields the same conclusions effortlessly:</p>\n<div class=\"codehilite\"><pre><span></span>  Lines Copies  Function name\n  48459      1  cranelift_codegen_meta::shared::legalize::define\n  25984     64  alloc::raw_vec::RawVec&lt;T,A&gt;::reserve_internal\n  25333      1  cranelift_codegen_meta::isa::x86::legalize::define\n  21762    155  core::iter::traits::iterator::Iterator::try_fold\n  17385    182  core::option::Option&lt;T&gt;::map\n  15959      1  cranelift_codegen_meta::shared::instructions::define\n  15896    945  core::ptr::real_drop_in_place\n  13215     81  &lt;alloc::vec::Vec&lt;T&gt; as alloc::vec::SpecExtend&lt;T,I&gt;&gt;::spec_extend\n  11749     31  hashbrown::raw::RawTable&lt;T&gt;::rehash_in_place\n  10948      1  cranelift_codegen_meta::isa::x86::recipes::define\n</pre></div>\n\n\n</blockquote>",
        "id": 186436192,
        "sender_full_name": "GitHub",
        "timestamp": 1579814007
    },
    {
        "content": "<p>bnjbvr labeled <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>This is especially a problem when building with opt-level=2, since cargo doesn't know to apply the optimization level only to target code, while cranelift-codegen-meta is host code.</p>\n<p>Interestingly, the build time for the cranelift-codegen-meta is dominated by LLVM (80 to 90% of the time), mostly spent between multiple LLVM module passes, LTO passes and codegen passes.</p>\n<p>This seems to be mostly caused by the size of <code>shared::instructions::define</code> and <code>shared::legalize::define</code>.</p>\n<p>Cc: @alexcrichton </p>\n</blockquote>",
        "id": 187830659,
        "sender_full_name": "GitHub",
        "timestamp": 1581351525
    },
    {
        "content": "<p>alexcrichton transferred <a href=\"https://github.com/bytecodealliance/cranelift/issues/1318\" target=\"_blank\" title=\"https://github.com/bytecodealliance/cranelift/issues/1318\">Issue #1318</a>:</p>\n<blockquote>\n<p>This is especially a problem when building with opt-level=2, since cargo doesn't know to apply the optimization level only to target code, while cranelift-codegen-meta is host code.</p>\n<p>Interestingly, the build time for the cranelift-codegen-meta is dominated by LLVM (80 to 90% of the time), mostly spent between multiple LLVM module passes, LTO passes and codegen passes.</p>\n<p>This seems to be mostly caused by the size of <code>shared::instructions::define</code> and <code>shared::legalize::define</code>.</p>\n<p>Cc: @alexcrichton </p>\n</blockquote>",
        "id": 189361754,
        "sender_full_name": "GitHub",
        "timestamp": 1582932513
    }
]