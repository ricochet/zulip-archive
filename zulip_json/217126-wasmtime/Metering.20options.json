[
    {
        "content": "<p>I wanted to know about various metering options in Wasmtime and which one seems to be performant. My aim is to get number of instructions executed (during runtime and not number of instructions in the WASM binary) when I do <code>call_async</code>. I see there is something called <code>fuel</code> but read that it might have performance concerns.</p>",
        "id": 491153246,
        "sender_full_name": "spino17",
        "timestamp": 1735455435
    },
    {
        "content": "<p><a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html#method.consume_fuel\">Fuel</a> was initially the only option but <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html#method.epoch_interruption\">Epoch-based interruption</a> should be more performant for most use cases especially those centered around preventing DOS/infinite-looping components.</p>\n<p>I think that if you want to get the <em>exact number</em> of instructions executed you may have to use fuel, but the mapping isn't quite so easy -- <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Store.html#method.set_fuel\"><code>set_fuel</code> docs note that *most* instructions consume one unit</a>, but there are some that consume 0, so not sure how pedantic you want to be in that area.</p>",
        "id": 491252268,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546058
    },
    {
        "content": "<p>thanks <span class=\"user-mention\" data-user-id=\"598440\">@Victor Adossi</span> for the reply. I may not want the exact number of instructions executed but a measure of it being linearly proportional to it would be fine, so for example I might be okay with 0 costed instructions using fuel. Is there a way for it in Epoch based interruptions ?</p>",
        "id": 491252677,
        "sender_full_name": "spino17",
        "timestamp": 1735546378
    },
    {
        "content": "<p>So epochs are time based -- they don't really work at the instruction level, so it's completely divorced. Depends on your use case of course, but if you can identify some period of time that makes sense to segment as epochs, then you <em>should</em> be able to achieve a similar result... I think also epoch-based limitation also fits quite well with a lot of scheduling theory/how various schedulers (below WASM in \"the stack\") work as well.</p>",
        "id": 491252828,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546489
    },
    {
        "content": "<p>yeah that's a good suggestion. I was interested in this naive instruction count because of concrete number and associated pricing (for the product). for epoch I think I could do how many epochs passed in executing that wasm function and have pricing per epoch.</p>",
        "id": 491253050,
        "sender_full_name": "spino17",
        "timestamp": 1735546638
    },
    {
        "content": "<p>what if I don't want to interrupt but just get the count of epochs at the end of the execution ? something like fuel API in this example: <a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/examples/fuel.rs\">https://github.com/bytecodealliance/wasmtime/blob/main/examples/fuel.rs</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/blob/main/examples/fuel.rs\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/33b0b198e8421a327a3d4021d0e3d11dfb5924ba/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f626633343866373131386564663533366262323737306232333437653937363865616339653062653863623832376666656138353066613331323431366262382f62797465636f6465616c6c69616e63652f7761736d74696d65&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/examples/fuel.rs\" title=\"wasmtime/examples/fuel.rs at main · bytecodealliance/wasmtime\">wasmtime/examples/fuel.rs at main · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">A lightweight WebAssembly runtime that is fast, secure, and standards-compliant - bytecodealliance/wasmtime</div></div></div>",
        "id": 491253244,
        "sender_full_name": "spino17",
        "timestamp": 1735546764
    },
    {
        "content": "<p>Ah so if the idea is tied to pricing I think you could definitely do better with a time-based restriction -- this is how most compute platforms will charge right, the idea of \"compute seconds\" or something similar</p>",
        "id": 491253250,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546770
    },
    {
        "content": "<p>yeah, this makes sense. It's more performant so that's definitely a pros</p>",
        "id": 491253347,
        "sender_full_name": "spino17",
        "timestamp": 1735546812
    },
    {
        "content": "<p>If you'd like to maintain metrics around used epoch/timing then you'd have to add that implementation yourself to the epoch based approach I think</p>",
        "id": 491253409,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546852
    },
    {
        "content": "<p>ohh okay, let me take a look at it. Much thanks <span class=\"user-mention\" data-user-id=\"598440\">@Victor Adossi</span> for the help!</p>",
        "id": 491253469,
        "sender_full_name": "spino17",
        "timestamp": 1735546913
    },
    {
        "content": "<p>Ah, what's interesting is you could actually use a <em>combination</em> of fuel and epochs -- </p>\n<p>the <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Store.html#method.epoch_deadline_callback\"><code>epoch_deadline_callback</code></a> you pass in gets a <code>StoreContextMut</code> which actually can get access to the <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.StoreContextMut.html#method.get_fuel\">amount of fuel</a> remaining</p>",
        "id": 491253527,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546937
    },
    {
        "content": "<p>You should have a lot of lattitude for making this stuff performant with those tools and the ability to change stuff like the yield intervals and deadlines dynamically (as long as that callback stays fast of course!)</p>",
        "id": 491253570,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735546978
    },
    {
        "content": "<p>Good luck -- please feel free to contribute examples/issues/documentation if you come across anything confusing!</p>",
        "id": 491253614,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735547017
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598440\">Victor Adossi</span> <a href=\"#narrow/channel/217126-wasmtime/topic/Metering.20options/near/491253527\">said</a>:</p>\n<blockquote>\n<p>Ah, what's interesting is you could actually use a <em>combination</em> of fuel and epochs -- </p>\n<p>the <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.Store.html#method.epoch_deadline_callback\"><code>epoch_deadline_callback</code></a> you pass in gets a <code>StoreContextMut</code> which actually can get access to the <a href=\"https://docs.rs/wasmtime/latest/wasmtime/struct.StoreContextMut.html#method.get_fuel\">amount of fuel</a> remaining</p>\n</blockquote>\n<p>That's a really great suggestion! so for interruption epoch will be used which is performant and can compute fuel in the callback.</p>",
        "id": 491253760,
        "sender_full_name": "spino17",
        "timestamp": 1735547124
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598440\">Victor Adossi</span> <a href=\"#narrow/channel/217126-wasmtime/topic/Metering.20options/near/491253614\">said</a>:</p>\n<blockquote>\n<p>Good luck -- please feel free to contribute examples/issues/documentation if you come across anything confusing!</p>\n</blockquote>\n<p>yeah absolutely</p>",
        "id": 491253774,
        "sender_full_name": "spino17",
        "timestamp": 1735547138
    },
    {
        "content": "<p>I think this discussion has misunderstood some of the performance characteristics of the options: in particular, if you are getting fuel remaining in an epoch-interrupt handler, that implies fuel instrumentation is compiled in, at which point <em>also</em> using epochs is only added overhead</p>",
        "id": 491306683,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735578665
    },
    {
        "content": "<p>Also, for what it's worth, epochs are not time-based, necessarily: they are counter-based. The usual mode of use is to have some external thing (a thread on the side, or some other part of your runtime) increment the epoch counter regularly. But I would strongly caution against using its notion of \"time\" for anything related to real money (billing): it's not precise at all</p>",
        "id": 491306752,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735578720
    },
    {
        "content": "<p>Or not necessarily tied to a real system clock</p>",
        "id": 491306804,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735578730
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> has marked this topic as unresolved.</p>",
        "id": 491306810,
        "sender_full_name": "Notification Bot",
        "timestamp": 1735578735
    },
    {
        "content": "<p>There is also the aspect of \"noisy neighbor\" interference: billing based on wallclock time gives one an unpredictable amount of work for given cost because we're timeslicing on the async executor threads. If you want deterministic and explainable billing, fuel alone is the only way to go</p>",
        "id": 491306890,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735578784
    },
    {
        "content": "<p>(at least, for billing based on \"work done\", rather than some other cost model, e.g. per-request up to a limit or ...)</p>",
        "id": 491306939,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735578822
    },
    {
        "content": "<blockquote>\n<p>I think this discussion has misunderstood some of the performance characteristics of the options: in particular, if you are getting fuel remaining in an epoch-interrupt handler, that implies fuel instrumentation is compiled in, at which point <em>also</em> using epochs is only added overhead</p>\n</blockquote>\n<p>Maybe this wasn't clear --  my interpretation of the request was that while fuel is the only precise way to count the actual instructions used, setting the instruction count low and actually <em>stopping</em> frequently was probably not desired. </p>\n<p>If I understood @spino17's desire right, they wanted an accurate count of of the number of instructions executed, and I responded that fuel was the way to do that (with some caveats on instruction counting) -- I don't think there was a misunderstanding there. Then the question was asked about how this might interplay in epoch based interruptions, and we discussed that.</p>\n<p>The final idea (which I probably didn't explain enough) about using them both in the context of billing was that it might make more sense to enable fuel but not actually try to trap frequently (i.e. set the fuel really high) but only <em>check</em> the used fuel periodically on an epoch determined time schedule.</p>\n<p>Maybe I'm wrong here and simply having the fuel instrumentation will be the majority of the negative performance impact, but the idea was that you have the fuel counting happening but do not have to do the fine-grained management, with some ability to stop computations from running an unreasonable amount of time and blocking the executor.</p>\n<blockquote>\n<p>Also, for what it's worth, epochs are not time-based, necessarily: they are counter-based. The usual mode of use is to have some external thing (a thread on the side, or some other part of your runtime) increment the epoch counter regularly. But I would strongly caution against using its notion of \"time\" for anything related to real money (billing): it's not precise at all</p>\n</blockquote>\n<p>I think we might be splitting hairs here -- I still consider a virtual/logical clock that is incremented in line with a physical one to be time-based (never mind that you still have access to the <em>actual</em> system clock during the callback), but that's neither here nor there.</p>\n<p>While we're here though, I'd love to hear how would you actually solve this, <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> ? Would you go for purely fuel as a solution?</p>",
        "id": 491359061,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735615291
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"598440\">Victor Adossi</span> <a href=\"#narrow/channel/217126-wasmtime/topic/Metering.20options/near/491359061\">said</a>:</p>\n<blockquote>\n<p>The final idea (which I probably didn't explain enough) about using them both in the context of billing was that it might make more sense to enable fuel but not actually try to trap frequently (i.e. set the fuel really high) but only <em>check</em> the used fuel periodically on an epoch determined time schedule.</p>\n<p>Maybe I'm wrong here and simply having the fuel instrumentation will be the majority of the negative performance impact, but the idea was that you have the fuel counting happening but do not have to do the fine-grained management, with some ability to stop computations from running an unreasonable amount of time and blocking the executor.</p>\n</blockquote>\n<p>Right, yes, I understood the proposal; my main point is that this will be slower. I studied the performance of fuel-counting mechanisms extensively when I came up with and implemented epochs; the overhead exists whether you use fuel to actually interrupt, or just to count execution steps. Additionally adding the epoch checks -- which are another set of instructions on every backedge -- will only slow down execution further.</p>\n<p>So: we want to count execution precisely; so we need to flip the \"fuel\" switch on. We can set the fuel reserves to <code>u64::MAX</code>, never take a fuel interrupt, we're still paying the cost. Now we need a way to periodically interrupt and context-switch back to the caller. We can use fuel -- which we've already paid the instrumentation cost of -- by setting some fuel reserve less than <code>u64::MAX</code> -- or we can turn on epochs, which will add <em>another</em> set of instructions to every backedge. Both have roughly the same interuption cost (a call back into the runtime), but epochs will add yet another slowdown factor.</p>\n<p>Fuel checks consist of two parts: load-decrement-store on \"used fuel\", and a compare-and-branch to see if that crosses zero. The latter is very cheap (almost always correctly predicted); almost all the cost is in the load-and-store traffic. In particular the latencies (three or four cycles each for ld and st) and the store-to-load forwarding is painful on modern CPUs, and hard for the instruction scheduler to predict. We need to store back to memory at least across every callsite, because we don't have a custom calling convention that pins the value in a register (doing so would be a perf tradeoff to evaluate; unclear if always a win). All that to say: the cost is in the counting, not the checking.</p>\n<blockquote>\n<p>While we're here though, I'd love to hear how would you actually solve this, @Chris Fallin ? Would you go for purely fuel as a solution?</p>\n</blockquote>\n<p>Yes, definitely, for all the reasons above. Epochs were designed to be used only when one doesn't need the deterministic counting of fuel.</p>",
        "id": 491364543,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1735620290
    },
    {
        "content": "<blockquote>\n<p>Fuel checks consist of two parts: load-decrement-store on \"used fuel\", and a compare-and-branch to see if that crosses zero. The latter is very cheap (almost always correctly predicted); almost all the cost is in the load-and-store traffic. In particular the latencies (three or four cycles each for ld and st) and the store-to-load forwarding is painful on modern CPUs, and hard for the instruction scheduler to predict. We need to store back to memory at least across every callsite, because we don't have a custom calling convention that pins the value in a register (doing so would be a perf tradeoff to evaluate; unclear if always a win). All that to say: the cost is in the counting, not the checking.</p>\n</blockquote>\n<p>Thanks for the thorough explanation here -- this really solved misconceptions I had about where the cost was.</p>",
        "id": 491364946,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1735620728
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> for the complete picture. This makes much sense now and I should move forward with fuel approach only then. Thanks again <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> and <span class=\"user-mention\" data-user-id=\"598440\">@Victor Adossi</span> for the help and the above elaborate discussion.</p>",
        "id": 491420057,
        "sender_full_name": "spino17",
        "timestamp": 1735663258
    }
]