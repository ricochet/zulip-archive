[
    {
        "content": "<p>I just noticed that LTO wasn't enabled for wasmtime, would it make sense to enable it at some point, for release builds? (Or is it set automatically under a specific Rust profile?)</p>",
        "id": 217245916,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1605778507
    },
    {
        "content": "<p>ah, good question! <span class=\"user-mention\" data-user-id=\"253994\">@Alex Crichton</span>, do you see any reason not to enable thin LTO? AFAICT it's probably indeed not enabled through some indirect means?</p>",
        "id": 217262992,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1605789502
    },
    {
        "content": "<p>The main reason is build time to benefit gained, even Thin LTO for the full  crate graph can sometimes take awhile</p>",
        "id": 217290227,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1605801778
    },
    {
        "content": "<p>mostly because we produce a \"full release\" on every commit</p>",
        "id": 217290295,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1605801799
    },
    {
        "content": "<p>but other than that should be fine to enable</p>",
        "id": 217290311,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1605801804
    },
    {
        "content": "<p>ah, cool. <span class=\"user-mention\" data-user-id=\"254393\">@Benjamin Bouvier</span> would you be up for doing an experiment with this as a PR, so we can see the impact on build times?</p>",
        "id": 217293582,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1605803042
    },
    {
        "content": "<p>I'm happy to try this, yes!</p>",
        "id": 217300519,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1605805847
    },
    {
        "content": "<p>Do we already have a small, blessed set of benchmarks to get an idea of the performance impact of enabling LTO?</p>",
        "id": 217615137,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606129889
    },
    {
        "content": "<p>I've looked at the benchmarking rfc, and it seems this is still in flux</p>",
        "id": 217615334,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606130026
    },
    {
        "content": "<p>I've got some initial measurements on my machine for compile time, at least. My machine is quite beefy (32 cores at 4 GHz), so it might not be representative and we should measure the effect on CI, in particular. All measures done after a build cache clear (<code>cargo clean</code>).</p>\n<ul>\n<li>lto off: total build times of 41 seconds</li>\n<li>lto thin: total build tmies of 42 seconds</li>\n<li>lto fat: 1' 57 seconds</li>\n</ul>\n<p>In terms of throughput: I only have local benchmarks which measure the throughput of generated code, since I've always been working on mostly Cranelift and codegen :-) So the measurement might not be very telling, as there's only very little time spent in initializing the VM and calling into the codegen'd code. On the 4 synthetic benchmarks I've tried, the speedup is in the noise range, for both thin and fat LTO modes.</p>\n<p>With valgrind, I get the measured the instructions retired count for 2 very small benchmarks:</p>\n<ul>\n<li>fbench: no LTO: 1660M / thin LTO: 1648M / fat LTO: 1632M</li>\n<li>ffbench: no LTO: 1465M / thin LTO: 1452M / fat LTO: 1436M</li>\n</ul>\n<p>so 1.5 to 2% retired instructions decrease for fat LTO, when compared to the baseline.</p>\n<p>At this point, I think that:</p>\n<ul>\n<li>we should find benchmarks that are more representative of this use case, that is, that spend more time in the VM itself.</li>\n<li>thin LTO seems to be the nice midpoint, with almost no impact on compile times, and a small decrease in retired instruction counts.</li>\n<li>we should measure the impact on CI to get a better understanding of the total effect on runtime. I'll start this right now; in advance sorry for the noise this will generate for new PRs. (Also, I don't know how predictable are the CI runners...)</li>\n</ul>",
        "id": 217617612,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606131542
    },
    {
        "content": "<p>And here's some summary of the 3 PRs:</p>\n<ul>\n<li>test time isn't affected, because tests run in a different profile. Kind of obvious after the fact, but I didn't realize this before, so worth mentioning!</li>\n<li>thin LTO resulted in a build failure on Windows with mingw, making it impossible to get the actual build times.</li>\n<li>fat LTO worked, though, so we have an idea of the overhead:<ul>\n<li>build linux: from 18 minutes (lto=off) to 51 minutes (lto=fat)</li>\n<li>mac: 16 to 40</li>\n<li>win: 31 to 60</li>\n<li>aarch64: 23 to 48</li>\n</ul>\n</li>\n</ul>",
        "id": 217625717,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606137135
    },
    {
        "content": "<p>So, for LTO=fat, it seems that the huge increase in compile times, and relatively low benefits in runtimes (with the caveat that the benchmarks are synthetic codegen benchmarks), it would be counterproductive to enable it right now. More realistic benchmarks should be used to determine if this is worth it.</p>\n<p>For LTO=thin, the mingw failures would need to be investigated and solved first. Locally the increase in compile times has been unnoticeable, the effect on run time (same caveat applies) has been very low as well. So it may be fine to postpone it as well.</p>",
        "id": 217625958,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606137291
    },
    {
        "content": "<p>Overall, it seems that more VM- heavy benchmarks (e.g. WASI benchmarks) would be required to make interesting measurements here, and that enabling LTO would be a perfect testbed for the benchmarking infrastructure in general.</p>",
        "id": 217626018,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606137355
    },
    {
        "content": "<p>thank you for looking into this! <span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span></p>\n<p>I agree that fat LTO is clearly not viable, which doesn't seem surprising. I also agree that we should have more useful benchmarks to evaluate the rest, including whether it's worth it to sort out the issues with thin-LTO on Windows. Though perhaps <span class=\"user-mention\" data-user-id=\"253994\">@Alex Crichton</span> knows what's going on with those, and how to easily address them?</p>",
        "id": 217626331,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606137546
    },
    {
        "content": "<p>sure yeah happy to look into mingw issues, but we should be careful with evaluation numbers. LTO shouldn't be 2x slower but with Cargo it's easy to accidentally build things 2x more than before. I think when just the <code>release</code> profile is changed then it means <code>cargo build --release</code> will shared probably only build dependencies with <code>cargo test --release</code>, so there's a huge duplication of artifacts built. Similarly ThinLTO will probably hit duplicate build issues.</p>\n<p>What we probably want to do is to drill down what we want LTO'd and perhaps do that on a separate builder? That way builders can ideally sharae a cache.</p>",
        "id": 217637983,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606143777
    },
    {
        "content": "<p>ah, that makes sense!</p>",
        "id": 217643069,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606145980
    },
    {
        "content": "<p>and makes me think even more that we should tackle this with useful benchmarks in hand that exercise the runtime itself in a meaningful way. Once we do, I guess we could even look into using PGO on published builds, which seems like it could make a meaningful difference</p>",
        "id": 217643269,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606146061
    },
    {
        "content": "<p>I gave PGO a spin the other day for testing the compile time of a few modules but unfortunately it didn't give really any meaningful difference for me locally</p>",
        "id": 217643864,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606146325
    },
    {
        "content": "<p>although I was pretty un-scientific in my measurments</p>",
        "id": 217643884,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606146337
    },
    {
        "content": "<p>yeah, that all seems like it really wants benchmarks to run that exercise enough of the runtime. I'd bet that a lot of stuff one would choose somewhat arbitrarily ends up spending most time in Cranelift-compiled code, and thus not really benefit from PGO</p>",
        "id": 217647351,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606147716
    },
    {
        "content": "<p>but perhaps you accounted for that?</p>",
        "id": 217647381,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606147729
    },
    {
        "content": "<p>oh yeah what I was testing was exclusively compile time</p>",
        "id": 217649123,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606148417
    },
    {
        "content": "<p>no runtime at all</p>",
        "id": 217649133,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606148423
    },
    {
        "content": "<p>yeah, I guess compile time is something we should in theory already be well positioned to evaluate, and where naively I would've expected to see PGO make a difference. Oh well ...</p>",
        "id": 217649361,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606148525
    },
    {
        "content": "<p>also reading just the error message of MinGW, one of the issues with lto is that it builds all the examples with LTO as well, so we're doing the full LTO passes maybe 10-ish times, which as you can imagine increases compile times a lot</p>",
        "id": 217659228,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1606153279
    },
    {
        "content": "<p>lol</p>",
        "id": 217672920,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1606160191
    },
    {
        "content": "<p>oh well</p>",
        "id": 217733722,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1606212783
    }
]