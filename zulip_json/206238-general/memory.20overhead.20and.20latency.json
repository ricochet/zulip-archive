[
    {
        "content": "<p>hi... can someone shade some light one these queries?</p>\n<ol>\n<li>Lowest runtime overhead of just the Wasm VM and runtime for dummy code, say for C - excluding the initial page size </li>\n<li>Lowest startup latency for dummy code, for C</li>\n<li>How low you foresee the overhead can get reduced in the next couple years</li>\n</ol>",
        "id": 262769636,
        "sender_full_name": "Audacious Tux",
        "timestamp": 1637914380
    },
    {
        "content": "<p>See <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3319#issuecomment-916236710\">https://github.com/bytecodealliance/wasmtime/pull/3319#issuecomment-916236710</a> for benchmarks of the overhead of calling between wasm code and the host.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/pull/3319#issuecomment-916236710\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/01395c5b2c7de8963fadadeb3dfd4d5a7e2df1fa\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f663039623165623930373464383332383632623835323263303035383339346561613462653430353863303061336631306561613766336435383337653834302f62797465636f6465616c6c69616e63652f7761736d74696d652f70756c6c2f33333139)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/pull/3319#issuecomment-916236710\" title=\"Optimize `Func::call` and its C API by alexcrichton · Pull Request #3319 · bytecodealliance/wasmtime\">Optimize `Func::call` and its C API by alexcrichton · Pull Request #3319 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">This commit is an alternative to #3298 which achieves effectively the\nsame goal of optimizing the Func::call API as well as its C API\nsibling of wasmtime_func_call. The strategy taken here is diffe...</div></div></div>",
        "id": 262799178,
        "sender_full_name": "bjorn3",
        "timestamp": 1637934523
    },
    {
        "content": "<p>For reducing the startup time you can precompile the wasm using <code>wasmtime compile</code>.</p>",
        "id": 262799273,
        "sender_full_name": "bjorn3",
        "timestamp": 1637934595
    },
    {
        "content": "<p>We've done some WAMR profiling, and memory wise, we got WAMR + zephyr rtos running on STM microcontroller with 340kb of RAM, the runtime appeared to take roughly ~120kb of RAM, the Wasm application's we were running (c based) were between 3kb - 5kb of RAM. </p>\n<p>We've done some more extensive testing recently on real-time performance, and I'd be happy to share what we have.</p>",
        "id": 263191414,
        "sender_full_name": "Chris Woods",
        "timestamp": 1638298625
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"435699\">@Chris Woods</span> In our test with WAMR, we can manage to run a hello-world wasm module under 5KB RAM (given runtime binary directly run from flash). We can follow up on the details.</p>",
        "id": 263234137,
        "sender_full_name": "Wang Xin",
        "timestamp": 1638322581
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"268650\">@Wang Xin</span>  That's awesome. I believe, in our tests, we struggled with an STM with less ram - at the time we just assumed that was due to the RTOS + runtime overhead. I don't think we measured the runtime only overhead.</p>",
        "id": 263281267,
        "sender_full_name": "Chris Woods",
        "timestamp": 1638361436
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"435699\">@Chris Woods</span>  Have you referred to the following document to build the wasm app so as to reduce the memory usage?<br>\n<a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint\">https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint</a><br>\nNormally in IoT system, as file io operation isn't needed, we can build the wasm app with '-nostdlib' mode and run it with WAMR's builtin libc, for example, use the following command to build wasm app:<br>\n  /opt/wasi-sdk/bin/clang -O3 -z stack-size=4096 -Wl,--initial-memory=65536 \\<br>\n    -o test.wasm main.c \\<br>\n    -Wl,--export=__main_argc_argv -Wl,--export=main \\<br>\n    -Wl,--export=__heap_base,--export=__data_end  \\<br>\n    -nostdlib -Wl,--no-entry -Wl,--strip-all -Wl,--allow-undefined<br>\nHere '-z stack-size=4096' is to specify the auxiliary stack size (auxiliary stack is part of linear memory), you can increase it if it is not enough.<br>\nAnd for iwasm, you can specify the heap size and stack size, with \"iwasm --heap-size=n --stack-size=n\".<br>\nOr specify them when calling wasm_runtime_instantiate:<br>\nwasm_module_inst_t<br>\nwasm_runtime_instantiate(const wasm_module_t module,<br>\n<strong>uint32_t stack_size, uint32_t heap_size,</strong><br>\n                         char *error_buf, uint32_t error_buf_size);<br>\nBy default they are both16KB, but some simple wasm apps, we can decrease them, for example, 4KB to 8KB might be<br>\nenough.</p>\n<p>And also WAMR provides memory profiling feature, please refer to the following link for more details:<br>\n<a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment\">https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/fb42cb559a792552b54680fd37b0d4f6b32ab824\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f326661373036626530393666633766396366646165663331383566636230396239393466316233643536623330626131653065396565316333633035353932652f62797465636f6465616c6c69616e63652f7761736d2d6d6963726f2d72756e74696d65)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint\" title=\"wasm-micro-runtime/build_wasm_app.md at main · bytecodealliance/wasm-micro-runtime\">wasm-micro-runtime/build_wasm_app.md at main · bytecodealliance/wasm-micro-runtime</a></div><div class=\"message_embed_description\">WebAssembly Micro Runtime (WAMR). Contribute to bytecodealliance/wasm-micro-runtime development by creating an account on GitHub.</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/fb42cb559a792552b54680fd37b0d4f6b32ab824\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f326661373036626530393666633766396366646165663331383566636230396239393466316233643536623330626131653065396565316333633035353932652f62797465636f6465616c6c69616e63652f7761736d2d6d6963726f2d72756e74696d65)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment\" title=\"wasm-micro-runtime/build_wamr.md at main · bytecodealliance/wasm-micro-runtime\">wasm-micro-runtime/build_wamr.md at main · bytecodealliance/wasm-micro-runtime</a></div><div class=\"message_embed_description\">WebAssembly Micro Runtime (WAMR). Contribute to bytecodealliance/wasm-micro-runtime development by creating an account on GitHub.</div></div></div>",
        "id": 263381516,
        "sender_full_name": "Wenyong Huang",
        "timestamp": 1638407815
    },
    {
        "content": "<p>We (me and Chris Woods) are evaluating the real time capabilities of WAMR. we have performed some experiments on x86 and arm machines (raspberry pis) to measure latencies and jitter. The summary of the preliminary results are as follows:</p>\n<p>1) Start up latency </p>\n<p>-&gt; Experiments performed on zbook intel core i7 </p>\n<p>-&gt; Two benchmarking scenarios are considered (<a href=\"https://gist.github.com/chhokrad/91b2ffbbcb8e07e81e4877d7df8619c8\">https://gist.github.com/chhokrad/91b2ffbbcb8e07e81e4877d7df8619c8</a>). In the first scenario, the timestamp is taken before and after calling a web assembly function (void do_nothing()). The web assembly binary is generated by translating the c code (<a href=\"https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c\">https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c</a>). The second scenario is similar to the first except, the second timestamp is taken by a native call from within the wasm ( see function void do_nothing_with_native() <a href=\"https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c\">https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c</a>). </p>\n<p>-&gt; Results: Benchmark scenario 1 --&gt; Median: 100.0 nanoseconds Average: 129.8 nanoseconds Standard Deviation: 318.5 nanoseconds</p>\n<p>-&gt; Results: Benchmark scenario 2--&gt; Median: 100.0 nanoseconds Average: 52.1 nanoseconds Standard Deviation: 100.9 nanoseconds</p>\n<p>2) GPIO access latency </p>\n<p>-&gt; Experiments performed on raspberry pi 4b with wiringPi 2.5.2</p>\n<p>-&gt; The benchmark application replicates the signal from an input pin to an output pin. The signal generated at the input pin of the raspberry pi is a square wave of fixed frequency (100 Hz) using an external source. The difference between the timestamps of the rising/ trailing edges of the waveform at two pins is considered as the hardware IO latency. </p>\n<p>-&gt; A total of 60 experiments were performed with varying scheduling priorities (non-real, 50, 70, 90) and each experiments lasts 0.3 secs generating 64 data points. (The sampling rate used for data acquisition is 32 nanoseconds).</p>\n<p>-&gt; Results: Median: 224 nanoseconds Average: 225 nanoseconds Standard Deviation: 82.5 nanoseconds</p>\n<p>--&gt; Observations: 1) Scheduling priority did not have much effect on the latency 2) On an average the wasm incurs 19% more latency as compared to executing the application natively.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://gist.github.com/chhokrad/91b2ffbbcb8e07e81e4877d7df8619c8\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/2aafd906f69f8f71c7544060163ba3e419b173e8\\/68747470733a2f2f6769746875622e6769746875626173736574732e636f6d2f696d616765732f6d6f64756c65732f67697374732f676973742d6f672d696d6167652e706e67)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://gist.github.com/chhokrad/91b2ffbbcb8e07e81e4877d7df8619c8\" title=\"main.c\">main.c</a></div><div class=\"message_embed_description\">GitHub Gist: instantly share code, notes, and snippets.</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/2aafd906f69f8f71c7544060163ba3e419b173e8\\/68747470733a2f2f6769746875622e6769746875626173736574732e636f6d2f696d616765732f6d6f64756c65732f67697374732f676973742d6f672d696d6167652e706e67)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://gist.github.com/chhokrad/7d2206d625132919b80f95810f7cf50c\" title=\"testapp.c\">testapp.c</a></div><div class=\"message_embed_description\">GitHub Gist: instantly share code, notes, and snippets.</div></div></div>",
        "id": 263475949,
        "sender_full_name": "Ajay Chhokra",
        "timestamp": 1638467667
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"415404\">Wenyong Huang</span> <a href=\"#narrow/stream/206238-general/topic/memory.20overhead.20and.20latency/near/263381516\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"435699\">Chris Woods</span>  Have you referred to the following document to build the wasm app so as to reduce the memory usage?<br>\n<a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint\">https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wasm_app.md#2-how-to-reduce-the-footprint</a><br>\nNormally in IoT system, as file io operation isn't needed, we can build the wasm app with '-nostdlib' mode and run it with WAMR's builtin libc, for example, use the following command to build wasm app:<br>\n  /opt/wasi-sdk/bin/clang -O3 -z stack-size=4096 -Wl,--initial-memory=65536 \\<br>\n    -o test.wasm main.c \\<br>\n    -Wl,--export=__main_argc_argv -Wl,--export=main \\<br>\n    -Wl,--export=__heap_base,--export=__data_end  \\<br>\n    -nostdlib -Wl,--no-entry -Wl,--strip-all -Wl,--allow-undefined<br>\nHere '-z stack-size=4096' is to specify the auxiliary stack size (auxiliary stack is part of linear memory), you can increase it if it is not enough.<br>\nAnd for iwasm, you can specify the heap size and stack size, with \"iwasm --heap-size=n --stack-size=n\".<br>\nOr specify them when calling wasm_runtime_instantiate:<br>\nwasm_module_inst_t<br>\nwasm_runtime_instantiate(const wasm_module_t module,<br>\n<strong>uint32_t stack_size, uint32_t heap_size,</strong><br>\n                         char *error_buf, uint32_t error_buf_size);<br>\nBy default they are both16KB, but some simple wasm apps, we can decrease them, for example, 4KB to 8KB might be<br>\nenough.</p>\n<p>And also WAMR provides memory profiling feature, please refer to the following link for more details:<br>\n<a href=\"https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment\">https://github.com/bytecodealliance/wasm-micro-runtime/blob/main/doc/build_wamr.md#enable-memory-profiling-experiment</a></p>\n</blockquote>\n<p>That is awesome! thank you so much for the details !</p>",
        "id": 263886511,
        "sender_full_name": "Chris Woods",
        "timestamp": 1638812201
    }
]