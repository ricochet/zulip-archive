[
    {
        "content": "<p>Hello! </p>\n<p>I was wondering, would compilation to PTX ever be supported? PTX is basically assembly but for GPU kernels on nvidia GPUs. Its just like any other ISA. It would be very helpful for me and perhaps for many people if we could compile rust to PTX. targeting nvptx64-nvidia-cuda using LLVM currently doesnt really work because of LLVM dylib limitations, and it makes broken PTX a lot of the time. Not sure how much work it would be because i'm not quite sure how cranelift's codegen works. But i expect it may be as much work as a \"smaller\" ISA like ARM.</p>",
        "id": 241728606,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623041179
    },
    {
        "content": "<p>Greetings <span class=\"user-mention\" data-user-id=\"418736\">@Riccardo D'Ambrosio</span> ! I'm not aware of anyone with immediate plans to add a PTX (or GPU in general) backend to Cranelift, but actually the Embark Studios folks had a similar desire a while ago and we talked about whether adding a GPU backend to Cranelift would make sense, which eventually led to the conclusion that it probably is more straightforward  to develop a  rustc backend directly. They've since built <a href=\"https://github.com/EmbarkStudios/rust-gpu\">rust-gpu</a>, which generates SPIR-V. <span class=\"user-mention\" data-user-id=\"254393\">@Benjamin Bouvier</span> or <span class=\"user-mention\" data-user-id=\"318573\">@Johan Andersson</span> would be the right folks to talk to if you want to know more!</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/EmbarkStudios/rust-gpu\" style=\"background-image: url(https://opengraph.githubassets.com/e303944a6abe406ec6f4889f80398507a09f020ce1f33b3eaa611e166e663406/EmbarkStudios/rust-gpu)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/EmbarkStudios/rust-gpu\" title=\"EmbarkStudios/rust-gpu\">EmbarkStudios/rust-gpu</a></div><div class=\"message_embed_description\">üêâ Making Rust a first-class language and ecosystem for GPU code üöß - EmbarkStudios/rust-gpu</div></div></div>",
        "id": 241732075,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623045394
    },
    {
        "content": "<p>Yeah rust-gpu is great, but CUDA usually yields considerably higher (30%+) performance for physics simulations and things like that, and has things that vulkan just doesnt have, like graphs, special memory handling, etc, so using rust-gpu over cuda is not really acceptable for me :(</p>",
        "id": 241732147,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045484
    },
    {
        "content": "<p>for the small examples ive tried right now, rustc seems to make correct ptx, ill explore this further since last time i tried this, it made broken ptx</p>",
        "id": 241732189,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045544
    },
    {
        "content": "<p>The issue is that i have to use <code>--emit=asm</code> which is kind of a hack because windows has some issues linking with a custom ptx linker</p>",
        "id": 241732198,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045571
    },
    {
        "content": "<p>Anyways, cranelift supporting PTX would still be very helpful since targeting the GPU for things like jit compilers (sounds crazy ikr) is very helpful</p>",
        "id": 241732211,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045599
    },
    {
        "content": "<p>Gotcha. Well, we're always looking for more contributors, so if you have interest in developing a PTX backend, we'd be happy to talk further! We're spread pretty thin otherwise so such a backend is unlikely to be developed without someone specifically driving it forward. But I could point you (or anyone else) toward the right places to start.</p>",
        "id": 241732290,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623045668
    },
    {
        "content": "<p>yeah if i find that targeting ptx with rustc is completely broken i might look at it</p>",
        "id": 241732311,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045719
    },
    {
        "content": "<p>im not sure how hard the PTX ISA is, i presume a lot of special handling would need to be done because it has special things like textures, surfaces, etc. im not sure how cranelift handles ISA-specific features</p>",
        "id": 241732381,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623045782
    },
    {
        "content": "<p>We more or less provide a standard load/store abstract machine at the IR level, similar to e.g. LLVM IR. There's precedent for adding intrinsics that are platform-specific but we try to minimize that</p>",
        "id": 241732464,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623045856
    },
    {
        "content": "<p>My initial gut reaction to that (with the caveat that I am not very familiar with the GPU world in general) is that we probably wouldn't turn into a compiler that understands, e.g., textures or surfaces. But insofar as general IR wants to be compiled down to GPGPU kernels, that seems reasonable to me</p>",
        "id": 241732504,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623045914
    },
    {
        "content": "<p>hmm i see, im not sure how llvm's ptx backend handles it</p>",
        "id": 241732651,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046014
    },
    {
        "content": "<p>although, if the extent of the platform-specific quirks that one needs  is just that there are special memories (scratchpad, texture memory?, etc) then we actually do have a notion of separate \"heaps\" that can be accessed (this comes from the multi-Wasm-heap world)</p>",
        "id": 241732766,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046096
    },
    {
        "content": "<p><a href=\"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#texture-sampler-and-surface-types\">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#texture-sampler-and-surface-types</a></p>",
        "id": 241732801,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046130
    },
    {
        "content": "<p>OK, interesting. So the first step would be working out how to represent these primitives in CLIF</p>",
        "id": 241732886,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046204
    },
    {
        "content": "<p>yeah</p>",
        "id": 241732910,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046246
    },
    {
        "content": "<p>there also seems to be some weirdness with \"hiding the ABI\", and there is the question of what to do about regalloc (iirc GPUs have \"thousands-ish\" of registers, but does ptx present a virtual-register machine?)</p>",
        "id": 241732940,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046286
    },
    {
        "content": "<p>yes ptx has virtual registers</p>",
        "id": 241732965,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046317
    },
    {
        "content": "<p><a href=\"https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parameterized-variable-names\">https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parameterized-variable-names</a></p>",
        "id": 241733023,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046331
    },
    {
        "content": "<p>ptx is actually pretty human-friendly compared to other ISAs id say</p>",
        "id": 241733034,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046352
    },
    {
        "content": "<p>OK, gotcha, so we would need a way to bypass regalloc as well (that makes our life easier in some ways but also special-cases a bunch of stuff in the backend)</p>",
        "id": 241733037,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046360
    },
    {
        "content": "<p>need to also write an assembler for it, im not sure how much work that is, and i actually need that right now for jit compiling some math lol</p>",
        "id": 241733069,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046388
    },
    {
        "content": "<p>Yeah, each of our backends relies on an assembler library of sorts -- the <code>MachInst</code> implementation and the emit code centered around the <code>MachBuffer</code></p>",
        "id": 241733101,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046439
    },
    {
        "content": "<p>so the steps to write a backend are (i) get that assembler infrastructure written, (ii) define the lowering rules (basically a big <code>match</code>), (iii) define some other machine-specific traits like ABI implementations</p>",
        "id": 241733159,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046475
    },
    {
        "content": "<p>yeah i looked at the x64 impl... gigantic</p>",
        "id": 241733167,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046490
    },
    {
        "content": "<p>why is that much larger than say, arm?</p>",
        "id": 241733176,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046498
    },
    {
        "content": "<p>hmm, I just linecounted; 20087 lines in isa/x64 vs. 21156 in isa/aarch64</p>",
        "id": 241733215,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046557
    },
    {
        "content": "<p>possibly you're seeing in aarch64 we split the lowering into two files (<a href=\"http://lower.rs\">lower.rs</a>, <a href=\"http://lower_inst.rs\">lower_inst.rs</a>)? anyway both are pretty comparable in complexity</p>",
        "id": 241733264,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046582
    },
    {
        "content": "<p>i see</p>",
        "id": 241733287,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046613
    },
    {
        "content": "<p>would estimate a few months of full-time work to bring up a new backend, maybe 6 months to a year to have a well-tuned one</p>",
        "id": 241733299,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046627
    },
    {
        "content": "<p>so, \"new backend for platform X?\" is not a small ask, but as said above, happy to discuss further if you're interested in driving this!</p>",
        "id": 241733320,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046649
    },
    {
        "content": "<p>Yeah for sure, its kind of a last resort for me, so kind of unlikely, but maybe in the future ill explore it, not sure</p>",
        "id": 241733336,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046674
    },
    {
        "content": "<p>thanks anyways! <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 241733338,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046679
    },
    {
        "content": "<p>for sure!</p>",
        "id": 241733392,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046696
    },
    {
        "content": "<p>quick q while im here, is it possible to make cranelift call an extern c function i have in my rust code when using it as a jit compiler?</p>",
        "id": 241733399,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046709
    },
    {
        "content": "<p>It should be, yes; this is how \"hostcalls\" in e.g. wasmtime work</p>",
        "id": 241733415,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046731
    },
    {
        "content": "<p>is there a specific function in the docs that does that?</p>",
        "id": 241733432,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046749
    },
    {
        "content": "<p>I actually spend more time inside the compiler than at its boundary so I can't remember the API off the top of my head :-) but in the IR, it's an <code>ExternalName</code>, and then we give that back to you in a relocation so you can patch the address in before executing</p>",
        "id": 241733500,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046809
    },
    {
        "content": "<p>probably grep for <code>ExternalName</code> in <code>crates/*</code> in the wasmtime repo will get you started</p>",
        "id": 241733515,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046825
    },
    {
        "content": "<p>haha, thanks</p>",
        "id": 241733521,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046833
    },
    {
        "content": "<p>i suppose cranelift can't call standard rust functions because of its unspecified calling convention right? which isnt a big issue since i can just use a \"trampoline\" function</p>",
        "id": 241733575,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623046910
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"264278\">@bjorn3</span> on that (cranelift backend for rustc, so they are the expert) but yes, I think for a general hostcall sort of setup, using <code>extern \"C\"</code> functions will be a lot simpler and more reliable</p>",
        "id": 241733664,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1623046965
    },
    {
        "content": "<p>If you are using cranelift-jit, and declare a function with <code>module.declare_function</code>, cranelift-jit will fallback to looking up the symbol in the host executable if it  isn't defined using <code>module.define_function</code>. You can also use <code>.symbol()</code> on the <code>JitBuilder</code> to add custom fallbacks that are looked up before the host executable symbols.</p>",
        "id": 241740610,
        "sender_full_name": "bjorn3",
        "timestamp": 1623052280
    },
    {
        "content": "<p>You will indeed have to use <code>extern \"C\"</code> trampolines. You should try to avoid passing non-primitive types as part of the abi calculation for aggregates (structs, unions, ...) has to be done by the user of cranelift.</p>",
        "id": 241740791,
        "sender_full_name": "bjorn3",
        "timestamp": 1623052400
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"418736\">@Riccardo D'Ambrosio</span></p>",
        "id": 241740808,
        "sender_full_name": "bjorn3",
        "timestamp": 1623052415
    },
    {
        "content": "<p>I see, thanks! <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 241741282,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052710
    },
    {
        "content": "<p>is there a way to write a universal trampoline? i would suppose not because we have no variadic generics :/</p>",
        "id": 241741316,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052735
    },
    {
        "content": "<p>most of the functions i want to call take <code>vek</code> vectors or matrices :/</p>",
        "id": 241741368,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052785
    },
    {
        "content": "<p>but theyre repr C so they should be dead simple</p>",
        "id": 241741372,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052796
    },
    {
        "content": "<p>You should probably just pass pointers instead of passing them by value. That is much simpler to implement and avoids a move to the argument part of the stack.</p>",
        "id": 241741505,
        "sender_full_name": "bjorn3",
        "timestamp": 1623052883
    },
    {
        "content": "<p>the issue is im reusing this math code for my main physics engine library, so it needs to be idiomatic</p>",
        "id": 241741530,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052905
    },
    {
        "content": "<p>Only the trampolines need to take pointers, the library code can take it by value.</p>",
        "id": 241741650,
        "sender_full_name": "bjorn3",
        "timestamp": 1623052988
    },
    {
        "content": "<p>I see</p>",
        "id": 241741661,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1623052997
    },
    {
        "content": "<p>One possibility would of course be to compile the whole thing on a PTX target and then execute it on the GPU using cuModuleLoadData (CUDA Driver API).</p>\n<p>However, I think it would be a good move to compile directly into the GPU assembly and thus avoid an intermediate instance.</p>\n<p>Disadvantages of this are that these GPU ISAs are different from graphics card to graphics card generation (for example Nvidia Maxwell, Kepler, ...).<br>\nI think with this one could achieve a much higher performance than leaving this to a proprietary compiler.</p>\n<p>Tuning this directly to the GPU would be a lot of reverse engineering work, since NVIDIA only publishes very limited documentation on their ISAs.</p>",
        "id": 290924625,
        "sender_full_name": "Robin Lindner",
        "timestamp": 1658855112
    }
]