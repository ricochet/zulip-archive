[
    {
        "content": "<p>Hi everyone.</p>\n<p>I'm new here (via <span class=\"user-mention\" data-user-id=\"254124\">@Lin Clark</span>)... already started a thread under #wasi on some initial pytorch/libtorch wasm experiments my collaborators and I are experimenting with (apologies for the basic questions at this point).</p>\n<p>Hope to connect with others on efforts to bring machine learning to wasm.</p>\n<p>Sounds like <span class=\"user-mention\" data-user-id=\"234973\">@Till Schneidereit</span>   <span class=\"user-mention\" data-user-id=\"258954\">@Mingqiu Sun</span> and <span class=\"user-mention\" data-user-id=\"254110\">@Andrew Brown</span> are the ones to connect with on this topic? Congrats on the 2208 PR - seems like the ball is rolling in this space.</p>",
        "id": 216940969,
        "sender_full_name": "Austin Huang",
        "timestamp": 1605565213
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"363483\">@Austin Huang</span>, nice to meet you; are you interested in trying out wasi-nn using Wasmtime?</p>",
        "id": 217067817,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605649755
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254110\">@Andrew Brown</span> yes though i'm still learning the basics at this point. also probably need to catch up on the design discussions to date (do you have any links to check out so I don't rehash what's already been discussed?). </p>\n<p>As I understand it it's focusing on a runtime for compute graph inference, right? What are the paths to get something compiled down to an artifact it can consume? is there a compilation path, from say, onnx or torchscript?</p>",
        "id": 217068265,
        "sender_full_name": "Austin Huang",
        "timestamp": 1605649990
    },
    {
        "content": "<p>Well, there's an <a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/ci/run-wasi-nn-example.sh\">example script</a> that should give you some idea how to perform the inference and all of those artifacts were generated from the <a href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\">instructions I documented here</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/blob/main/ci/run-wasi-nn-example.sh\" style=\"background-image: url(https://avatars0.githubusercontent.com/u/54038801?s=400&amp;v=4)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/ci/run-wasi-nn-example.sh\" title=\"bytecodealliance/wasmtime\">bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Standalone JIT-style runtime for WebAssembly, using Cranelift - bytecodealliance/wasmtime</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\" style=\"background-image: url(https://github.githubassets.com/images/modules/gists/gist-og-image.png)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\" title=\"Test Fixtures for OpenVINO Inference\">Test Fixtures for OpenVINO Inference</a></div><div class=\"message_embed_description\">Test Fixtures for OpenVINO Inference. GitHub Gist: instantly share code, notes, and snippets.</div></div></div>",
        "id": 217068563,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605650144
    },
    {
        "content": "<p>I am working on a blog post that should be a better explainer for how to use wasi-nn so there's also the option to wait for that <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 217068680,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605650193
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254110\">@Andrew Brown</span> interesting. why is wasi-nn described as a library here? i was under the impression it's more of a standard the runtime implements.</p>\n<p>i haven't used openvino  but it sounds like it can consume onnx as a common denominator. could there be a more direct path (from say pytorch or tf? tbh i hear more about other IRs (xla, mlir, onnx ...) ... though i get the IR space is pretty fluid so gotta start somewhere i suppose.</p>",
        "id": 217069847,
        "sender_full_name": "Austin Huang",
        "timestamp": 1605650764
    },
    {
        "content": "<p>Not sure where you see wasi-nn being described as a library (let me know and I will fix!). It is a specification so I should be using \"spec\" or \"standard,\" though there might be confusion because wasi-nn is implemented in Wasmtime using the wasmtime-wasi-nn crate. That is the crate talks to OpenVINO to actually perform the inference.</p>",
        "id": 217070983,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605651295
    },
    {
        "content": "<p>\"Not all libraries (e.g. wasi-nn) will know how to decode images...\" <a href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\">https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1</a> maybe i'm misreading</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\" style=\"background-image: url(https://github.githubassets.com/images/modules/gists/gist-og-image.png)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://gist.github.com/abrown/c7847bf3701f9efbb2070da1878542c1\" title=\"Test Fixtures for OpenVINO Inference\">Test Fixtures for OpenVINO Inference</a></div><div class=\"message_embed_description\">Test Fixtures for OpenVINO Inference. GitHub Gist: instantly share code, notes, and snippets.</div></div></div>",
        "id": 217071053,
        "sender_full_name": "Austin Huang",
        "timestamp": 1605651348
    },
    {
        "content": "<p>Cool, let me fix that... As for whether OpenVINO supports other IRs, take a look at their <a href=\"https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html\">model optimizer documentation</a>--there is a tool that allows for converting one IR to another (not sure if it covers exactly what you're looking to do?)</p>",
        "id": 217071266,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605651472
    },
    {
        "content": "<p>E.g.: <a href=\"https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html\">https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html</a></p>",
        "id": 217071339,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605651499
    },
    {
        "content": "<p>will have a look. There's a lot of different things I'd like to do :) but my immediate aim is to wrap my head around the scope of wasi-nn (what's in and out of scope) and how to interface with it from a programming langauge runtime (C++ will be a focus for now since I use libtorch)</p>",
        "id": 217073585,
        "sender_full_name": "Austin Huang",
        "timestamp": 1605652971
    },
    {
        "content": "<p>Sounds good, let me know if you run into issues; here's <span class=\"user-mention\" data-user-id=\"258954\">@Mingqiu Sun</span> and I talking about wasi-nn: <a href=\"https://www.youtube.com/watch?v=6O44X76rgIg\">YouTube - Introducing WASI-NN</a>.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"6O44X76rgIg\" href=\"https://www.youtube.com/watch?v=6O44X76rgIg\"><img src=\"https://i.ytimg.com/vi/6O44X76rgIg/default.jpg\"></a></div>",
        "id": 217074736,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1605653698
    }
]