[
    {
        "content": "<p>Hi all, we haven't had stuff here for a while but a LOT of stuff has been done. Here's a quick update.</p>",
        "id": 397063393,
        "sender_full_name": "Ralph",
        "timestamp": 1697533870
    },
    {
        "content": "<ol>\n<li>there are now three engines with runwasi shims: wasmedge, wasmtime, and now wasmer.</li>\n</ol>",
        "id": 397063741,
        "sender_full_name": "Ralph",
        "timestamp": 1697533990
    },
    {
        "content": "<ol start=\"2\">\n<li>downstream of runwasi, there are I think four shims: spin, slight, lunatic, and wasm workers. These are app host optimizations with nicer dev ux and custom app level features.</li>\n</ol>",
        "id": 397063909,
        "sender_full_name": "Ralph",
        "timestamp": 1697534057
    },
    {
        "content": "<p>the repository for the downstream shims is currently <a href=\"https://github.com/deislabs/containerd-wasm-shims\">https://github.com/deislabs/containerd-wasm-shims</a>.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/deislabs/containerd-wasm-shims\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/f87b1420ca61a9fd6a53e7051313099ef2bf9db0\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f366463316366323236393630343966613335306661663662633566616238636265383536643537316265326266316134373439376531623633653139376134612f646569736c6162732f636f6e7461696e6572642d7761736d2d7368696d73)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/deislabs/containerd-wasm-shims\" title=\"GitHub - deislabs/containerd-wasm-shims: containerd shims for running WebAssembly workloads in Kubernetes\">GitHub - deislabs/containerd-wasm-shims: containerd shims for running WebAssembly workloads in Kubernetes</a></div><div class=\"message_embed_description\">containerd shims for running WebAssembly workloads in Kubernetes - GitHub - deislabs/containerd-wasm-shims: containerd shims for running WebAssembly workloads in Kubernetes</div></div></div>",
        "id": 397063976,
        "sender_full_name": "Ralph",
        "timestamp": 1697534086
    },
    {
        "content": "<ol start=\"3\">\n<li>The most recent versions of shims now support \"pod agnosticity\" -- the ability of containers and modules/components to run in the same pod without any modification of k8s workloads.</li>\n</ol>",
        "id": 397064179,
        "sender_full_name": "Ralph",
        "timestamp": 1697534164
    },
    {
        "content": "<ol start=\"4\">\n<li>all shims work on both arm and amd64</li>\n</ol>",
        "id": 397064223,
        "sender_full_name": "Ralph",
        "timestamp": 1697534183
    },
    {
        "content": "<ol start=\"5\">\n<li>Windows support is coming relatively soon, so all shims will work on windows and linux.</li>\n</ol>",
        "id": 397064276,
        "sender_full_name": "Ralph",
        "timestamp": 1697534209
    },
    {
        "content": "<ol start=\"6\">\n<li>Runwasi shims are working on moving from a scratch-image delivery package to an OCI Artifact-based delivery package, meaning that only one \"image\" version is required for any execution platform, whether windows or linux, amd/arm, k8s or standalone (that is, execution of standalone app hosts will work from the same reference).</li>\n</ol>",
        "id": 397064761,
        "sender_full_name": "Ralph",
        "timestamp": 1697534400
    },
    {
        "content": "<p>at this time, we are now looking forward to wasi preview 2 with component support. As that appears, runwasi shims will update to use that and versioning will clearly mark that for people wanting to try support.</p>",
        "id": 397064963,
        "sender_full_name": "Ralph",
        "timestamp": 1697534461
    },
    {
        "content": "<p>two final things for those who care:</p>",
        "id": 397065075,
        "sender_full_name": "Ralph",
        "timestamp": 1697534506
    },
    {
        "content": "<ol>\n<li>runwasi is meant to run WASI, obviously. However, the project isn't into worrying about enforcing such things, partly in full recognition of the moving spec and reference work and partly in the belief that developers are more than able to choose their own functionality. After all, anyone can fork the project and build their own customizations in any case. What the project will do, however, as soon as it's easy to incorporate is build reports of wasi support by shims and app hosts and ensure that releases come with those reports so that if you're looking for wasi support you can easily see which shims have implementations and which shins either do not or to what extent they do.</li>\n</ol>",
        "id": 397065658,
        "sender_full_name": "Ralph",
        "timestamp": 1697534721
    },
    {
        "content": "<ol start=\"2\">\n<li>There is an issue to add a shim for wamr. Hopefully we can get that up and running relatively soon.</li>\n</ol>",
        "id": 397065724,
        "sender_full_name": "Ralph",
        "timestamp": 1697534752
    },
    {
        "content": "<p>ooh! there was a 3.</p>",
        "id": 397066020,
        "sender_full_name": "Ralph",
        "timestamp": 1697534854
    },
    {
        "content": "<ol start=\"3\">\n<li>We are collaborating with the developers of kwasm to create a robust k8s operator installation experience. Once that's done, installing, upgrading, and uninstalling can be done on current clusters and can be entirely separate from core cluster operations.</li>\n</ol>",
        "id": 397066250,
        "sender_full_name": "Ralph",
        "timestamp": 1697534936
    },
    {
        "content": "<p>that's about it for now.</p>",
        "id": 397066288,
        "sender_full_name": "Ralph",
        "timestamp": 1697534950
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"268586\">Ralph</span> <a href=\"#narrow/stream/227959-wasmtime-on-k8s/topic/status.20and.20resuscitation/near/397064179\">said</a>:</p>\n<blockquote>\n<ol start=\"3\">\n<li>The most recent versions of shims now support \"pod agnosticity\" -- the ability of containers and modules/components to run in the same pod without any modification of k8s workloads.</li>\n</ol>\n</blockquote>\n<p>Hey Ralph, would you mind clarifying this? <code>RuntimeClass</code>es apply to pods, so I was wondering how you could get a \"regular\" container and a Wasm container to run in the same <code>Pod</code> definition.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"268586\">Ralph</span> <a href=\"#narrow/stream/227959-wasmtime-on-k8s/topic/status.20and.20resuscitation/near/397064761\">said</a>:</p>\n<blockquote>\n<ol start=\"6\">\n<li>Runwasi shims are working on moving from a scratch-image delivery package to an OCI Artifact-based delivery package, meaning that only one \"image\" version is required for any execution platform, whether windows or linux, amd/arm, k8s or standalone (that is, execution of standalone app hosts will work from the same reference).</li>\n</ol>\n</blockquote>\n<p>I'd love to learn more about this, is there a PR/example/docs I can peruse? It <em>seems</em> like what this means is that rather than <code>FROM scratch</code> (not sure where this was used), runwasi will use the specified base image of the shim (does the shim supply that somehow)?</p>",
        "id": 397199984,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1697587906
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"598440\">@Victor Adossi</span>. The answers are:</p>",
        "id": 397264884,
        "sender_full_name": "Ralph",
        "timestamp": 1697619703
    },
    {
        "content": "<ol>\n<li><a href=\"https://github.com/keithmattix/istio-wasm-demo\">https://github.com/keithmattix/istio-wasm-demo</a> for an example using istio.</li>\n</ol>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/keithmattix/istio-wasm-demo\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/53793c3a88b6d0b9b8f24454bc5f0642045509ee\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f316463316466333939353032393530373233633930393835613463643964393562656239326161353161633530646462643838333439626134323632636262612f6b656974686d61747469782f697374696f2d7761736d2d64656d6f)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/keithmattix/istio-wasm-demo\" title=\"GitHub - keithmattix/istio-wasm-demo\">GitHub - keithmattix/istio-wasm-demo</a></div><div class=\"message_embed_description\">Contribute to keithmattix/istio-wasm-demo development by creating an account on GitHub.</div></div></div>",
        "id": 397264900,
        "sender_full_name": "Ralph",
        "timestamp": 1697619712
    },
    {
        "content": "<ol start=\"2\">\n<li><a href=\"https://github.com/opencontainers/image-spec/pull/1141\">https://github.com/opencontainers/image-spec/pull/1141</a> is the OCI spec work in progress. Container \"scratch\" images will still be supported, but because <em>any container image</em> is arch- and OS-specific, we can't just use one of them for all deployments, whereas the artifact approach means that we can push ONE deployment/module/component and then any runwasi shim can pull it in and do the right thing.</li>\n</ol>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/opencontainers/image-spec/pull/1141\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/169e503915088370c0d1ed1c45a530f16dc0139c\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f663434303564623335383065626630633334306138343735346337613165303865633235613737613331336439613462343564316565323065616166633162642f6f70656e636f6e7461696e6572732f696d6167652d737065632f70756c6c2f31313431)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/opencontainers/image-spec/pull/1141\" title=\"Artifacts clarification by neersighted · Pull Request #1141 · opencontainers/image-spec\">Artifacts clarification by neersighted · Pull Request #1141 · opencontainers/image-spec</a></div><div class=\"message_embed_description\">Closes #1131\nRelates to #1137\nFollow-up to #999\n\nAttempt to better clarify the conceptual differences between artifacts and images (which I tie to the config as described in this spec), and provide...</div></div></div>",
        "id": 397265220,
        "sender_full_name": "Ralph",
        "timestamp": 1697619837
    },
    {
        "content": "<p>no more multiarch builds, no custom code in runwasi to handle all possible differences.</p>",
        "id": 397265307,
        "sender_full_name": "Ralph",
        "timestamp": 1697619860
    },
    {
        "content": "<p>BTW, currently we ONLY use FROM Scratch to build minimal images with the application artifact graph inside to push to a repo. at deployment, we can then point the <code>image</code> field at a familiar \"image\" without adding funky yaml to kubernetes.</p>",
        "id": 397266507,
        "sender_full_name": "Ralph",
        "timestamp": 1697620255
    },
    {
        "content": "<p>but runwasi does not <em>run</em> that container image; instead, it pulls the image, extracts the contents, and executes those contents with the runtime (like wasmtime). The container is NOT executed; the wasm sandbox executes the contents.</p>",
        "id": 397266663,
        "sender_full_name": "Ralph",
        "timestamp": 1697620314
    },
    {
        "content": "<p>we then brought in the Youki work for OCI support, so that gave us two features in addition: it enables us to execute the wasm sandbox inside OCI features, and it enables us to run a container image and a module in the same pod, per the example above.</p>",
        "id": 397266846,
        "sender_full_name": "Ralph",
        "timestamp": 1697620376
    },
    {
        "content": "<p>Another example using Dapr is at <a href=\"https://dev.to/thangchung/series/24617\">https://dev.to/thangchung/series/24617</a>.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://dev.to/thangchung/series/24617\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/9158beda7b09cb083a5c2257ac75857908e5b0dd\\/68747470733a2f2f74686570726163746963616c6465762e73332e616d617a6f6e6177732e636f6d2f692f3668716d636a61786267626f6e3879647739337a2e706e67)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://dev.to/thangchung/series/24617\" title=\"WebAssembly, Docker container, Dapr, and Kubernetes better together Series' Articles\">WebAssembly, Docker container, Dapr, and Kubernetes better together Series' Articles</a></div><div class=\"message_embed_description\">View WebAssembly, Docker container, Dapr, and Kubernetes better together Series' Articles on DEV Community</div></div></div>",
        "id": 397266950,
        "sender_full_name": "Ralph",
        "timestamp": 1697620419
    },
    {
        "content": "<p>But FROM Scratch still had a problem: Windows won't pull that image!!!! it's an empty image, but the k8s framework on windows doesn't think it will run</p>",
        "id": 397267129,
        "sender_full_name": "Ralph",
        "timestamp": 1697620483
    },
    {
        "content": "<p>so we needed to move to an OCI Artifact approach, as that will enable one component \"artifact\" to be pulled by anyone who knows how to run it.</p>",
        "id": 397267274,
        "sender_full_name": "Ralph",
        "timestamp": 1697620535
    },
    {
        "content": "<p>that last part now works in code, but the spec work in OCI is still ongoing.</p>",
        "id": 397267313,
        "sender_full_name": "Ralph",
        "timestamp": 1697620550
    },
    {
        "content": "<p>this will also enable RTOSES and standalone application hosts (wasmcloud, spin, lunatic, anyone) to use OCI registries to pull and execute components.</p>",
        "id": 397267449,
        "sender_full_name": "Ralph",
        "timestamp": 1697620585
    },
    {
        "content": "<p>does that help?</p>",
        "id": 397267459,
        "sender_full_name": "Ralph",
        "timestamp": 1697620589
    },
    {
        "content": "<p>Thanks for the detailed explanation, this is fantastic. </p>\n<p>I didn't realize that the artifact spec was what was being used to facilitate running the two alongside each other, and I didn't see the wide ranging changes like enabling Windows and RTOSes. </p>\n<p>Thanks for the links,  will dig in and try to better understand!</p>\n<p><span class=\"user-mention silent\" data-user-id=\"268586\">Ralph</span> <a href=\"#narrow/stream/227959-wasmtime-on-k8s/topic/status.20and.20resuscitation/near/397266663\">said</a>:</p>\n<blockquote>\n<p>but runwasi does not <em>run</em> that container image; instead, it pulls the image, extracts the contents, and executes those contents with the runtime (like wasmtime). The container is NOT executed; the wasm sandbox executes the contents.</p>\n</blockquote>\n<p>Ah this makes sense -- the packaging that was necessary to get the WASM distributed -- I'd forgotten about that bit. I was wondering how you could get <em>both</em> a binary (or the equivalent \"pre-WASM\" workload) and a WASM binary out of the one artifact and have the runtime underneath know to run them both.</p>\n<p>If I'm understanding right, you'd have <em>one</em> image pushed to a registry with a <code>CMD</code> set to the binary that needs to actually run, with the WASM file also on disk somewhere, and metadata to specify the artifact (in this case the WASM file) so the runtime knows to start it, as well, right?</p>",
        "id": 397289012,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1697627719
    },
    {
        "content": "<p>I'd like to also recommend this blog: <a href=\"https://dev.to/thangchung/how-to-run-webassemblywasi-application-spin-with-dapr-on-kubernetes-2b8n\">https://dev.to/thangchung/how-to-run-webassemblywasi-application-spin-with-dapr-on-kubernetes-2b8n</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://dev.to/thangchung/how-to-run-webassemblywasi-application-spin-with-dapr-on-kubernetes-2b8n\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/b70c184e50bb2234c4cc7c802d35e1de6169b889\\/68747470733a2f2f7265732e636c6f7564696e6172792e636f6d2f70726163746963616c6465762f696d6167652f66657463682f732d2d7749304a426331542d2d2f635f696d616767615f7363616c652c665f6175746f2c666c5f70726f67726573736976652c685f3530302c715f6175746f2c775f313030302f68747470733a2f2f6465762d746f2d75706c6f6164732e73332e616d617a6f6e6177732e636f6d2f75706c6f6164732f61727469636c65732f3733346b6a3079626d677a6230666579703632352e706e67)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://dev.to/thangchung/how-to-run-webassemblywasi-application-spin-with-dapr-on-kubernetes-2b8n\" title=\"How to run WebAssembly/WASI application (Spin) with Dapr on Kubernetes\">How to run WebAssembly/WASI application (Spin) with Dapr on Kubernetes</a></div><div class=\"message_embed_description\">Introduction   As far as we know, WebAssembly (WASM) / WebAssembly System Interface (WASI)...</div></div></div>",
        "id": 397752730,
        "sender_full_name": "Mossaka (Joe)",
        "timestamp": 1697823686
    },
    {
        "content": "<p>Whoops, <span class=\"user-mention\" data-user-id=\"598440\">@Victor Adossi</span> I had forgotten to answer this, though <span class=\"user-mention\" data-user-id=\"487764\">@Mossaka (Joe)</span> might be better here.</p>",
        "id": 397756425,
        "sender_full_name": "Ralph",
        "timestamp": 1697825555
    },
    {
        "content": "<blockquote>\n<p>\"If I'm understanding right, you'd have one image pushed to a registry with a CMD set to the binary that needs to actually run, with the WASM file also on disk somewhere, and metadata to specify the artifact (in this case the WASM file) so the runtime knows to start it, as well, right?\"</p>\n</blockquote>",
        "id": 397756430,
        "sender_full_name": "Ralph",
        "timestamp": 1697825559
    },
    {
        "content": "<p>the image has only the runtime that executes for shims like spin, slight, etc. The app host shims do not use the underlying runtime because they're built with the crate/lib for that wasm runtime. They can execute standalone, in other words, so those contain a) the app host and b) the wasm module(s) to execute, and c) any config files or other artifacts. They're all dropped and executed as-is.</p>",
        "id": 397756596,
        "sender_full_name": "Ralph",
        "timestamp": 1697825665
    },
    {
        "content": "<p>the runwasi shims with merely wasm runtimes in them place the runtimes onto the node; using artifacts, you can just drop the artifact and execute it. So, slightly different paths. With artifacts, you don't push \"spin\" to the repo -- it's already on the node. You only push the module.</p>",
        "id": 397756694,
        "sender_full_name": "Ralph",
        "timestamp": 1697825725
    },
    {
        "content": "<p>Ah thank you for the detailed explanation! It makes a lot more sense to me now</p>",
        "id": 397765035,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1697830083
    },
    {
        "content": "<p>I was thinking that the image coming in would be basically empty except for the module</p>",
        "id": 397765091,
        "sender_full_name": "Victor Adossi",
        "timestamp": 1697830105
    },
    {
        "content": "<p>Actually, the examples we've shown are two images - one is the usual Linux image and one is wasm image. The difference between these two is that one has the runtime built into the image (e.x. the Python runtime) and the wasm one only have wasm files. </p>\n<p>When the shim sees the rootfs, it tries to determine whether the executable is a Linux executable or a Wasm executable. (e.g. here is the source code in runwasi to determine if the exeuctbale is a Linux executable: <a href=\"https://github.com/containerd/runwasi/blob/main/crates/containerd-shim-wasm/src/sys/unix/container/executor.rs#L86-L107\">https://github.com/containerd/runwasi/blob/main/crates/containerd-shim-wasm/src/sys/unix/container/executor.rs#L86-L107</a>)</p>",
        "id": 397770701,
        "sender_full_name": "Mossaka (Joe)",
        "timestamp": 1697832943
    },
    {
        "content": "<p><em>fancy</em></p>",
        "id": 398143888,
        "sender_full_name": "Ralph",
        "timestamp": 1698089052
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"268586\">@Ralph</span> : I don't know if this is the right place to raise this concern. Please reroute me if not.</p>\n<p>Context: At an upcoming event, I am demonstrating ways we can leverage a combination of Wasm + cloud native tech to build sustainable/greener workloads. Toward which, one of the things that I am doing is deploying the containerd shims and associated workloads per <a href=\"https://github.com/deislabs/containerd-wasm-shims/blob/main/containerd-shim-spin/quickstart.md\">this example</a>. In the demo, I'm also using the <a href=\"https://sustainable-computing.io/\">Kepler</a> &amp; the <a href=\"https://kube-green.dev/\">kube-green</a> projects to demonstrate how much memory/CPU is being consumed &amp; I noticed something odd. The pod running the wws workload, even when it was idle <strong>i.e. no curl requests were being sent its way</strong>, was consuming ~75% of the assigned CPU. The other pods consumed way way less. I will attach a screencap shortly.</p>\n<p>My question: Is this expected behavior?</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://kube-green.dev/\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/1a7ac9b98fbc37c157b6e0e9dbb6a374c9bb6de7\\/68747470733a2f2f6b7562652d677265656e2e6465762f696d672f6f672d636f7665722e706e67)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://kube-green.dev/\" title=\"kube-green\">kube-green</a></div><div class=\"message_embed_description\">kube-green documentation</div></div></div>",
        "id": 404781491,
        "sender_full_name": "Divya Mohan",
        "timestamp": 1701233295
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"618524\">Divya Mohan</span> <a href=\"#narrow/stream/227959-wasmtime-on-k8s/topic/status.20and.20resuscitation/near/404781491\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"268586\">Ralph</span> : I don't know if this is the right place to raise this concern. Please reroute me if not.</p>\n<p>Context: At an upcoming event, I am demonstrating ways we can leverage a combination of Wasm + cloud native tech to build sustainable/greener workloads. Toward which, one of the things that I am doing is deploying the containerd shims and associated workloads per <a href=\"https://github.com/deislabs/containerd-wasm-shims/blob/main/containerd-shim-spin/quickstart.md\">this example</a>. In the demo, I'm also using the <a href=\"https://sustainable-computing.io/\">Kepler</a> &amp; the <a href=\"https://kube-green.dev/\">kube-green</a> projects to demonstrate how much memory/CPU is being consumed &amp; I noticed something odd. The pod running the wws workload, even when it was idle <strong>i.e. no curl requests were being sent its way</strong>, was consuming ~75% of the assigned CPU. The other pods consumed way way less. I will attach a screencap shortly.</p>\n<p>My question: Is this expected behavior?</p>\n</blockquote>\n<p>Okay, there are a couple of things I was mistaken about here.</p>\n<ul>\n<li>It's not the CPU, but the memory.</li>\n<li>\n<p>Additionally, it's not the pod, but the wws workload that's consuming around ~49.68 MiB of the assigned 128 MiB when it is idle. That's  <strong>~38.81%</strong> and <strong>not 75%</strong>, sorry!. However, in comparison to the other workloads when they are idle, this is significantly higher. (spin 8.25%, slight 9.84%, and lunatic 6.17%). Screenshots attached below.</p>\n</li>\n<li>\n<p>For wws workload (when idle)<br>\n<a href=\"/user_uploads/15107/YH6HXVbnbd04GSCLN2YCSJhW/Screenshot-2023-11-29-at-10.41.06AM.png\">Screenshot-2023-11-29-at-10.41.06AM.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/YH6HXVbnbd04GSCLN2YCSJhW/Screenshot-2023-11-29-at-10.41.06AM.png\" title=\"Screenshot-2023-11-29-at-10.41.06AM.png\"><img src=\"/user_uploads/15107/YH6HXVbnbd04GSCLN2YCSJhW/Screenshot-2023-11-29-at-10.41.06AM.png\"></a></div></li>\n<li>\n<p>For spin workload (when idle)<br>\n<a href=\"/user_uploads/15107/_ud6r_OqQFD5DHbovj36tpzK/Screenshot-2023-11-29-at-10.43.11AM.png\">Screenshot-2023-11-29-at-10.43.11AM.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/_ud6r_OqQFD5DHbovj36tpzK/Screenshot-2023-11-29-at-10.43.11AM.png\" title=\"Screenshot-2023-11-29-at-10.43.11AM.png\"><img src=\"/user_uploads/15107/_ud6r_OqQFD5DHbovj36tpzK/Screenshot-2023-11-29-at-10.43.11AM.png\"></a></div></li>\n</ul>",
        "id": 404784943,
        "sender_full_name": "Divya Mohan",
        "timestamp": 1701234630
    },
    {
        "content": "<p>Morning from Italy, Divya! The wws shim just uses the wws priest, and nothing more</p>",
        "id": 404803603,
        "sender_full_name": "Ralph",
        "timestamp": 1701243237
    },
    {
        "content": "<p>So my assumption is that it's just a large project.... It's apache after all,basically</p>",
        "id": 404803717,
        "sender_full_name": "Ralph",
        "timestamp": 1701243268
    },
    {
        "content": "<p>Let's ping angel at VMware and see what he says...</p>",
        "id": 404803900,
        "sender_full_name": "Ralph",
        "timestamp": 1701243343
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"512058\">@Angel M</span> any thoughts?</p>",
        "id": 404804474,
        "sender_full_name": "Ralph",
        "timestamp": 1701243622
    },
    {
        "content": "<p>Thanks, I thought as much! Just wanted to clarify before I jump to conclusions <span aria-label=\"joy\" class=\"emoji emoji-1f602\" role=\"img\" title=\"joy\">:joy:</span>  I'll wait for Angel to answer :)</p>",
        "id": 404861119,
        "sender_full_name": "Divya Mohan",
        "timestamp": 1701263046
    },
    {
        "content": "<p>the shims themselves merely consume the upstream runwasi crate, so anything \"different\" is what the shim app host brings.....</p>",
        "id": 404874328,
        "sender_full_name": "Ralph",
        "timestamp": 1701267077
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"618524\">@Divya Mohan</span>,</p>\n<p>This is amazing! It's really cool to see the comparison between containers / Wasm / Wasm runtimes running side by side <span aria-label=\"smiley\" class=\"emoji emoji-1f603\" role=\"img\" title=\"smiley\">:smiley:</span>. In the case of wws, the example is running a JS based module, which contains an entire QuickJS interpreter + JS Polyfill code inside the Wasm module. Without checking it yet, I believe it's the main reason for the memory footprint is higher in this example. I believe a Rust example will use less memory, but we wanted to use JS to showcase this specific language.</p>\n<p>In addition to that, we spawn the entire <code>wws</code> server, which contains different libraries as <span class=\"user-mention\" data-user-id=\"268586\">@Ralph</span> mentioned. Would you mind to open a discussion on the GitHub project? The information you provided here is more than enough, just wanted to keep track of it and start digging into the issue: <a href=\"https://github.com/vmware-labs/wasm-workers-server/discussions\">https://github.com/vmware-labs/wasm-workers-server/discussions</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/vmware-labs/wasm-workers-server/discussions\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/acd2220ffcfe17e8842fdd11d5145971e800028b\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f363166636163343863643362343136653136633062326334333164346531326661646636616437383161313535313935626462663338346565633933653236302f766d776172652d6c6162732f7761736d2d776f726b6572732d736572766572)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/vmware-labs/wasm-workers-server/discussions\" title=\"vmware-labs/wasm-workers-server · Discussions\">vmware-labs/wasm-workers-server · Discussions</a></div><div class=\"message_embed_description\">Explore the GitHub Discussions forum for vmware-labs wasm-workers-server. Discuss code, ask questions &amp; collaborate with the developer community.</div></div></div>",
        "id": 404907340,
        "sender_full_name": "Angel M",
        "timestamp": 1701276094
    },
    {
        "content": "<p>And thank you <span class=\"user-mention\" data-user-id=\"268586\">@Ralph</span> for the ping here!</p>",
        "id": 404907395,
        "sender_full_name": "Angel M",
        "timestamp": 1701276116
    },
    {
        "content": "<p>in short, it's more of a scale-out web server than a serverless function host in design, and the footprint indicates that, though I'm sure it can be configured differently.</p>",
        "id": 404914234,
        "sender_full_name": "Ralph",
        "timestamp": 1701278101
    },
    {
        "content": "<p>Thanks gentlemen for your response!</p>\n<p><span class=\"user-mention\" data-user-id=\"512058\">@Angel M</span> : I've opened up a <a href=\"https://github.com/vmware-labs/wasm-workers-server/discussions/258\">discussion</a>. If you do need anything else from my side for the investigation, I'd be happy to help!</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/vmware-labs/wasm-workers-server/discussions/258\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/1087c9b6e425eee40427b2597b4b4a137513aa78\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f666430343037313536613437636539366130393632623132613866373334646230376362626333383934356132646235356436303633326366636335373361632f766d776172652d6c6162732f7761736d2d776f726b6572732d7365727665722f64697363757373696f6e732f323538)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/vmware-labs/wasm-workers-server/discussions/258\" title=\"WWS workload with containerd shim taking more CPU as compared to other Wasm workloads · vmware-labs/wasm-workers-server · Discussion #258\">WWS workload with containerd shim taking more CPU as compared to other Wasm workloads · vmware-labs/wasm-workers-server · Discussion #258</a></div><div class=\"message_embed_description\">This is per the discussion on the Bytecode Alliance Zulip regarding Wasm workers server workloads taking way more memory (~38%) as compared to other Wasm workloads from the same example. To do: Pro...</div></div></div>",
        "id": 404991597,
        "sender_full_name": "Divya Mohan",
        "timestamp": 1701310702
    },
    {
        "content": "<p>Thank you <span class=\"user-mention\" data-user-id=\"618524\">@Divya Mohan</span> !!</p>",
        "id": 405162683,
        "sender_full_name": "Angel M",
        "timestamp": 1701364227
    }
]