[
    {
        "content": "<p>What is the current best practice to measure and report WebAssembly runtime performance(outside browser)? One of the most recent publications in this field is this: <a href=\"https://github.com/wabench\">https://github.com/wabench</a>. I have currently the following concerns:</p>\n<ul>\n<li>How do you deal with runtime startup and teardown cost?</li>\n<li>How do you deal with JIT effects (I am unsure whether the JITs of Wasm runtimes are as sophisticated as the ones found in JVMs, but still).</li>\n<li>Several programs in wabench emit significant amount of printouts. Is it reasonable to include these in the timing measurements?</li>\n</ul>\n<p>For the first concern, I am thinking that I could either measure the time for an \"empty\" main program and subtract that from other measurements. For the second I guess I could add a repetition loop inside the main and disregard the first 100 iterations of 200 (or how long it takes to warm up the JIT). The first concern could also be resolved with this method having the timing done in the code itself.</p>\n<p>Finally, would it be meaningful for the Bytecode Alliance to consider setting up an approved runtime performance benchmark suite? I would be interested in helping out with this work, if wo. Besides wabench we also have the libsodium which has been used to benchmark wasm runtimes as well: <a href=\"https://00f.net/2023/01/04/webassembly-benchmark-2023/\">https://00f.net/2023/01/04/webassembly-benchmark-2023/</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/wabench\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/d668a22ecdedfe8e15390f7ddb04632c2fba50f4\\/68747470733a2f2f617661746172732e67697468756275736572636f6e74656e742e636f6d2f752f3131353139363739313f763d343f733d343030)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/wabench\" title=\"wabench - Overview\">wabench - Overview</a></div><div class=\"message_embed_description\">wabench has one repository available. Follow their code on GitHub.</div></div></div>",
        "id": 327539374,
        "sender_full_name": "Mats Brorsson",
        "timestamp": 1676292582
    },
    {
        "content": "<p>We use the sightglass benchmark suite to track Wasmtime/Cranelift performance for our own needs but actively discourage benchmark wars</p>\n<ul>\n<li><a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a></li>\n<li>Details and aspirations here: <a href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md\">https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md</a><ul>\n<li>In particular see the \"non-goals\" section</li>\n</ul>\n</li>\n</ul>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/e1a652e8294129a22cee0196483ee65574c64999\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f386232306461653965376465306337326533306464643565383336393338656132626166613630663236383464356430646163633961623839303962373733662f62797465636f6465616c6c69616e63652f7369676874676c617373)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass\" title=\"GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.\">GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of th...</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/58c9f98c3c4ecb48d38b8e9cd8288f266d03313b\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f633035323066386239323035343166623337613634373461313266613366666164623831646165316539653637383239646236386536663831366635363362382f62797465636f6465616c6c69616e63652f72666373)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md\" title=\"rfcs/benchmark-suite.md at main · bytecodealliance/rfcs\">rfcs/benchmark-suite.md at main · bytecodealliance/rfcs</a></div><div class=\"message_embed_description\">RFC process for Bytecode Alliance projects. Contribute to bytecodealliance/rfcs development by creating an account on GitHub.</div></div></div>",
        "id": 327657468,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1676327125
    },
    {
        "content": "<p>Thanks a lot, it's very helpful.</p>\n<p>However, if I were to compare two runtimes for use outside the browser, do you have any comments on my concerns?</p>\n<p><span class=\"user-mention silent\" data-user-id=\"253990\">fitzgen (he/him)</span> <a href=\"#narrow/stream/223391-wasm/topic/Benchmarking.20runtime.20performance/near/327657468\">said</a>:</p>\n<blockquote>\n<p>We use the sightglass benchmark suite to track Wasmtime/Cranelift performance for our own needs but actively discourage benchmark wars</p>\n<ul>\n<li><a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a></li>\n<li>Details and aspirations here: <a href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md\">https://github.com/bytecodealliance/rfcs/blob/main/accepted/benchmark-suite.md</a><ul>\n<li>In particular see the \"non-goals\" section</li>\n</ul>\n</li>\n</ul>\n</blockquote>",
        "id": 327733183,
        "sender_full_name": "Mats Brorsson",
        "timestamp": 1676368618
    },
    {
        "content": "<p>Your specific concerns are addressed by Sightglass: runtime setup/teardown is addressed with an explicit separation of phases, so Sightglass measures only the actual (compilation, instantiation, execution) and nothing else; JIT effects are N/A in Wasmtime as we compile the whole module with our only tier (Cranelift optimizing mode) on load; and we avoid excessive IO in benchmarks that could become a bottleneck instead of CPU time</p>",
        "id": 327810113,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1676389912
    },
    {
        "content": "<p>I'll add a bit of detail to <span class=\"user-mention\" data-user-id=\"253990\">@fitzgen (he/him)</span> 's point about \"benchmark wars\": we recognize folks will want to compare engines, and actually I think that's a very useful data point (of course one wants to know whether an engine is fast enough, or which one is most efficient, when choosing what to use), but the main concern is just against incentivizing a \"performance at any cost\" culture. This comes in particular from the browser world where a singleminded focus on microbenchmark performance led JS engines astray with overcomplex optimizations; and in the case of the web it turns out that most code is cold and load/start time matters a lot more. The analogous guidance in the Wasm engine world might be: it's important to know what the whole system's performance characteristics and requirements are, and consciously choose a design point that fits those. E.g. Cranelift is less optimizing than LLVM but it's far simpler, and we're working on novel ways to formally verify it, which is made feasible because of its simplicity</p>",
        "id": 327811966,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1676390385
    },
    {
        "content": "<p>All of that said, though, we <em>are</em> interested (or at least I am) in relative performance measurements insofar as they can point out where we can do better. If you find anything surprising, please do let us know!</p>",
        "id": 327812199,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1676390431
    },
    {
        "content": "<p>from the corporate world I can add: We only benchmark the solution, then drive in on bottlenecks. In distributed work, it's the solution speed that matters, not the pure speed of a single component. That said, we've benchmarked several runtimes including wasmtime in high performance solutions and.... the runtimes are not the throughput problem.</p>",
        "id": 327818001,
        "sender_full_name": "Ralph",
        "timestamp": 1676391917
    },
    {
        "content": "<p>A question about Sightglass, can the CPU cycles it reports be translated into real time by dividing them with the CPU clock frequency (assuming it is locked)? Is time spent waiting for IO to complete and system calls included in the CPU cycles?</p>",
        "id": 328054677,
        "sender_full_name": "wsta",
        "timestamp": 1676478828
    },
    {
        "content": "<blockquote>\n<p>can the CPU cycles it reports be translated into real time by dividing them with the CPU clock frequency (assuming it is locked)?</p>\n</blockquote>\n<p>It can be translated into task clock time. The task clock time is the result of adding the time the process spent on each cpu core (excluding waiting for io or sleeping) together. The wall clock time is the time from the start of the process until the end. This includes any time waiting on io and sleeping and counts any second during which multiple cpu cores are used as a single second, while task clock time counts a second for each cpu core that was running it.</p>\n<blockquote>\n<p>Is time spent waiting for IO to complete and system calls included in the CPU cycles?</p>\n</blockquote>\n<p>No for IO, yes for system calls. cpu-cycles includes system calls. cpu-cycles:u only includes userspace time. Sightglass uses cpu-cycles, not cpu-cycles:u.</p>",
        "id": 328068477,
        "sender_full_name": "bjorn3",
        "timestamp": 1676482483
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"581902\">@wsta</span>, you might be interested in the other measurement mechanisms in Sightglass as well: <code>cycles</code> is the default since it is the most portable but you might interested in <code>perf-counters</code> on Linux, which uses <code>perf</code> to get different rows of data. There are others there if you run <code>sightglass benchmark --help</code> and more can be added if needed.</p>",
        "id": 328123124,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1676501349
    },
    {
        "content": "<p>Thanks to you both!</p>",
        "id": 328182956,
        "sender_full_name": "wsta",
        "timestamp": 1676538064
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"268586\">Ralph</span> <a href=\"#narrow/stream/223391-wasm/topic/Benchmarking.20runtime.20performance/near/327818001\">said</a>:</p>\n<blockquote>\n<p>from the corporate world I can add: We only benchmark the solution, then drive in on bottlenecks. In distributed work, it's the solution speed that matters, not the pure speed of a single component. That said, we've benchmarked several runtimes including wasmtime in high performance solutions and.... the runtimes are not the throughput problem.</p>\n</blockquote>\n<p>I'm joining this conversation late, and thanks <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span>  for pointing me here.</p>\n<p>Yes, the overall solution is important, however, which choosing a runtime implementation having knowledge of any peformance characteristics and differences between the engines is important. It is a comparison we did. That's not to say one engine is \"better\" than another. That is only to say some engines are designed for different environments and cope with differing workloads in different ways. - After all, we have both Wasmtime and WAMR.</p>\n<p>It is important that our internal engineering teams understand the characteristics of each.</p>",
        "id": 329275542,
        "sender_full_name": "Chris Woods",
        "timestamp": 1677008216
    },
    {
        "content": "<p><strong>Re posting here, after a great redirect</strong></p>\n<p>Hi folks. We've a framework we created for building and testing multiple non-web based WASM engines, it gathers informaiton on jitter, latency, and compares various algortthms between the differning engines and against native speed too. We shared our results initial at the WASM Research event last year. It's taken a while, but we've got the necessary internal approval (it took a while, longer than expected) to share this framework and the tests as an Apache2 licensed open source contribution.... </p>\n<p>We're hoping this would help toward to wider community goal of having a shared set of tests and a framework to run time. It was originally created by us as a home grown way to provide some repeatable, cross engine performance tests. To allow us to better understand the timing, jitter, and potential real time use cases for WASM and the various runtimes. The  test framework accounts for the different engines and all the possible ways in which they could be configured, for for WAMR - it covers AoT, JIT, Fast Interpreter, and Standard Interpreter.</p>\n<p>What I think is of value here, is that the framework includes all the scafolding and code for downloading the latest branchs of various non-web runtimes, building them each several times with muiltiple configuration options and then running a set of tests. Each test is run multiple times. As a guide a single test run would gather over 50k data points.</p>\n<p>Now the tests themsevles are not limited, they can of course be changed. But our inital thought was that the framework and the scaffolding it provides might be useful if there was a desire to create cross engine performance tooling... </p>\n<p>I see SightGlass exists, and to be fair we created this framework in isolation, so I'm not sure if some of it would be of interest at all. - Of course no offence taken if it isn't.  </p>\n<p>Are there any other efforts within the alliance to create this type of cross-engine performance analysis? -- Is this something we feel we'd need?</p>\n<p>As I post this - I'm playing catch up and reading <span class=\"user-mention\" data-user-id=\"253990\">@fitzgen (he/him)</span> 's benchmark-suite link..</p>",
        "id": 329278285,
        "sender_full_name": "Chris Woods",
        "timestamp": 1677009077
    },
    {
        "content": "<p>more information is always good. I have never, ever met humans that didn't use the requirement for component benchmarking as an excuse to ignore the solution's performance.  I include myself in that space. It's a human thing, generally. But I love more info, too.</p>",
        "id": 329282039,
        "sender_full_name": "Ralph",
        "timestamp": 1677010255
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"435699\">@Chris Woods</span>, I'd be interested to talk to you about your framework and I can probably more quickly compare and contrast it with Sightglass since I've worked on that project. I will say that Sightglass has needed to add the ability to add more Wasm engines for a while now but some of that work has been stuck due to other work (I started but did not finish a V8 integration <a href=\"https://github.com/bytecodealliance/sightglass/pull/166\">here</a> and <span class=\"user-mention\" data-user-id=\"253991\">@Yury Delendik</span> had a SpiderMonkey integration that has not been upstreamed). So I think your work is in the \"might be helpful!\" category. Do you want to message me privately to set up time to talk?</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass/pull/166\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/79577bfbc6ed7ae52e4934e2ab444ce35cfd4e49\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f386361393539653430653761333963663566353237333439373130356362313336663534646263393938326666663031363639303931353066393831346335612f62797465636f6465616c6c69616e63652f7369676874676c6173732f70756c6c2f313636)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass/pull/166\" title=\"Add a V8 engine by abrown · Pull Request #166 · bytecodealliance/sightglass\">Add a V8 engine by abrown · Pull Request #166 · bytecodealliance/sightglass</a></div><div class=\"message_embed_description\">This change adds the beginnings of a new V8 engine to Sightglass. It uses V8's libwee8 library as the backing engine and constructs a libengine.so in C++ that is compatible with Sightglass. As-is, ...</div></div></div>",
        "id": 329309486,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1677020510
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"254110\">@Andrew Brown</span>  - thanks for the ping, yes would love to chat. I'll drop you a message to setup a time for a chat!</p>",
        "id": 329436075,
        "sender_full_name": "Chris Woods",
        "timestamp": 1677074943
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"435699\">@Chris Woods</span> do you have a link to your benchmark framework?</p>",
        "id": 329513046,
        "sender_full_name": "Mats Brorsson",
        "timestamp": 1677094329
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"506554\">@Mats Brorsson</span>  Hey Mats, I'm currently caught in a catch-22, the internal company process wants to know where I will share it. Happy to host a 20-30 min meeting to give an overview of the framework, if that would be of interest ?</p>",
        "id": 329741994,
        "sender_full_name": "Chris Woods",
        "timestamp": 1677164500
    },
    {
        "content": "<p>Definitely, I’d like my PhD student to join as well. Which time zone are you in. We’re at CET.</p>",
        "id": 329743005,
        "sender_full_name": "Mats Brorsson",
        "timestamp": 1677164764
    }
]