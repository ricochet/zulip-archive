[
    {
        "content": "<p>Are there any reports on cranelift and RA2's performance? Flamegraphs generated? What percentage of time of overall compilation should I expect register allocation to take?(right now it's around 40%, where as isel(dag tiling), optimizations, and more occupy less than half that.</p>",
        "id": 454730162,
        "sender_full_name": "Leaves",
        "timestamp": 1722232810
    },
    {
        "content": "<p>For a paper we took time measurements of the overall compilation pipeline (<a href=\"/user_uploads/15107/7nRkE3-JHDcj_uYawIii5l6j/BDEE5997-5C92-4E1B-BAAC-B5984B44EB67.jpg\">BDEE5997-5C92-4E1B-BAAC-B5984B44EB67.jpg</a>)</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/7nRkE3-JHDcj_uYawIii5l6j/BDEE5997-5C92-4E1B-BAAC-B5984B44EB67.jpg\" title=\"BDEE5997-5C92-4E1B-BAAC-B5984B44EB67.jpg\"><img data-original-dimensions=\"1239x556\" src=\"/user_uploads/thumbnail/15107/7nRkE3-JHDcj_uYawIii5l6j/BDEE5997-5C92-4E1B-BAAC-B5984B44EB67.jpg/840x560.webp\"></a></div><p>We did a bit of profiling but not a lot made it into the results due to space constraints and we concluded that the problems are more of algorithmic nature. Wrt RA2 specifically, we got similar results (roughly 50% of time spent in register allocation). IMO it is simply a pretty slow algorithm (and the strict separation between cranelift and RA2 also doesn&lsquo;t help in some cases).</p>",
        "id": 454735430,
        "sender_full_name": "T0b1",
        "timestamp": 1722234858
    },
    {
        "content": "<p>In my own compiler using RA2 it spends around 70% of the time in register allocation.</p>",
        "id": 454748013,
        "sender_full_name": "Amanieu",
        "timestamp": 1722238609
    },
    {
        "content": "<p>Is that paper published?</p>",
        "id": 454819863,
        "sender_full_name": "bjorn3",
        "timestamp": 1722256297
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"264278\">bjorn3</span> <a href=\"#narrow/stream/217117-cranelift/topic/Cranelift.20Profiling.2E/near/454819863\">said</a>:</p>\n<blockquote>\n<p>Is that paper published?</p>\n</blockquote>\n<p>If you mean our paper, it was published at CGO this year. A preprint is available <a href=\"https://home.in.tum.de/~engelke/pubs/2403-cgo.pdf\">here</a></p>",
        "id": 454854812,
        "sender_full_name": "T0b1",
        "timestamp": 1722263943
    },
    {
        "content": "<p>Thanks! Interesting to see that regalloc is much faster for LLVM than for Cranelift.</p>",
        "id": 454864880,
        "sender_full_name": "bjorn3",
        "timestamp": 1722266178
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"563135\">T0b1</span> <a href=\"#narrow/stream/217117-cranelift/topic/Cranelift.20Profiling.2E/near/454735430\">said</a>:</p>\n<blockquote>\n<p>~~</p>\n</blockquote>\n<p>Ok glad to know I'm somewhat on track.</p>\n<p>Flamegraph revealing RA2 spends 30%(13% of overall compilation) of it's time in .collect()....</p>",
        "id": 454881564,
        "sender_full_name": "Leaves",
        "timestamp": 1722270388
    },
    {
        "content": "<p>And the results are steady across compilations lots of binaries, including several over 200mb</p>",
        "id": 454881958,
        "sender_full_name": "Leaves",
        "timestamp": 1722270496
    },
    {
        "content": "<blockquote>\n<p>Cranelift-IR (CIR)</p>\n</blockquote>\n<p>fyi: Cranelift's IR is called CLIF</p>",
        "id": 454883896,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1722270997
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"264278\">bjorn3</span> <a href=\"#narrow/stream/217117-cranelift/topic/Cranelift.20Profiling.2E/near/454864880\">said</a>:</p>\n<blockquote>\n<p>Thanks! Interesting to see that regalloc is much faster for LLVM than for Cranelift.</p>\n</blockquote>\n<p>Haven't actually read the paper yet, just skimming now, but is it actually <em>faster</em> or does it take less relative time because LLVM is doing so much more in the mid-end?</p>",
        "id": 454884031,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1722271043
    },
    {
        "content": "<p>It's actually faster. But there may be several factors involved. For example if Cranelift generates more code due to poor optimizations then it will have to spend more time in register allocation.</p>",
        "id": 454886414,
        "sender_full_name": "Amanieu",
        "timestamp": 1722271625
    },
    {
        "content": "<p>While I agree with that, Idk if it could account for this big of a difference.</p>",
        "id": 454886517,
        "sender_full_name": "Leaves",
        "timestamp": 1722271661
    },
    {
        "content": "<blockquote>\n<p>Flamegraph revealing RA2 spends 30%(13% of overall compilation) of it's time in .collect()....</p>\n</blockquote>\n<p>This doesn't mean too much to me in isolation -- in several places RA2 uses iterator-chain constructions to compute results, that are in the end collected into a new data structure. Certainly we've been really careful not to allocate small intermediate objects (almost all the work is operating on a few large arrays of different entity types) so it's not the usual low-hanging fruit that one could infer from this.</p>\n<p>In general I've spent a lot of time (several months fulltime) profiling RA2, and at least back in 2021/2022 I found most of what I could, heavily optimized data structure size and layout, and eeked out a bunch of 1-2% wins, so I believe it's pretty close to a local optimum for its design point. I think any big wins are going to have to come from algorithmic changes, as someone mentioned upthread: fewer splits, for example, or better bundle merging, or ... and all those have complexity and generated-code-quality tradeoffs.</p>\n<p>If someone comparing against LLVM were to point out some specific design choices that seem to make a difference, or compare other statistics (e.g., number of liveranges, number of splits, number of backtracking points, that sort of thing) that'd be quite useful -- and as always PRs welcome!</p>",
        "id": 454917500,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722278552
    },
    {
        "content": "<p>Reading a bit more of the paper, I find myself a little perplexed, e.g. here</p>\n<blockquote>\n<p>roughly 6% of register allocation time is spent inserting and looking up values in B-trees. Using a greedy approach instead could significantly improve register allocation performance.</p>\n</blockquote>\n<p>The B-trees (the allocation maps) are how we know which registers are free; these lookups are necessary. I'm not sure what \"a greedy approach\" could mean: do you mean something like a linear-scan allocator, where we only need the current snapshot-in-time availability (one bit per register)? That fundamentally won't work because this is a backtracking allocator and needs to record allocations across all program points to undo them.</p>\n<p>Also the description of RA2 as \" a modified linear-scan allocator that calculates live-ranges for virtual registers, merges non-overlapping ones into bundles and splits them if too many are live in physical registers at the same time.\" is not really accurate: linear-scan implies a single pass to allocate (possibly with a pre-pass to compute liveness?), whereas RA2 can evict, split, and reallocate the smaller pieces -- it is backtracking.</p>",
        "id": 454919045,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722279057
    },
    {
        "content": "<p>I'm playing around with creating reuseable environment to lower the number of heap allocations made. This is looking very promising when compiling large binaries <span aria-label=\"eyes\" class=\"emoji emoji-1f440\" role=\"img\" title=\"eyes\">:eyes:</span></p>",
        "id": 454930868,
        "sender_full_name": "Leaves",
        "timestamp": 1722282165
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/Cranelift.20Profiling.2E/near/454919045\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>roughly 6% of register allocation time is spent inserting and looking up values in B-trees. Using a greedy approach instead could significantly improve register allocation performance.</p>\n</blockquote>\n<p>The B-trees (the allocation maps) are how we know which registers are free; these lookups are necessary. I'm not sure what \"a greedy approach\" could mean: do you mean something like a linear-scan allocator, where we only need the current snapshot-in-time availability (one bit per register)? That fundamentally won't work because this is a backtracking allocator and needs to record allocations across all program points to undo them.</p>\n</blockquote>\n<p>The wording is confusing, yes. What we mean is that we think that switching to a simple (linear scan) greedy algorithm like LLVM's FastRegAlloc or DirectEmit's for register allocation is a better way to fix the register allocation performance (at least in a JIT setting where compilation performance is important).<br>\nBoth of these allocators iterate only once over the IR (LLVM backwards, DirectEmit forwards) and just assign any free register or spill using some simple heuristics without being able to reverse any decision made.<br>\nLLVM's allocator does not construct liveness information, DirectEmit constructs live intervals based on loops instead of ranges.<br>\nI'm no too familiar with LLVM's design in particular however, the other author looked at that, so I do not know what heuristics they are using exactly.</p>\n<p><a href=\"https://github.com/golang/go/blob/master/src/cmd/compile/internal/ssa/regalloc.go\">Go's register allocator</a> might also be interesting, it does some more advanced stuff but is still relatively fast AFAIK (though we haven't benchmarked it).</p>\n<p>This obviously leads to worse codegen (DirectEmit for example has some problems with \"overspilling\" due to its architecture)<br>\nbut it is still pretty good (as seen in the runtime benchmarks).</p>\n<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/Cranelift.20Profiling.2E/near/454919045\">said</a>:</p>\n<blockquote>\n<p>Also the description of RA2 as \" a modified linear-scan allocator that calculates live-ranges for virtual registers, merges non-overlapping ones into bundles and splits them if too many are live in physical registers at the same time.\" is not really accurate: linear-scan implies a single pass to allocate (possibly with a pre-pass to compute liveness?), whereas RA2 can evict, split, and reallocate the smaller pieces -- it is backtracking.</p>\n</blockquote>\n<p>I might have gotten confused. I think I saw some references to the original Linear Scan paper when I was reading up about it so that's where that might be coming from though I'm not sure anymore.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/golang/go/blob/master/src/cmd/compile/internal/ssa/regalloc.go\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/369131b80ff939112bff647879e2cb1f4bf64266/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f363861386637306662333134643231653666313839613262306164326364626663323734313532386139313661643866633466373636363638303332333165612f676f6c616e672f676f&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/golang/go/blob/master/src/cmd/compile/internal/ssa/regalloc.go\" title=\"go/src/cmd/compile/internal/ssa/regalloc.go at master · golang/go\">go/src/cmd/compile/internal/ssa/regalloc.go at master · golang/go</a></div><div class=\"message_embed_description\">The Go programming language. Contribute to golang/go development by creating an account on GitHub.</div></div></div>",
        "id": 455126061,
        "sender_full_name": "T0b1",
        "timestamp": 1722346986
    },
    {
        "content": "<p>You'll be happy to know that a Google Summer of Code project participant is actually writing a linear-scan algorithm to have as an option in RA2, so we will actually have that option!</p>",
        "id": 455150483,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722353181
    },
    {
        "content": "<p>Ah, cool that it got picked up. I‘ll definitely check out the results once it‘s available</p>",
        "id": 455165558,
        "sender_full_name": "T0b1",
        "timestamp": 1722357199
    },
    {
        "content": "<p>It's not actually linear-scan, it's a single-pass backwards allocator. Linear scan requires building live ranges for each value, which a backwards allocator doesn't.</p>",
        "id": 455166209,
        "sender_full_name": "Amanieu",
        "timestamp": 1722357437
    },
    {
        "content": "<p>I too am guilty of approximating the meaning of linear-scan :-) Yes, even simpler and faster; inspiration from the SSRA (solid-state register allocator) post</p>",
        "id": 455167339,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722357831
    },
    {
        "content": "<p>By the way, I noticed in profiles that regalloc2 spends 2.5x more time in <code>merge_vreg_bundle</code> than regalloc3 does despite using the same algorithm.</p>\n<p>In regalloc3 I only allow blockparams on blocks with more than one predecessor, so the regalloc2-&gt;regalloc3 adaptation layer is eliminating all the unnecessary blockparams by renaming vregs into values. Perhaps that's a sign that there is some performance to gain if Cranelift stops emitting these unnecessary blockparams?</p>",
        "id": 455239307,
        "sender_full_name": "Amanieu",
        "timestamp": 1722382102
    },
    {
        "content": "<p>certainly possible; this is with optimizations enabled (including CL's constant phi removal pass) or no?</p>",
        "id": 455239537,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722382181
    },
    {
        "content": "<p>we have had issues with excess blockparam creation in the past</p>",
        "id": 455239574,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722382193
    },
    {
        "content": "<p>It was with the default for <code>wasmtime compile</code>, I'm not sure if this enables optimizations.</p>",
        "id": 455240580,
        "sender_full_name": "Amanieu",
        "timestamp": 1722382514
    },
    {
        "content": "<p>It was definitely triggering errors in my validator about blockparams on functions with only 1 predecessor.</p>",
        "id": 455240640,
        "sender_full_name": "Amanieu",
        "timestamp": 1722382538
    },
    {
        "content": "<p>I even tried including <a href=\"https://github.com/bytecodealliance/wasmtime/pull/8565\">https://github.com/bytecodealliance/wasmtime/pull/8565</a> but it was still generating unnecessary blockparams.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/pull/8565\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/bcf7f4144e3c65e8ea50c4c1520c268d9e22e479/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f376232363439353962373962633237393462383065356364343266656430633839626461393937336230663766383035323462383066313437626338333932622f62797465636f6465616c6c69616e63652f7761736d74696d652f70756c6c2f38353635&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/pull/8565\" title=\"wasmtime: Remove ALL constant phis by jameysharp · Pull Request #8565 · bytecodealliance/wasmtime\">wasmtime: Remove ALL constant phis by jameysharp · Pull Request #8565 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">When we're trying to delete block-params that can be replaced by a single dominating value, we weren't handling some cases.\nIn particular, if we concluded that a block formal parameter (say, v3) ha...</div></div></div>",
        "id": 455240745,
        "sender_full_name": "Amanieu",
        "timestamp": 1722382575
    },
    {
        "content": "<p>Does crane lift produce a pruned ssa? I don’t think so…</p>",
        "id": 455295767,
        "sender_full_name": "Leaves",
        "timestamp": 1722407904
    },
    {
        "content": "<p>So it isn’t trying to remove all truly useless phis</p>",
        "id": 455295779,
        "sender_full_name": "Leaves",
        "timestamp": 1722407917
    },
    {
        "content": "<p>Or rather, it may be removing dead phis, that don’t really join anything, but it might not(and I don’t think is) removing all truly useless phis</p>",
        "id": 455295796,
        "sender_full_name": "Leaves",
        "timestamp": 1722407930
    },
    {
        "content": "<p>I’m not sure yet though and I’m studying the code daily trying to get a better understanding of</p>",
        "id": 455295816,
        "sender_full_name": "Leaves",
        "timestamp": 1722407942
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"732970\">@Leaves</span> The remove-constant-phis pass at least claims to remove \"useless phis\" (those with all inputs the same) as well</p>",
        "id": 455401900,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1722439190
    }
]