[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span>, <span class=\"user-mention\" data-user-id=\"253994\">@Alex Crichton</span>: this morning I paged in more information related to the question Alex asked about alignment and load coalescing. The original patch where I disabled load-coalescing for SIMD operations is <a href=\"https://github.com/bytecodealliance/wasmtime/pull/3107/files#diff-4adf48ae85aed38db700830cef790888a48d3bc15acd7d01a219ab35762ca0e9R158-R160\">this one</a>--e.g., if an instruction uses vectors and the load is not aligned, forget about load-coalescing.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/pull/3107/files#diff-4adf48ae85aed38db700830cef790888a48d3bc15acd7d01a219ab35762ca0e9R158-R160\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/8fff9b98e52457f5294f6cecacc3a1b554832425\\/68747470733a2f2f617661746172732e67697468756275736572636f6e74656e742e636f6d2f752f3534313838303f733d34303026763d34)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/pull/3107/files#diff-4adf48ae85aed38db700830cef790888a48d3bc15acd7d01a219ab35762ca0e9R158-R160\" title=\"x64: avoid load-coalescing SIMD operations with non-aligned loads by abrown · Pull Request #3107 · bytecodealliance/wasmtime\">x64: avoid load-coalescing SIMD operations with non-aligned loads by abrown · Pull Request #3107 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Fixes #2943, though not as optimally as may be desired. With x64 SIMD\ninstructions, the memory operand must be aligned--this change adds that\ncheck. There are cases, however, where we can do better...</div></div></div>",
        "id": 261581476,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022365
    },
    {
        "content": "<p>I think Alex's question was whether this was always the case in x64 and I vaguely mumbled something about classes of instructions.</p>",
        "id": 261581518,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022395
    },
    {
        "content": "<p>ah yes that's what I was remembering, thanks for digging that up!</p>",
        "id": 261581538,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1637022409
    },
    {
        "content": "<p>The official answer is this:</p>",
        "id": 261581579,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022441
    },
    {
        "content": "<p>From the Intel manual, section 14.9: \"Most arithmetic and data processing instructions encoded using the VEX prefix and performing memory accesses have more flexible memory alignment requirements than instructions that are encoded without the VEX prefix. Specifically,<br>\n• With the exception of explicitly aligned 16 or 32 byte SIMD load/store instructions, most VEX-encoded, arithmetic and data processing instructions operate in a flexible environment regarding memory address alignment, i.e. VEX-encoded instruction with 32-byte or 16-byte load semantics will support unaligned load operation by default. Memory arguments for most instructions with VEX prefix operate normally without <br>\ncausing #GP(0) on any byte-granularity alignment (unlike Legacy SSE instructions). The instructions that require explicit memory alignment requirements are listed in Table 14-22.\"</p>",
        "id": 261581748,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022547
    },
    {
        "content": "<p><a href=\"/user_uploads/15107/1oVI4g3mIh1fBqR4PdvG4GZT/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/1oVI4g3mIh1fBqR4PdvG4GZT/image.png\" title=\"image.png\"><img src=\"/user_uploads/15107/1oVI4g3mIh1fBqR4PdvG4GZT/image.png\"></a></div>",
        "id": 261581787,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022580
    },
    {
        "content": "<p>I think the bottom line is that if we switched to using AVX* encodings (i.e. VEX) for 128-bit SIMD we could re-allow the load coalescing regardless of the alignment of the memory operand</p>",
        "id": 261581959,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637022687
    },
    {
        "content": "<p>that's really good to know! It seems like we'd want to do this for any significant \"serious SIMD kernel\" -- fusing the load is probably a measurable perf improvement in tight loops?</p>",
        "id": 261584206,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1637024229
    },
    {
        "content": "<p>the downside is compatibility iiuc -- AVX needs Haswell or up, right? (My Ivy Bridge workstation in my closet will want a fallback, as I think we should strive to support any amd64 chip in the limit, but it feels like a reasonable thing to optimize for the common case here and focus on better codegen for AVX-onward)</p>",
        "id": 261584355,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1637024345
    },
    {
        "content": "<p>Hm so does this mean we shoudl disable that patch and try to actually deny-list instructions that otherwise require 16-byte alignment? We presumably have enough fuzzing now that we can be somewhat confident if we let the fuzzers run for awhile</p>",
        "id": 261656614,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1637076129
    },
    {
        "content": "<p>under the presumption that most VEX things don't generate a fault for unaligned addresses</p>",
        "id": 261656678,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1637076157
    },
    {
        "content": "<p>in an ISLE world, I think we can just switch <code>RegMem</code> operands to <code>Reg</code> for instructions where it isn't safe to fuse the load</p>",
        "id": 261672761,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1637082196
    },
    {
        "content": "<p>for the instruction constructors (in <code>inst.isle</code>)</p>",
        "id": 261672783,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1637082210
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"253994\">@Alex Crichton</span> yeah, I think it makes sense to do this transition; it can be done piecemeal (we're free to mix VEX-encoded and old-style-SSE-encoded instructions in one instruction stream, and I don't think there's a perf penalty for that?)</p>",
        "id": 261674641,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1637083018
    },
    {
        "content": "<p>another cool thing about VEX encodings is that there are three-operand forms (op dest, src1, src2), which plays nicer with regalloc (both old -- no more move insertion -- and new -- fewer constraints)</p>",
        "id": 261674804,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1637083099
    },
    {
        "content": "<p>My knowledge of VEX encodings is a few years out of date, but last time I worked with them, we had performance drops which we theorized could related to how the SSE encodings don't zero out the high parts of the registers, leading to spurious pipeline dependencies and partial-register update delays.</p>",
        "id": 261675808,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637083559
    },
    {
        "content": "<p>ah, that's good to know; so it sounds like we'd want to go all-in (only VEX encodings touching xmm/ymm regs)</p>",
        "id": 261676280,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1637083736
    },
    {
        "content": "<p>Yeah. It looks like Intel docs still have the recommendatations about using <code>vzeroupper</code> between vex instructions and sse instructions. So best not to intermix them.</p>",
        "id": 261678486,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637084673
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254083\">@Dan Gohman</span> you probably mean EVEX?</p>",
        "id": 261678538,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084699
    },
    {
        "content": "<p>oh, nm</p>",
        "id": 261678598,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084730
    },
    {
        "content": "<p>Oh, maybe. Intel's docs call it \"AVX code\". I don't have all the fine distinctions in my head paged in :-}</p>",
        "id": 261678610,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637084735
    },
    {
        "content": "<p>Source: 11.3.1 in <a href=\"https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf\">https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf</a></p>",
        "id": 261678753,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637084784
    },
    {
        "content": "<p>which edition?</p>",
        "id": 261678820,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084811
    },
    {
        "content": "<p>oh, sorry... linked</p>",
        "id": 261678847,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084821
    },
    {
        "content": "<p>ok, yeah, looks like something to look at some more</p>",
        "id": 261679015,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084888
    },
    {
        "content": "<p>and yeah, it is in fact talking about VEX when they say AVX there</p>",
        "id": 261679160,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637084953
    },
    {
        "content": "<p>looks like the link above is an old version of the doc, but the new version as of June 2021 still has the guidance</p>",
        "id": 261679185,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637084960
    },
    {
        "content": "<p><a href=\"https://cdrdv2.intel.com/v1/dl/getContent/671488?explicitVersion=true&amp;wapkw=intel%2064%20and%20ia-32%20architectures%20optimization%20reference%20manual\">https://cdrdv2.intel.com/v1/dl/getContent/671488?explicitVersion=true&amp;wapkw=intel%2064%20and%20ia-32%20architectures%20optimization%20reference%20manual</a></p>",
        "id": 261679395,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637085034
    },
    {
        "content": "<p>(for reference, it is section 15.3.1 in the newest edition)</p>",
        "id": 261679796,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637085190
    },
    {
        "content": "<p>it does talk about the use of 256-bit AVX instructions... not sure if the use of 128-bit AVX instructions has the same issue</p>",
        "id": 261679899,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637085233
    },
    {
        "content": "<p>It specifically talks about \"256-bit Intel AVX\", and I'm not 100% offhand whether that includes the re-encoded SSE instructions.</p>",
        "id": 261679910,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637085236
    },
    {
        "content": "<p>yeah</p>",
        "id": 261679922,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637085241
    },
    {
        "content": "<p>like with all of these guidance tidbits in the manual, I think I would want to benchmark things a bit on real systems</p>",
        "id": 261680044,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637085281
    },
    {
        "content": "<p>yeah :-)</p>",
        "id": 261680176,
        "sender_full_name": "Dan Gohman",
        "timestamp": 1637085330
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254110\">Andrew Brown</span> <a href=\"#narrow/stream/217117-cranelift/topic/x64.20SIMD.20alignment/near/261680044\">said</a>:</p>\n<blockquote>\n<p>like with all of these guidance tidbits in the manual, I think I would want to benchmark things a bit on real systems</p>\n</blockquote>\n<p>we should add more than just <code>blake3-simd</code> for SIMD things to sightglass :-p</p>",
        "id": 261680907,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1637085604
    },
    {
        "content": "<p>yup</p>",
        "id": 261686938,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1637088028
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254083\">Dan Gohman</span> <a href=\"#narrow/stream/217117-cranelift/topic/x64.20SIMD.20alignment/near/261675808\">said</a>:</p>\n<blockquote>\n<p>My knowledge of VEX encodings is a few years out of date, but last time I worked with them, we had performance drops which we theorized could related to how the SSE encodings don't zero out the high parts of the registers, leading to spurious pipeline dependencies and partial-register update delays.</p>\n</blockquote>\n<p>Certain VEX operations could be an issue on some older AVX512-enabled CPUs, when the AVX512 throttling was applied to 256-bit operations. This has been fixed in Ice Lake, though the story for older CPUs is still somewhat complicated: <a href=\"https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#Downclocking\">https://en.wikipedia.org/wiki/Advanced_Vector_Extensions#Downclocking</a></p>\n<p><span class=\"user-mention silent\" data-user-id=\"254110\">Andrew Brown</span> <a href=\"#narrow/stream/217117-cranelift/topic/x64.20SIMD.20alignment/near/261679899\">said</a>:</p>\n<blockquote>\n<p>it does talk about the use of 256-bit AVX instructions... not sure if the use of 128-bit AVX instructions has the same issue</p>\n</blockquote>\n<p>I don't think 128-bit instructions should be an issue in newer CPUs and some/most of the older ones, especially the ones without AVX512. Throttling is based on whether the upper portions of the registers are set (\"soft\" trigger mentioned in the link above).</p>",
        "id": 266847387,
        "sender_full_name": "Petr Penzin",
        "timestamp": 1641321933
    }
]