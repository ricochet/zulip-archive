[
    {
        "content": "<p>Similar to <a class=\"stream-topic\" data-stream-id=\"217117\" href=\"/#narrow/stream/217117-cranelift/topic/Chaos.20mode.20bachelor.20thesis\">#cranelift &gt; Chaos mode bachelor thesis</a>, I am currently thinking about writing a bachelor thesis utilizing Cranelift and its JIT capabilities. Now unlike the mentioned topic, I am not interested in extending or participating to Cranelift directly but rather determining its real life usefulness in a new context. Emulators after a certain generation of consoles utilize JITs heavily and I haven't yet seen anyone else use CLIR for this.</p>\n<p>I think it could be a good fit because of the much smaller compilation times and the optimisations do not matter <em>that</em> much as we mostly translate machine instructions pretty directly. Now, I am still not quite sure what exactly would be in scope for a bachelor thesis. While writing a full emulator (GBA, NDS and later) is possible, the question remains with the academic value -- Interpreter vs JIT is already well established. Comparisons with LLVM IR have already been done and its known that LLVM compile times make it unfit for emulation so that topic does not really work either.</p>\n<p>So if anyone has any ideas, I'd be grateful to hear them.</p>",
        "id": 388609300,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693607957
    },
    {
        "content": "<p>gotta run right now, but you might get a kick out of this: <a href=\"https://old.reddit.com/r/rust/comments/xe3bx1/minecraft_running_on_a_redstone_cpugpu/iog1o2t/?context=99999\">https://old.reddit.com/r/rust/comments/xe3bx1/minecraft_running_on_a_redstone_cpugpu/iog1o2t/?context=99999</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://old.reddit.com/r/rust/comments/xe3bx1/minecraft_running_on_a_redstone_cpugpu/iog1o2t/?context=99999\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/2e497402c3e20ecae28c7b033b8b44fd95a1f86f\\/68747470733a2f2f692e7974696d672e636f6d2f76692f2d42503744684854552d492f687164656661756c742e6a7067)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://old.reddit.com/r/rust/comments/xe3bx1/minecraft_running_on_a_redstone_cpugpu/iog1o2t/?context=99999\" title=\"Minecraft running on a redstone CPU/GPU implemented in Minecraft, running on a custom Minecraft server (written in Rust) capable of performing redstone calculations 10,000x faster than vanilla Minecraft\">Minecraft running on a redstone CPU/GPU implemented in Minecraft, running on a custom Minecraft server (written in Rust) capable of performing redstone calculations 10,000x faster than vanilla Minecraft</a></div><div class=\"message_embed_description\">Posted in r/rust by u/kibwen â€¢ 1,356 points and 68 comments</div></div></div>",
        "id": 388610028,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1693608366
    },
    {
        "content": "<p>It is definitely an interesting question in my mind (for an undergrad thesis) to explore compilation-time tradeoffs -- most of the JIT-based emulators I'm aware of (qemu, Valgrind) do fairly straightforward \"baseline-level\" compilation (not much optimization)</p>",
        "id": 388613027,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693610239
    },
    {
        "content": "<p>in order to get benefit from Cranelift's optimization you'd probably want a function-scope compiler, not a trace-based or basic-block-based JIT; that's sort of an interesting challenge when translating from machine code (look up \"control flow recovery\"; at least, for variable-length ISAs like x86)</p>",
        "id": 388613126,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693610298
    },
    {
        "content": "<p>the relevant questions include: what would you be trying to optimize (i.e. why do you think that applying a more strongly optimizing compiler would help) -- given that the input is machine code, is it that the original machine code is not optimized, or the translation introduces overheads, or ...</p>",
        "id": 388613229,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693610392
    },
    {
        "content": "<p>and then also the impedance mismatches that invariably arise -- different CPUs have slightly different status flags, ways of handling floating-point corner cases, etc -- and how to optimize them</p>",
        "id": 388613307,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693610419
    },
    {
        "content": "<p>Cranelift does give you a \"mid-end\" in which you can do rewrites, and it's not too hard to extend it with new opcodes/instructions, so it might be a good substrate for exploration of the semantic-mismatch questions in particular</p>",
        "id": 388613363,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693610462
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/JIT.20and.20emulation.20as.20a.20thesis.20topic/near/388613027\">said</a>:</p>\n<blockquote>\n<p>It is definitely an interesting question in my mind (for an undergrad thesis) to explore compilation-time tradeoffs -- most of the JIT-based emulators I'm aware of (qemu, Valgrind) do fairly straightforward \"baseline-level\" compilation (not much optimization)</p>\n</blockquote>\n<p>I am not really thinking of qemu or Valgrind necessarily, that's more virtualization. I mean more so bigger console emulators like yuzu, citra or similar that often utilize ARM to x86 Jitting. They are also relatively basic but often include their own IR and do minor optimisations on the block level. Usually basic blocks until they hit indirect branches.</p>",
        "id": 388613576,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693610594
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/JIT.20and.20emulation.20as.20a.20thesis.20topic/near/388613229\">said</a>:</p>\n<blockquote>\n<p>the relevant questions include: what would you be trying to optimize (i.e. why do you think that applying a more strongly optimizing compiler would help) -- given that the input is machine code, is it that the original machine code is not optimized, or the translation introduces overheads, or ...</p>\n</blockquote>\n<p>I would have to research a bit more but while the translation is relatively straightforward, some stuff is still possible. Though I can't remember rn, I will report back on that in a bit.</p>",
        "id": 388613754,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693610707
    },
    {
        "content": "<p><a href=\"https://github.com/merryhime/dynarmic\">https://github.com/merryhime/dynarmic</a> is the one I am thinking of that uses its own IR</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/merryhime/dynarmic\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/34fc927ba4de69c04dd1fbbca8bdec4fbd75b1c9\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f666337333830383963373663303836613466373732656434303262393236383939373137383662346166656237653739393863343835643531373136353733382f6d6572727968696d652f64796e61726d6963)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/merryhime/dynarmic\" title=\"GitHub - merryhime/dynarmic: An ARM dynamic recompiler.\">GitHub - merryhime/dynarmic: An ARM dynamic recompiler.</a></div><div class=\"message_embed_description\">An ARM dynamic recompiler. Contribute to merryhime/dynarmic development by creating an account on GitHub.</div></div></div>",
        "id": 388613799,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693610739
    },
    {
        "content": "<p>Cool, looking forward to hearing more! FWIW, in case you haven't hit on it yet -- a lot of prior work in this vein goes under the name \"dynamic binary translation\"; one of the original systems was Dynamo at HP in the 90s, which lives on as DynamoRIO (I think they did Alpha-to-Alpha dynamic recompilation with opts); qemu and Valgrind are absolutely relevant, in that they both do trace-based JIT'ing as well and you can learn a lot from the way they handle machine flags, how they organize and look up JIT'd code fragments, etc.</p>",
        "id": 388614304,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1693611062
    },
    {
        "content": "<p>I've heard that term before actually but nice to know the context and origin of it!</p>",
        "id": 388616075,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693612072
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"646077\">Kevin K.</span> <a href=\"#narrow/stream/217117-cranelift/topic/JIT.20and.20emulation.20as.20a.20thesis.20topic/near/388613754\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/JIT.20and.20emulation.20as.20a.20thesis.20topic/near/388613229\">said</a>:</p>\n<blockquote>\n<p>the relevant questions include: what would you be trying to optimize (i.e. why do you think that applying a more strongly optimizing compiler would help) -- given that the input is machine code, is it that the original machine code is not optimized, or the translation introduces overheads, or ...</p>\n</blockquote>\n<p>I would have to research a bit more but while the translation is relatively straightforward, some stuff is still possible. Though I can't remember rn, I will report back on that in a bit.</p>\n</blockquote>\n<p>Oh and I think I misread this message the first time, those are potential question to be asked and answered during research and comparisons and your suggestions. But yea, that is kind of my point -- finding those questions that have enough academic value and scope. A more strongly optimizing compiler, for example, can be overkill for many reasons. As you said, the input is already machine code and translation with strong optimizers will take longer and introduce stuttering. Optimizations like DCE and constant propagation are quite common compared to whatever LLVM has deep in its repertoire.</p>",
        "id": 388616478,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693612266
    },
    {
        "content": "<p>In any case, I would like to stick with a basic-block-based JIT for now, since that is much less complex and I don't think I'd be able to fit the other approaches into the time scope of a thesis. Most emulators that I know rely mostly on that aswell.</p>",
        "id": 388617772,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693612955
    },
    {
        "content": "<p>I am still partial to comparing LLVM IR and CLIR with respect to <a href=\"https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/compare-llvm.md\">https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/compare-llvm.md</a> and seeing how well those differences translate in emulation</p>",
        "id": 389047855,
        "sender_full_name": "Kevin K.",
        "timestamp": 1693860068
    },
    {
        "content": "<p>As someone who's work on binary translation for ~10 years, I find that compiler IRs like LLVM or Cranelift are not really suitable for implementing emulators. The main issue is that these IRs are designed for compiling things that look like C functions: you have a stack and the ability to call nested functions on that stack, function calls use standard calling conventions, etc.</p>\n<p>The current compiler that I am working on for a binary translator has specific features directly as opcodes in the IR, which allows them to be optimized by passes. For example:</p>\n<ul>\n<li>\"Functions\" don't exist at this level. Translated code blocks effectively always tail call to the next translated block.</li>\n<li>Support for multiple entry points, which is needed if you are doing call/return optimizations: a return target in the original code is represented as a secondary entry point in the translated code block. You can't treat it like a normal call because you don't have a stack on which to keep data across calls.</li>\n<li>A custom calling convention is used to improve performance. Almost all registers carry a significant value when transferring control between translated code blocks.</li>\n<li>All loads and stores can fault, which requires generating metadata for use by the trap handler to recover the original register state. This register state is passed to the original trap handler which expects to see a native register state.</li>\n<li>Loads from memory regions that are known to be read-only can be optimized to constants.</li>\n<li>Condition flag emulation is extremely performance-sensitive, so you need optimizations that convert \"evaluate some condition\" to a native compare&amp;branch operation.</li>\n<li>Control transfers between blocks require doing a runtime lookup to find the translated code block for a given source address. This can be optimized if the source address is known to be a constant, which avoids the runtime hash table lookup.</li>\n</ul>\n<p>It's probably possible to modify Cranelift to support these, but I decide to write my compiler entirely from scratch. It was heavily inspired by the design of Cranelift though, and in fact also uses regalloc2 for register allocation.</p>",
        "id": 389064465,
        "sender_full_name": "Amanieu",
        "timestamp": 1693869048
    }
]