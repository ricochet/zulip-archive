[
    {
        "content": "<p>Follow-up question to the conversation about Sightglass in the Cranelift meeting today: how long does it take to run the benchmarks, and what are the hardware requirements, apart from performance counters? <span class=\"user-mention\" data-user-id=\"254006\">@Andy Wortman</span> <span class=\"user-mention\" data-user-id=\"257554\">@Johnnie Birch</span>, can you give input on this?</p>",
        "id": 202338325,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1593449742
    },
    {
        "content": "<p>Asking because I'm wondering if we could run these as part of the normal CI, given that we want to measure instruction counts, not wall clock time, and thus don't need to worry about noise.</p>",
        "id": 202338461,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1593449798
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"234973\">@Till Schneidereit</span>  I believe just a few minutes ... 5 minutes to run the tests. What ran was the test and a baseline using native. Note however,  I know I made some updates that allowed you to download and rebuild a new version of wasmtime each experiment and all of that adds to the time. I will take a look later this afternoon to see the state and attempt to run.</p>",
        "id": 202343523,
        "sender_full_name": "Johnnie Birch",
        "timestamp": 1593452020
    },
    {
        "content": "<p>yeah running just now on my laptop there was about a minute for release builds of the benchmark programs, another two or so for the benchmarks to run. another minute or two on top for a fresh release build of wasmtime sounds about right?</p>",
        "id": 202347281,
        "sender_full_name": "iximeow",
        "timestamp": 1593453943
    },
    {
        "content": "<p>Ok, that sounds like stuff we could easily do in CI. In particular since we already have the builds. What we don't have are perf counters in GitHub Actions, so either we'd need to run this somewhere else, or change the setup accordingly. <span class=\"user-mention\" data-user-id=\"268444\">@Julian Seward</span> IIUC you suggested we should change how we measure things anyway?</p>",
        "id": 202357186,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1593458927
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"234973\">@Till Schneidereit</span> what I proposed to measure was: for compiler run time, just the instruction count.  For the generated code, the instruction count, the data read count and the data write count.  Measuring wallclock time is so noisy in practice as to be useless.  Measuring cache misses etc is also pointless because these depend on the processor implementation (cache sizes, prefetch strategies, other stuff running at the same time) and so will tell us nothing useful.</p>",
        "id": 202410178,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593507581
    },
    {
        "content": "<p>For the generated code I've suggested including the data read/write counts because those relate directly to decisions the register allocator makes (spilling) and so any regressions in that area should be obvious from those numbers.</p>",
        "id": 202410313,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593507653
    },
    {
        "content": "<p>Wouldn't measuring <em>only</em> instruction count hide the pipelining and other architectural effects of CPUs, though? And if so, would measure both values yield better trends?</p>",
        "id": 202412377,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1593509110
    },
    {
        "content": "<p>(umm) when you say \"both\", what is the second value that you mention?</p>",
        "id": 202413259,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593509667
    },
    {
        "content": "<p>Time, in addition to instruction count.</p>",
        "id": 202413822,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1593510038
    },
    {
        "content": "<p>Ah, ok.  Well, we could measure time too; but my experience with doing that has mostly been bad.  Eg, for the 1%-sized icount changes that we were dealing with during the RA tuning phase, we could not have done that work if we'd used only run times.</p>",
        "id": 202414111,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593510223
    },
    {
        "content": "<p><a href=\"http://perf.rust-lang.org\">perf.rust-lang.org</a> allows people to select a number of different data sets: <code>cpu-clock</code>,<code>cycles:u</code>,<code>faults</code>,<code>instructions:u</code>,<code>max-rss</code>,<code>task-clock</code>,<code>wall-time</code>. It'd be good to learn more about what people find most useful of those</p>",
        "id": 202415009,
        "sender_full_name": "Till Schneidereit",
        "timestamp": 1593510804
    },
    {
        "content": "<p>In my experience.even with a dedicated setup like rust's wall clock time is almost always not useful</p>",
        "id": 202435529,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593524103
    },
    {
        "content": "<p>It's only useful when adding parallelism to show that increased instructions have decreased wall time</p>",
        "id": 202435588,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593524125
    },
    {
        "content": "<p>It's.worth collecting because it's easy but its rarely the main statistic when measuring changes</p>",
        "id": 202435658,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593524158
    },
    {
        "content": "<p>But it's also important to recognize that instruction counting just may be a proxy for time, it isn't always. In practice though I think it's been really consistent with rust</p>",
        "id": 202435785,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593524199
    },
    {
        "content": "<p>as an additional data point, i've also seen inconsistencies between instruction count and wallclock time with <a href=\"http://regalloc.rs\">regalloc.rs</a> (e.g. on two runs, one has lower icount but higher wallclock, in a consistent manner), so having both gives a slightly better idea of what's going on.</p>",
        "id": 202436206,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1593524369
    },
    {
        "content": "<p>(would surely be nice to note the total number of calls to malloc, if that's not too hard to get from e.g. callgrind)</p>",
        "id": 202436288,
        "sender_full_name": "Benjamin Bouvier",
        "timestamp": 1593524403
    },
    {
        "content": "<p>I can believe that (about icounts vs wallclock times).</p>",
        "id": 202436576,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593524524
    },
    {
        "content": "<p>One thing we could also maybe collect is cache misses; maybe those can partly account for situations where the insn count goes down but the wallclock time goes up.</p>",
        "id": 202436728,
        "sender_full_name": "Julian Seward",
        "timestamp": 1593524588
    },
    {
        "content": "<p>One thing I'd recommend is to collect everything that's reasonable for profiling-over-time</p>",
        "id": 202440333,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593526163
    },
    {
        "content": "<p>it's rare that one metric fits all situations/improvements/regressions</p>",
        "id": 202440341,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593526171
    },
    {
        "content": "<p>but having multiple allows you to correlate various things if necessary</p>",
        "id": 202440359,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1593526181
    },
    {
        "content": "<p>FWIW, sometimes the instruction count does not change even if runtime increases by 100%: <a href=\"https://bugzilla.mozilla.org/show_bug.cgi?id=1649109\">https://bugzilla.mozilla.org/show_bug.cgi?id=1649109</a>.  That bug is about a Spectre mitigation but it could have been about a change in code generation strategy that was thought to be innocuous b/c branch prediction would paper over it.  Insn count is a good starting point for  assessing the quality of the compiler's output (and has the virtue of having a stable meaning over time and being independent of the microarchitecture) but microarchitectural effects means insn count alone can be highly misleading in at least some cases.</p>",
        "id": 202665472,
        "sender_full_name": "Lars Hansen",
        "timestamp": 1593681220
    }
]