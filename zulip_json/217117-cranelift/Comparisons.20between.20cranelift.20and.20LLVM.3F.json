[
    {
        "content": "<p>Has there been any benchmarking of cranelift against LLVM recently? I know maintainers are reluctant to make these kinds of comparisons, and that it's easy to compare apples against oranges, etc; but at the same time, short build times are an explicit goal of the project and build time improvements are often mentioned in progress reports, so it makes sense to wonder how they stack up against the state of the art.</p>\n<p>The only data I can find is the often-cited <a href=\"https://github.com/rust-lang/rust/pull/77975\">20-30% figure from bjorn3</a> from 2020 (no associated benchmarks) and <a href=\"https://arxiv.org/abs/2011.13127\">this arxiv paper</a> from 2021 mentioned on the Cranelift readme.</p>\n<p>Are there any more recent benchmarks to be found?</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/rust-lang/rust/pull/77975\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/41d50cb413844c720f2e814640c6643f8a60d243\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f353431346165396138336135353237343230623539616565306437373434303430313332303135336431303836303236636363313338663066613639623636622f727573742d6c616e672f727573742f70756c6c2f3737393735)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/rust-lang/rust/pull/77975\" title=\"Add cg_clif as optional codegen backend by bjorn3 · Pull Request #77975 · rust-lang/rust\">Add cg_clif as optional codegen backend by bjorn3 · Pull Request #77975 · rust-lang/rust</a></div><div class=\"message_embed_description\">Rustc_codegen_cranelift is an alternative codegen backend for rustc based on Cranelift. It has the potential to improve compilation times in debug mode. In my experience the compile time improvemen...</div></div></div>",
        "id": 303241105,
        "sender_full_name": "Olivier FAURE",
        "timestamp": 1665401096
    },
    {
        "content": "<p>Compiling <a href=\"https://github.com/ebobby/simple-raytracer/\">https://github.com/ebobby/simple-raytracer/</a> from scratch in debug mode is what I used as benchmark for that ~20-30% figure. This covers the full compilation. The time spent in the codegen backend is about half of that.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/ebobby/simple-raytracer/\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/ccbf1aec7a36372e895329f453b21f820b730f32\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f363237633334323762303965316461366261653336316431663236623138303138376532313763346661323839333263656438326635306338323331313130642f65626f6262792f73696d706c652d726179747261636572)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/ebobby/simple-raytracer/\" title=\"GitHub - ebobby/simple-raytracer: Simple ray tracing project in Rust to learn both Rust and the algorithms and math for raytracing.\">GitHub - ebobby/simple-raytracer: Simple ray tracing project in Rust to learn both Rust and the algorithms and math for raytracing.</a></div><div class=\"message_embed_description\">Simple ray tracing project in Rust to learn both Rust and the algorithms and math for raytracing. - GitHub - ebobby/simple-raytracer: Simple ray tracing project in Rust to learn both Rust and the a...</div></div></div>",
        "id": 303250656,
        "sender_full_name": "bjorn3",
        "timestamp": 1665404843
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"354194\">@Olivier FAURE</span> most of my work in this area has been driven by comparisons against SpiderMonkey, rather than LLVM. We're faster than LLVM (sometimes by a lot) so it's somewhat less interesting -- \"hey great, we won!\" -- whereas SM is currently 2-3x faster at compiling the same Wasm module as Wasmtime-with-Cranelift, so there's a lot to learn</p>",
        "id": 303287538,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665418077
    },
    {
        "content": "<p>(faster build time, to be clear, not code quality)</p>",
        "id": 303287632,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665418100
    },
    {
        "content": "<p>there are active efforts to dig further into this and drive improvements based on it</p>",
        "id": 303287675,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665418118
    },
    {
        "content": "<blockquote>\n<p>We're faster than LLVM (sometimes by a lot) so it's somewhat less interesting</p>\n</blockquote>\n<p>Faster for code of equivalent quality? I'm not sure how much that's been measured.</p>\n<p>I think it's still interesting for cg_clif adoption. If people know that Cranelift is X% faster than LLVM  for equivalent code, there'll be more enthusiasm for the project.</p>\n<blockquote>\n<p>most of my work in this area has been driven by comparisons against SpiderMonkey</p>\n</blockquote>\n<p>Are there Cranelift vs SpiderMonkey (vs V8 vs LLVM) benchmarks?</p>",
        "id": 303402578,
        "sender_full_name": "Olivier FAURE",
        "timestamp": 1665486050
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"354194\">Olivier FAURE</span> <a href=\"#narrow/stream/217117-cranelift/topic/Comparisons.20between.20cranelift.20and.20LLVM.3F/near/303402578\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>We're faster than LLVM (sometimes by a lot) so it's somewhat less interesting</p>\n</blockquote>\n<p>Faster for code of equivalent quality? I'm not sure how much that's been measured.</p>\n</blockquote>\n<p>No, definitely not, that's a much stronger claim than what I had said :-)</p>\n<p>I don't think it's very realistic to expect LLVM-quality code out of a JIT-speed compiler; it's worth aiming for, and getting as close as we can, but we'll never hit that threshold in all likelihood. And given that we can't generate LLVM-quality code today, we can't measure that datapoint.</p>\n<blockquote>\n<p>I think it's still interesting for cg_clif adoption. If people know that Cranelift is X% faster than LLVM  for equivalent code, there'll be more enthusiasm for the project.</p>\n</blockquote>\n<p>I do agree it would be fantastic if it existed, but again, it's not a very realistic expectation, IMHO. We can possibly push the \"code goodness per unit of compile time\" efficiency metric further, through smart algorithms; but LLVM has engineer-decades of optimization work poured into it, and there is no shortcut to getting all of the edge cases and isel details and niche optimizations right.</p>\n<blockquote>\n<p>Are there Cranelift vs SpiderMonkey (vs V8 vs LLVM) benchmarks?</p>\n</blockquote>\n<p>There's the paper cited in cranelift/README.md. I'm not aware of anyone running continuous/up-to-date benchmarks, but it's not so hard to do oneself (write a JS wrapper that loads a Wasm module and run it in the SpiderMonkey shell, vs. <code>wasmtime compile</code>).</p>",
        "id": 303487363,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665509966
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"354194\">@Olivier FAURE</span>, I've done some of those comparisons over in <a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a>. It currently only measures Wasmtime in <code>main</code> but you may be interested in a PR I submitted to also measure V8: <a href=\"https://github.com/bytecodealliance/sightglass/pull/166\">https://github.com/bytecodealliance/sightglass/pull/166</a>. Though unfinished, that is most of the way there to get some numbers. <span class=\"user-mention\" data-user-id=\"253991\">@Yury Delendik</span> also has a similar SpiderMonkey patch but that has not been submitted as a PR yet.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/8bcb5236a57cee0a0cc86ae5e3575e195f9aa885\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f613535326433373436363334376566616437616666383732626264346166646564366634646634363834626334643937373939616531663766356162393864372f62797465636f6465616c6c69616e63652f7369676874676c617373)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass\" title=\"GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.\">GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of th...</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass/pull/166\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/79577bfbc6ed7ae52e4934e2ab444ce35cfd4e49\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f386361393539653430653761333963663566353237333439373130356362313336663534646263393938326666663031363639303931353066393831346335612f62797465636f6465616c6c69616e63652f7369676874676c6173732f70756c6c2f313636)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass/pull/166\" title=\"Add a V8 engine by abrown · Pull Request #166 · bytecodealliance/sightglass\">Add a V8 engine by abrown · Pull Request #166 · bytecodealliance/sightglass</a></div><div class=\"message_embed_description\">This change adds the beginnings of a new V8 engine to Sightglass. It uses V8's libwee8 library as the backing engine and constructs a libengine.so in C++ that is compatible with Sightglass. As-is, ...</div></div></div>",
        "id": 303536317,
        "sender_full_name": "Andrew Brown",
        "timestamp": 1665530844
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/Comparisons.20between.20cranelift.20and.20LLVM.3F/near/303487363\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"354194\">Olivier FAURE</span> <a href=\"#narrow/stream/217117-cranelift/topic/Comparisons.20between.20cranelift.20and.20LLVM.3F/near/303402578\">said</a>:</p>\n<blockquote>\n<p>Faster for code of equivalent quality? I'm not sure how much that's been measured.</p>\n</blockquote>\n<p>No, definitely not, that's a much stronger claim than what I had said :-)</p>\n</blockquote>\n<p>As an example, there is report on using <a href=\"https://github.com/bytecodealliance/wasmtime/issues/4686\">LEA instruction for arithmetic on x86</a>. I am curious what would be the best way to measure effects of change that would implement this suggestion today? Does sightglass have universal benchmarks that would cover this? And how much would <code>wasmtime-bench-api</code> affect the results:</p>\n<blockquote>\n<p>The <code>wasmtime-bench-api</code> intentionally does things that will likely hurt its absolute performance numbers but which help us more easily get statistically meaningful results, like randomizing the locations of heap allocations.</p>\n</blockquote>\n<p>(taken from <a href=\"https://github.com/bytecodealliance/sightglass#this-is-not-a-general-purpose-webassembly-benchmark-suite\">This is NOT a General-Purpose WebAssembly Benchmark Suite</a> section in sightglass' README)</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/4686\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/120954f678359be0a30703eab7c2a54245fe8419\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f386431303465383638623934326531366236623335623630363636316237623436326530633736383838643332303161613839373534353263653235333865662f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f34363836)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/4686\" title=\"[cranelift] Avoid 64-bit imul_imm if possible on all architectures · Issue #4686 · bytecodealliance/wasmtime\">[cranelift] Avoid 64-bit imul_imm if possible on all architectures · Issue #4686 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Feature Not all architectures has a fast 64-bit imul + imm. But even on modern like SnB-family and AMD Ryzen it takes 3 cycle latency, 1c throughput which not always faster lea + shl / add combinat...</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass#this-is-not-a-general-purpose-webassembly-benchmark-suite\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/8bcb5236a57cee0a0cc86ae5e3575e195f9aa885\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f613535326433373436363334376566616437616666383732626264346166646564366634646634363834626334643937373939616531663766356162393864372f62797465636f6465616c6c69616e63652f7369676874676c617373)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass#this-is-not-a-general-purpose-webassembly-benchmark-suite\" title=\"GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.\">GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of th...</div></div></div>",
        "id": 303545586,
        "sender_full_name": "Petr Penzin",
        "timestamp": 1665537363
    },
    {
        "content": "<p>Re: how to measure -- Sightglass benchmarks are a good start, yeah. The main thing that we've found Sightglass to do that perturbs results in undesirable ways is its randomized allocator; you can build bench-api without that (turn off the Cargo feature; I forget the exact incantation offhand). One has to be pretty careful with variance otherwise -- we've found that limiting to one thread, pinning to a single core, and doing all the other usual system-quieting things for benchmarking (disable frequency scaling and hyperthreading, etc) is necessary to get good results. Sightglass will otherwise happily tell you \"no statistically significant difference\" when there is a small swing but it's buried in noise.</p>",
        "id": 303546205,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665537876
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/Comparisons.20between.20cranelift.20and.20LLVM.3F/near/303487363\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"354194\">Olivier FAURE</span> <a href=\"#narrow/stream/217117-cranelift/topic/Comparisons.20between.20cranelift.20and.20LLVM.3F/near/303402578\">said</a>:</p>\n<blockquote>\n<p>Faster for code of equivalent quality? I'm not sure how much that's been measured.</p>\n</blockquote>\n<p>No, definitely not, that's a much stronger claim than what I had said :-)</p>\n</blockquote>\n<p>I feel like we're talking past each other a bit.</p>\n<p>To be clear, I'm not asking whether Cranelift can beat LLVM at <code>-O1</code> or <code>-O2</code> (though I'm not sure why you're being so pessimistic; when LLVM came out, GCC was the compiler with a decade of history behind it, and it only took them 10 years to catch up). But I do wonder if Cranelift can generate better code than LLVM at <code>-O0</code>? Because if it can't, then yeah, there's not much of a point of comparing between Cranelift and LLVM.</p>\n<p>I mean, ultimately the hope is for a Rust backend that produces roughly usable binaries much faster than LLVM. I don't know if \"roughly usable\" necessarily means \"on par with LLVM -O0\" or if you can go even lower though.</p>",
        "id": 303587075,
        "sender_full_name": "Olivier FAURE",
        "timestamp": 1665565701
    },
    {
        "content": "<p>No one has done any sort of in-depth comparison with LLVM at <code>-O0</code> AFAIK. Closest would probably be whatever benchmarking <span class=\"user-mention\" data-user-id=\"264278\">@bjorn3</span> has done with <code>cg_clif</code> mentioned upthread, but I don't know the details of that and whether that was comparing against LLVM <code>-O0</code> or what. I think that, unfortunately, the answers to your questions mostly don't exist because no one has done the work to design the experiment and gather the data.</p>",
        "id": 303619596,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1665578748
    },
    {
        "content": "<p>Yeah, that was comparing against rustc with LLVM -O0.</p>",
        "id": 303619819,
        "sender_full_name": "bjorn3",
        "timestamp": 1665578830
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"354194\">@Olivier FAURE</span> thanks, that makes much more sense; wasn't clear to me that you had meant \"unoptimizing LLVM\"! This is indeed an interesting data point; actually I'd be curious about both optimizing Cranelift vs unoptimizing LLVM (probably reasonably improved code, and maybe comparable compile time?) and unoptimizing Cranelift vs unoptimizing LLVM (cg_clif comparisons are this one)</p>",
        "id": 303670581,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1665590459
    },
    {
        "content": "<p>I do think that there's quite a lot of \"cheap\" optimizations that can be done and keep it fast enough for jjt purposes</p>",
        "id": 303693484,
        "sender_full_name": "Carlo Kok",
        "timestamp": 1665597928
    }
]