[
    {
        "content": "<p>I posted on the Libre-SOC mailing list a plan to apply for a Rust Foundation grant once those are open again to add a PowerISA backend to Cranelift:<br>\n<a href=\"https://lists.libre-soc.org/pipermail/libre-soc-dev/2023-February/005502.html\">https://lists.libre-soc.org/pipermail/libre-soc-dev/2023-February/005502.html</a><br>\nthere was also some discussion on IRC:<br>\n<a href=\"https://libre-soc.org/irclog/%23libre-soc.2023-02-19.log.html#t2023-02-19T18:56:10\">https://libre-soc.org/irclog/%23libre-soc.2023-02-19.log.html#t2023-02-19T18:56:10</a></p>",
        "id": 329062710,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676925128
    },
    {
        "content": "<p>also posted on rust's project-portable-simd:<br>\n<a href=\"https://rust-lang.zulipchat.com/#narrow/stream/257879-project-portable-simd/topic/plan.20for.20experimental.20SVP64.20support.20through.20cranelift/near/329064779\">https://rust-lang.zulipchat.com/#narrow/stream/257879-project-portable-simd/topic/plan.20for.20experimental.20SVP64.20support.20through.20cranelift/near/329064779</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://rust-lang.zulipchat.com/#narrow/stream/257879-project-portable-simd/topic/plan.20for.20experimental.20SVP64.20support.20through.20cranelift/near/329064779\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/b470a6a9a9c7305c1cb5dfd01f6a6cac651c1674\\/68747470733a2f2f7a756c69702d617661746172732e73332e616d617a6f6e6177732e636f6d2f343731352f7265616c6d2f69636f6e2e706e673f76657273696f6e3d32)\"></a><div class=\"data-container\"><div class=\"message_embed_description\">If this message does not go away, try reloading the page.</div></div></div>",
        "id": 329064938,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676926236
    },
    {
        "content": "<p>You might want to take a look at <a href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/cranelift-dynamic-vector.md\">https://github.com/bytecodealliance/rfcs/blob/main/accepted/cranelift-dynamic-vector.md</a> The cranelift ir half has been implemented afaik, but the actual backend support for AArch64 SVE didn't get implemented despite being planned.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/cranelift-dynamic-vector.md\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/e18ee5b28bcafcdffe0895aabda2e535b9f3f38f\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f373435653430306266376132313236353262623262623338663636656539323938653864333366396263393832613966653333663430663538366161316161382f62797465636f6465616c6c69616e63652f72666373)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/rfcs/blob/main/accepted/cranelift-dynamic-vector.md\" title=\"rfcs/cranelift-dynamic-vector.md at main · bytecodealliance/rfcs\">rfcs/cranelift-dynamic-vector.md at main · bytecodealliance/rfcs</a></div><div class=\"message_embed_description\">RFC process for Bytecode Alliance projects. Contribute to bytecodealliance/rfcs development by creating an account on GitHub.</div></div></div>",
        "id": 329065380,
        "sender_full_name": "bjorn3",
        "timestamp": 1676926447
    },
    {
        "content": "<p>Cranelift indeed doesn't have autovectorization.</p>",
        "id": 329065516,
        "sender_full_name": "bjorn3",
        "timestamp": 1676926534
    },
    {
        "content": "<p>For cg_clif specifically be aware that all simd intrinsics are currently implemented entirely using scalar operations.</p>",
        "id": 329065738,
        "sender_full_name": "bjorn3",
        "timestamp": 1676926615
    },
    {
        "content": "<p>Dynamic vectors in Cranelift support arbitrary sizes, but static vectors only support power-of-two sizes.</p>",
        "id": 329065982,
        "sender_full_name": "bjorn3",
        "timestamp": 1676926705
    },
    {
        "content": "<p>I'm happy to assist with adding PowerISA support on the cg_clif side, but I think proper SIMD support would be a lot more work that isn't a priority for me right now. I think I will need to redo how vector types are represented in cg_clif for example as it is rather fragile in terms of correctness.</p>",
        "id": 329066684,
        "sender_full_name": "bjorn3",
        "timestamp": 1676926995
    },
    {
        "content": "<p>ok, well SVP64 doesn't fit that well into dynamic vectors: in SVP64 all vectors are kinda like ArrayVec in that the user selects the capacity which is a compile-time constant <code>1..=64</code> elements (not limited to powers of 2, future ISA versions may expand that) and then at runtime the length can be dynamically set per-instruction to <code>0..=capacity</code>by writing to the VL register. there are also some more complex modes where each element is a fixed-width vector of <code>1..=4</code> elements (we call that sub-vectors).</p>\n<p>for llvm, my plan is to use <code>llvm.vp.*</code> ops with fixed-length vectors for an ISA-independent representation -- imho cranelift needs its generic vector ops to become more like llvm's <code>llvm.vp.*</code>ops, since they're more general.</p>",
        "id": 329068431,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676927914
    },
    {
        "content": "<p>svp64 supports an even more general representation of vector ops as essentially auto-vectorized multi-instruction loops, of which the above ops are just the degenerate single-instruction case.</p>",
        "id": 329068710,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676928068
    },
    {
        "content": "<p>my plan is to support the simple <code>llvm.vp.*</code> case and leave the more complex stuff for when we get more funding</p>",
        "id": 329068917,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676928179
    },
    {
        "content": "<p>basic summary of <code>llvm.vp.*</code> ops:<br>\nall ops are of the form <code>%result = call &lt;result_ty&gt; @llvm.vp.the_op.arg_types(&lt;inputs...&gt;, &lt;mask&gt;, &lt;vl&gt;)</code> with:<br>\nresult and inputs types are fixed or dynamic length vectors (their length is effectively like <code>ArrayVec</code>'s capacity)<br>\nmask is a fixed or dynamic length vector with element type <code>i1</code><br>\nvl is an i32 (effectively <code>ArrayVec</code>'s length)<br>\nthe result elements are calculated using this algorithm:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">result</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">poison</span><span class=\"w\"> </span><span class=\"c1\">// skipped for store ops</span>\n<span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">el_idx</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">vl</span><span class=\"p\">.</span><span class=\"n\">min</span><span class=\"p\">(</span><span class=\"n\">capacity</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<span class=\"w\">    </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">mask</span><span class=\"p\">[</span><span class=\"n\">el_idx</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"p\">{</span>\n<span class=\"w\">        </span><span class=\"n\">result</span><span class=\"p\">[</span><span class=\"n\">el_idx</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">op</span><span class=\"p\">(</span><span class=\"n\">input0</span><span class=\"p\">[</span><span class=\"n\">el_idx</span><span class=\"p\">],</span><span class=\"w\"> </span><span class=\"n\">input1</span><span class=\"p\">[</span><span class=\"n\">el_idx</span><span class=\"p\">],</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.);</span>\n<span class=\"w\">    </span><span class=\"p\">}</span>\n<span class=\"p\">}</span>\n</code></pre></div>",
        "id": 329071164,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676929283
    },
    {
        "content": "<p>all inputs and mask must have matching lengths and fixed/dynamic-ness.</p>",
        "id": 329071370,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676929408
    },
    {
        "content": "<p>actually, the <code>llvm.vp.*</code> ops have UB if vl &gt; capacity, sorry for the mixup</p>",
        "id": 329071748,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676929626
    },
    {
        "content": "<p><a href=\"https://llvm.org/docs/LangRef.html#vector-predication-intrinsics\">https://llvm.org/docs/LangRef.html#vector-predication-intrinsics</a></p>",
        "id": 329071804,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676929664
    },
    {
        "content": "<p>Doesn't Cranelift's dynamic vector representatiom allow each dynamic vector to have a different length?</p>",
        "id": 329075813,
        "sender_full_name": "bjorn3",
        "timestamp": 1676932172
    },
    {
        "content": "<p>not quite, according to the rfc all dynamic vectors have length <code>n * global_scale_factor</code> where <code>n</code> is user selectable and specific to each vector and where <code>global_scale_factor</code> is a global constant, selected by the cpu the output program is running on, and not user-selectable.</p>",
        "id": 329084648,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676938517
    },
    {
        "content": "<p>so, e.g. if <code>global_scale_factor</code> is <code>2</code>, then you can't have a dynamic vector with length <code>5</code></p>",
        "id": 329084702,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676938563
    },
    {
        "content": "<p>a key difference between SVP64 and most other \"scalable vector\" ISAs is that the capacity of vectors (MAXVL) is selected by the cpu designer on RVV and SVE, but is selected by the programmer/compiler on SVP64. This means that e.g. if you want a vector length of 14 then on RVV and SVE you always need to write a loop handling the case where the cpu designer decided to limit vector lengths to 4, whereas on SVP64 if you want a vector length of 14 then you just allocate 14 consecutive registers (for 64-bit elements) and use them as a 14-element vector, all cpus implementing SVP64 support that, though they may run at different speeds, e.g. a cpu could process 4 elements at a time and take multiple clock cycles to process the 14-element vector, but you would still only use 1 instruction.</p>",
        "id": 329085978,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676939516
    },
    {
        "content": "<p>The syntax to define a dynamic vector type is <code>dt0 = i32x4*gv0</code>. I don't see any restriction that <code>gv0</code> has to be a fixed constant for the cpu it runs on. Just that it is a <code>GlobalValue</code> which may reference the cpu's vector size or may be a memory load (whose value may not change while the function is excuting, but may otherwise change at runtime). Shouldn't be too hard to add a constant value as additional option to <code>GlobalValue</code> either.</p>",
        "id": 329122007,
        "sender_full_name": "bjorn3",
        "timestamp": 1676965041
    },
    {
        "content": "<p>so in other words you're saying i should use a dynamic vector but say the scale factor is always 1 on SVP64, basically a fixed-length vector with weird syntax?</p>",
        "id": 329143644,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676972564
    },
    {
        "content": "<p>e.g. <code>i32x3*1</code>?</p>",
        "id": 329168875,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1676980023
    },
    {
        "content": "<p>I meant using <code>i32*gv0</code> where <code>gv0</code> represents the constant 3.</p>",
        "id": 329231450,
        "sender_full_name": "bjorn3",
        "timestamp": 1676996010
    },
    {
        "content": "<p>Looking at it again it is a bit roundabout. Now that <code>Type</code> has been changed from 8bit to 16bit in size, maybe non-power-of-two sizes for non-dynamic vector types could work?</p>",
        "id": 329231896,
        "sender_full_name": "bjorn3",
        "timestamp": 1676996109
    },
    {
        "content": "<p>The intent of the expression language was indeed to offer the flexibility for a vector length to be defined however the ISA + runtime needs it to be; the global scale factor was just one example. You can go back and read the discussion on the RFC for examples of this :-) I'm confident we can adapt the framework to whatever Power needs as well</p>",
        "id": 329238081,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1676997770
    },
    {
        "content": "<p>SVP64 will need 1024+512 vector types now and more in the future -- 64 different MAXVL settings (1..=64), 4 SUBVL settings (1..=4) and 6 different element types i8/u8, i16/u16, i32/u32, i64/u64, f32, f64 -- we also support bf16 and f16 but those can be added later. future versions of the SVP64 ISA extension are highly likely to support more MAXVL settings</p>",
        "id": 329279811,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1677009535
    },
    {
        "content": "<p>From a blurry memory, the existing CLIF types should be fine with the exception of non-power-of-two lanes, with support for up to 256 lanes. Unless something has changed significantly, I think the bigger concern will be handling fully predicated SIMD opcodes - that is a huge change to CLIF.</p>",
        "id": 329382342,
        "sender_full_name": "Sam Parker",
        "timestamp": 1677059988
    },
    {
        "content": "<p>Redicated simd ops can be handled by emitting an unpredicated op followed by a vselect and then fusing both together into a predicated simd inst in the backend, right?</p>",
        "id": 329413302,
        "sender_full_name": "bjorn3",
        "timestamp": 1677068627
    },
    {
        "content": "<p>Yep, that. seems like a reasonable solution; it has the advantage that it will capture both code generated in exactly that shape to take advantage of predication, and code that happens to be in that shape from a generic frontend</p>",
        "id": 329465632,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1677081628
    },
    {
        "content": "<p>(i.e., the usual argument about canonicalization: it increases optimization opportunity by funneling through one canonical form)</p>",
        "id": 329465958,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1677081685
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"264278\">bjorn3</span> <a href=\"#narrow/stream/217117-cranelift/topic/PowerISA.20backend.20plans/near/329413302\">said</a>:</p>\n<blockquote>\n<p>Redicated simd ops can be handled by emitting an unpredicated op followed by a vselect and then fusing both together into a predicated simd inst in the backend, right?</p>\n</blockquote>\n<p>that doesn't work for operations that would produce UB in masked-off lanes, e.g. division by zero or load through null pointer. SVP64 has general enough semantics for vectors (each vector op is basically a full multi-instruction loop with optional element reordering for dest register and each separate source register independently as well as masking and a bunch of other options -- this is general enough to support a full FFT in basically one instruction) that it's likely better to canonicalize into SVP64-style IR and lower from that for other backends that aren't quite as general.</p>\n<p>when there's a single instruction in a vector op (the common case), SVP64 is basically a prefix setting up looping over vector elements and a suffix that is basically any existing PowerISA scalar instruction that is converted by the prefix into a vector op while possibly changing the element size from 32/64-bits to any of 8/16/32/64-bits (for ints) or f16/bf16/f32/f64 (for floats)</p>\n<p><a href=\"https://libre-soc.org/openpower/sv/\">https://libre-soc.org/openpower/sv/</a></p>",
        "id": 329583361,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1677098875
    },
    {
        "content": "<p>Right, for masked loads and stores a separate instruction makes sense. For division you could technically add another select to set the divisor to 1 for masked lanes, but I don't really like that solution either.</p>",
        "id": 329677932,
        "sender_full_name": "bjorn3",
        "timestamp": 1677147737
    }
]