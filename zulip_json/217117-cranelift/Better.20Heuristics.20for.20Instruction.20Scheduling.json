[
    {
        "content": "<p>Hello! Me and a colleague of mine would like to tackle issue #6260, proposing a better approach for instruction scheduling using heuristics.</p>\n<p>First, it would be good to know if the proposal is still relevant, given almost a year has passed since it was first published. For example, is there current work that would invalidate this, or, are you aware of someone already trying to implement it?</p>\n<p>We should note that while we feel like we adequately understand the heuristics proposed in the paper, we don't have any experience in the cranelift codebase. If you deem it necessary, we would be happy to join the weekly meeting (we also don't know how to do this).</p>",
        "id": 433056593,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1713022823
    },
    {
        "content": "<p>I forgot to add a <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\">link to the issue</a> for  convenience :)</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/e48e6d9a4919c91943fc6327f8f88dc3efba43ae\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f616365646664366332656633316164666263353736303563613863653832323430376634316538663062623964303166326139633636376638313861336634332f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36323630)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" title=\"cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime\">cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Feature When any optimization level is enabled, Cranelift runs e-graph equality saturation, which removes all pure instructions from the function layout and leaves only a data-flow graph representa...</div></div></div>",
        "id": 433057430,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1713023681
    },
    {
        "content": "<p>AFAIK it is still relevant</p>",
        "id": 433060855,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1713026764
    },
    {
        "content": "<p>And I don’t believe anyone is poking at this kind of thing right now</p>",
        "id": 433060868,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1713026790
    },
    {
        "content": "<p>Yes, it's still relevant! In my opinion at least, it'd be really useful to get at least approximate answers to: (i) how much benefit do we see with <em>any</em> sort of scheduling (versus the demand-driven / implicitly-sunk-to-latest approach we have now) across a wider set of benchmarks than the examples we've seen where it matters; and (ii) how low can we push the compile-time cost, to fit with the general ethos of Cranelift's optimizations</p>",
        "id": 433062755,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1713028746
    },
    {
        "content": "<p>To that end my personal take is \"simpler might be better?\" but it's worth exploring a range of approaches to be sure</p>",
        "id": 433062774,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1713028783
    },
    {
        "content": "<p>in the linked issue with the example that drove this thinking, <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159#issuecomment-1498177922\">here</a> I gave a possibly acceptable and very simple approach: try to preserve original ordering when one can (and maybe extend the notion of ordering to \"nodes created while rewriting another node\"). That addresses the \"llvm/user carefully scheduled the inner loop\" cases, at least, without getting into complex heuristics</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6159#issuecomment-1498177922\" style=\"background-image: url(https\\:\\/\\/uploads\\.zulipusercontent\\.net\\/522684f2c3bf6d92e22ac2e4fd8bb21aa5585450\\/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f643932646430616365396434316464343131613037343263663332633564336239646534373534653665396564393137333132343134313963393861393439362f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36313539)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159#issuecomment-1498177922\" title=\"Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime\">Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">I did a bit of work recently to get a build of XNNPACK working with Wasmtime. My original motivation for doing this was that XNNPACK has been used as a benchmark to evaluate a number of changes to ...</div></div></div>",
        "id": 433062911,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1713028889
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"709823\">Panagiotis Karouzakis</span> has marked this topic as resolved.</p>",
        "id": 433461354,
        "sender_full_name": "Notification Bot",
        "timestamp": 1713253377
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"709823\">Panagiotis Karouzakis</span> has marked this topic as unresolved.</p>",
        "id": 433461361,
        "sender_full_name": "Notification Bot",
        "timestamp": 1713253380
    },
    {
        "content": "<p>In Issue #6260 Jamey Sharp referenced a paper that combines two greedy techniques Critical Path (CP) that \"counts the maximum length of any data-dependent chain of instructions that must execute after this instruction before the end of the block\". Last Used Count  (LUC) that \"It counts how many live-ranges will end if we place this instruction now. Put another way, for each operand, check whether there are any other instructions that will use the same value but haven't been scheduled yet\". The LUC is used first, as a tie breaker we have the CP and as a last resort tie breaker we can use the smallest instruction number to be scheduled first. Other heuristics could be applied to but I think for a first approach we can try the CP+LUC first what do you think?</p>",
        "id": 433462504,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1713253847
    },
    {
        "content": "<p>That plus “preserve original ordering” above; latter cheaper, lower quality, curious how much lower (and how much faster during compilation) for real benchmarks!</p>",
        "id": 434454208,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1713572867
    },
    {
        "content": "<p>Hello again!</p>\n<p>Since this has been our first interaction with cranelift, we took some time (me and Panagiotis) to understand the codebase and the egraph concept a bit. We have some questions on where the arbitrary topo-sort selection of instructions (as described in <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\">issue #6260</a>) appears inside code. We have pinpointed three places on <code>elaborate.rs</code> you might be talking about:</p>\n<ol>\n<li>In <code>elaborate_domtree()</code> (although this should not concern basic blocks):</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">child</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">ctrl_plane</span><span class=\"p\">.</span><span class=\"n\">shuffled</span><span class=\"p\">(</span><span class=\"n\">domtree</span><span class=\"p\">.</span><span class=\"n\">children</span><span class=\"p\">(</span><span class=\"n\">block</span><span class=\"p\">))</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"p\">}</span>\n</code></pre></div>\n<ol start=\"2\">\n<li>In <code>elaborate_block()</code>:</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">arg</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"n\">elab_values</span><span class=\"p\">.</span><span class=\"n\">iter_mut</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"p\">}</span>\n</code></pre></div>\n<ol start=\"3\">\n<li>In <code>process_elab_stack()</code>:</li>\n</ol>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">arg</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">func</span><span class=\"p\">.</span><span class=\"n\">dfg</span><span class=\"p\">.</span><span class=\"n\">inst_values</span><span class=\"p\">(</span><span class=\"n\">inst</span><span class=\"p\">).</span><span class=\"n\">rev</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.</span><span class=\"w\"> </span><span class=\"p\">}</span>\n</code></pre></div>\n<p>Are we (firstly) correct and (secondly) complete with our findings?</p>\n<p>Lastly, please tell us if such \"mentoring\" advice is undesirable for this difficulty level in the codebase.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/e48e6d9a4919c91943fc6327f8f88dc3efba43ae/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f616365646664366332656633316164666263353736303563613863653832323430376634316538663062623964303166326139633636376638313861336634332f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36323630&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" title=\"cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime\">cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Feature When any optimization level is enabled, Cranelift runs e-graph equality saturation, which removes all pure instructions from the function layout and leaves only a data-flow graph representa...</div></div></div>",
        "id": 437686417,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715185737
    },
    {
        "content": "<p>The elaboration-stack machinery is indeed what decides instruction order today</p>",
        "id": 437699234,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715189992
    },
    {
        "content": "<p><em>Starting note: if this seems more like something that should be posted as an issue reply, please tell us.</em></p>\n<p>We started a prototype implementation <a href=\"https://github.com/karouzakisp/wasmtime\">here</a> for the program order retention approach.</p>\n<h1>Implementation steps</h1>\n<ul>\n<li>For each pure <code>Inst</code> removed from the function's layout, we give it a monotonically increasing sequence number using an instance of your <code>SecondaryMap</code> structure.</li>\n<li>During the elaboration stack processing, instead of eagerly elaborating instructions we do the following:<ul>\n<li>If the instruction was already present in the function's layout before the egraph optimizations, we insert it in a priority queue based on its sequence number, along with its <code>before</code> instruction as found in <code>process_elab_stack()</code>.</li>\n<li>If the instruction was generated during egraph optimization, we eagerly elaborate the entire priority queue (respecting the stored <code>before</code> placements) in ascending sequence order (presumably respecting the original order), and then elaborate the egraph-generated one.</li>\n</ul>\n</li>\n<li>We elaborate all instructions in our queue  (respecting the stored <code>before</code> placements) each time we finish with a skeleton instruction.</li>\n</ul>\n<h1>Possible mistakes</h1>\n<ul>\n<li>We are not confident how the optimization(?) of hoisting instructions outside loops works, so our keeping of <code>before</code> placements might be erroneous.</li>\n<li>We currently eagerly elaborate all instructions coming from rematerialization through <code>maybe_remat_arg()</code>.</li>\n<li>We are not certain if our process of finding if an instruction was in the original function layout is correct. The <code>SecondaryMap</code> we use takes an <code>Inst</code> and gives us a sequence number, but does a <code>Layout</code> have duplicate <code>Inst</code> entries, or are all of them unique? </li>\n</ul>\n<h1>Other notes</h1>\n<p>With our current implementation we don't reorder among neither egraph-generated instructions, nor skeleton instructions. The latter we believe is already optimal for the non-heuristics approach, but for the former we are thinking the delta approach might give us bigger reorder-ready ranges. We are not sure how frequent are such new instruction generations from the egraph though, so it might not be worth it in the end to track their generation roots.</p>\n<p>We are aware that an <code>InstNode</code> in <code>Layout</code> has a <code>seq</code> field. I think we don't have access to this field currently, so we created a <code>u32</code> sequence number to simulate this that wraps around.</p>\n<h1>Testing</h1>\n<p>When running <code>cargo test</code> for the entire project (on x86_64 machines), we pass 161/1183 tests. We believe most failed tests are because they expect a fixed sequence of instructions, and we indeed see from the failure outputs that our implementation reorders some of them. There were some though that concearned us, since they duplicated some instructions. One such test is <code>disas</code> / <code>load-store</code> / <code>x64</code> / <code>load_store_static_kind_i32_index_0_guard_yes_spectre_i8_access_0x1000_offset.wat</code>.</p>\n<p>We tried to simply run the benchmarks from issue <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\">#6159</a> with our release build of wasmtime, and they indeed ran without any observable problems (noted that we are extremely inexperienced here). Even concequtive runs from the same build had measurable variance, hence when comparing to the build without our commit the results were not clear. That's probably because we did them with our laptops, but still, it might be worth it to verify the stability of the results from issue <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\">#6159</a> .</p>\n<p>We had to port the <code>run.sh</code> script from the <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\">#6159</a> to the current CLI format. Also noted that we couldn't find the option to disable egraph optimization on the new wasmtime CLI.</p>\n<p><strong>Updated <code>run.sh</code>:</strong></p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code><span class=\"nb\">set</span><span class=\"w\"> </span>-e\n<span class=\"nv\">wasmtime</span><span class=\"o\">=</span><span class=\"s2\">\"../wasmtime/target/release/wasmtime run -C cache=n \\</span>\n<span class=\"s2\">  -W relaxed-simd=y,threads=y \\</span>\n<span class=\"s2\">  -S threads=y --\"</span>\n\n<span class=\"k\">for</span><span class=\"w\"> </span>t<span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"sb\">`</span><span class=\"nv\">$wasmtime</span><span class=\"w\"> </span>./end2end.simd.relaxed.wasm<span class=\"w\"> </span>--benchmark_list_tests<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>rg<span class=\"w\"> </span>-v<span class=\"w\"> </span>FP16<span class=\"sb\">`</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">  </span><span class=\"c1\"># echo ====================================================================</span>\n\n<span class=\"w\">  </span><span class=\"k\">for</span><span class=\"w\"> </span>file<span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span>end2end.simd.relaxed.wasm<span class=\"p\">;</span><span class=\"w\"> </span><span class=\"k\">do</span>\n<span class=\"w\">    </span><span class=\"c1\"># echo == $file ==</span>\n<span class=\"w\">    </span><span class=\"nb\">echo</span><span class=\"w\"> </span>-n<span class=\"w\"> </span><span class=\"s2\">\"wasmtime     \"</span>\n<span class=\"w\">    </span><span class=\"nv\">$wasmtime</span><span class=\"w\"> </span>./<span class=\"nv\">$file</span><span class=\"w\"> </span>--benchmark_filter<span class=\"o\">=</span><span class=\"nv\">$t</span><span class=\"w\"> </span><span class=\"m\">2</span>&gt;<span class=\"p\">&amp;</span><span class=\"m\">1</span><span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>rg<span class=\"w\"> </span><span class=\"nv\">$t</span>\n\n<span class=\"w\">  </span><span class=\"k\">done</span>\n<span class=\"w\">  </span><span class=\"nb\">echo</span>\n\n<span class=\"k\">done</span>\n</code></pre></div>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/karouzakisp/wasmtime\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/1129806e0bb2a58b1f65cbdf25369b4d063e7563/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f613738383765366361613166393530613032636330313762316338623133356266363761343837626537316537633964303166353934633765626132363563352f6b61726f757a616b6973702f7761736d74696d65&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/karouzakisp/wasmtime\" title=\"GitHub - karouzakisp/wasmtime: Investigating better instruction scheduling using heuristics on cranelift\">GitHub - karouzakisp/wasmtime: Investigating better instruction scheduling using heuristics on cranelift</a></div><div class=\"message_embed_description\">Investigating better instruction scheduling using heuristics on cranelift - karouzakisp/wasmtime</div></div></div><div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/522684f2c3bf6d92e22ac2e4fd8bb21aa5585450/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f643932646430616365396434316464343131613037343263663332633564336239646534373534653665396564393137333132343134313963393861393439362f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36313539&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\" title=\"Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime\">Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">I did a bit of work recently to get a build of XNNPACK working with Wasmtime. My original motivation for doing this was that XNNPACK has been used as a benchmark to evaluate a number of changes to ...</div></div></div>",
        "id": 438116414,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715441432
    },
    {
        "content": "<p>Correction: we <strong>fail</strong> in 161 tests out of the total 1,183 <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 438139243,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715467351
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> Can you provide us with bigger benchmarks in order to test the implementation with more rigorous results? The results from the existing benchmarks have a lot of variance and they are small.</p>",
        "id": 438427959,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1715626780
    },
    {
        "content": "<p>Have you guys looked into using sightglass? <a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a><br>\nThis is what we usually use to measure  changes, it has a few wasm benchmarks that are useful</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/ae44921f1d9461264d282583444d786ba06b1d52/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f633535633063623830646465626163643965663763326130653764326631663862336562333061323732333437663166316632373961343632336631666662362f62797465636f6465616c6c69616e63652f7369676874676c617373&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass\" title=\"GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.\">GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - bytecodealliance/sightglass</div></div></div>",
        "id": 438428600,
        "sender_full_name": "Afonso Bordado",
        "timestamp": 1715626990
    },
    {
        "content": "<p><a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a> is the usual suite of benchmarks we use for cranelift and wasmtime</p>\n<p>particularly the spidermonkey benchmark is important</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/ae44921f1d9461264d282583444d786ba06b1d52/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f633535633063623830646465626163643965663763326130653764326631663862336562333061323732333437663166316632373961343632336631666662362f62797465636f6465616c6c69616e63652f7369676874676c617373&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass\" title=\"GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.\">GitHub - bytecodealliance/sightglass: A benchmark suite and tool to compare different implementations of the same primitives.</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - bytecodealliance/sightglass</div></div></div>",
        "id": 438428615,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1715626997
    },
    {
        "content": "<p>the default suite (if you don't explicitly pass a particular benchmark on the CLI) is a good choice in general</p>\n<p>the default suite contains:</p>\n<ul>\n<li><code>bz2</code></li>\n<li>a rust markdown-to-html library</li>\n<li>spidermonkey.wasm</li>\n</ul>",
        "id": 438428995,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1715627146
    },
    {
        "content": "<p>you'll want to build <code>wasmtime-bench-api</code> on <code>main</code> and then on your branch to produce two different shared libraries:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"n\">checkout</span><span class=\"w\"> </span><span class=\"n\">main</span>\n<span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">cargo</span><span class=\"w\"> </span><span class=\"n\">build</span><span class=\"w\"> </span><span class=\"o\">--</span><span class=\"n\">release</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"n\">p</span><span class=\"w\"> </span><span class=\"n\">wasmtime</span><span class=\"o\">-</span><span class=\"n\">bench</span><span class=\"o\">-</span><span class=\"n\">api</span>\n<span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">cp</span><span class=\"w\"> </span><span class=\"n\">target</span><span class=\"o\">/</span><span class=\"n\">release</span><span class=\"o\">/</span><span class=\"n\">libwasmtime_bench_api</span><span class=\"p\">.</span><span class=\"n\">so</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"n\">tmp</span><span class=\"o\">/</span><span class=\"n\">main</span><span class=\"p\">.</span><span class=\"n\">so</span>\n<span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">git</span><span class=\"w\"> </span><span class=\"n\">checkout</span><span class=\"w\"> </span><span class=\"n\">better</span><span class=\"o\">-</span><span class=\"n\">inst</span><span class=\"o\">-</span><span class=\"n\">sched</span><span class=\"w\"> </span>#<span class=\"w\"> </span><span class=\"n\">or</span><span class=\"w\"> </span><span class=\"n\">whatever</span><span class=\"w\"> </span><span class=\"n\">your</span><span class=\"w\"> </span><span class=\"n\">branch</span><span class=\"w\"> </span><span class=\"n\">is</span><span class=\"w\"> </span><span class=\"n\">named</span>\n<span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">cargo</span><span class=\"w\"> </span><span class=\"n\">build</span><span class=\"w\"> </span><span class=\"o\">--</span><span class=\"n\">release</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"n\">p</span><span class=\"w\"> </span><span class=\"n\">wasmtime</span><span class=\"o\">-</span><span class=\"n\">bench</span><span class=\"o\">-</span><span class=\"n\">api</span>\n<span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">cp</span><span class=\"w\"> </span><span class=\"n\">target</span><span class=\"o\">/</span><span class=\"n\">release</span><span class=\"o\">/</span><span class=\"n\">libwasmtime_bench_api</span><span class=\"p\">.</span><span class=\"n\">so</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"n\">tmp</span><span class=\"o\">/</span><span class=\"n\">better</span><span class=\"o\">-</span><span class=\"n\">inst</span><span class=\"o\">-</span><span class=\"n\">sched</span><span class=\"p\">.</span><span class=\"n\">so</span>\n</code></pre></div>\n<p>and finally in sightglass do:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"cp\">$</span><span class=\"w\"> </span><span class=\"n\">cargo</span><span class=\"w\"> </span><span class=\"n\">run</span><span class=\"w\"> </span><span class=\"o\">--</span><span class=\"w\"> </span><span class=\"n\">benchmark</span><span class=\"w\"> </span><span class=\"o\">--</span><span class=\"n\">engine</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"n\">tmp</span><span class=\"o\">/</span><span class=\"n\">main</span><span class=\"p\">.</span><span class=\"n\">so</span><span class=\"w\"> </span><span class=\"o\">--</span><span class=\"n\">engine</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"n\">tmp</span><span class=\"o\">/</span><span class=\"n\">better</span><span class=\"o\">-</span><span class=\"n\">inst</span><span class=\"o\">-</span><span class=\"n\">sched</span><span class=\"p\">.</span><span class=\"n\">so</span>\n</code></pre></div>",
        "id": 438429685,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1715627413
    },
    {
        "content": "<p>Thanks for the pointers! — we didn't have time to check the contributors' documentation extensively...</p>\n<p>We also just found Chris Fallin's talk on egraphs in cranelift. We couldn't find the recording from the conference, so until now we relied on the accompanying slides, which was a bit less than ideal.</p>\n<p>We'll follow up with results in the next few days probably :)</p>",
        "id": 438433196,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715628763
    },
    {
        "content": "<p>There's a recording linked from my website; unfortunately the conference itself did not record (there were AV problems)</p>",
        "id": 438435074,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715629462
    },
    {
        "content": "<p><a href=\"https://cfallin.org/academics/\">https://cfallin.org/academics/</a> under \"invited talks\"</p>",
        "id": 438435144,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715629494
    },
    {
        "content": "<p>Yes, that's the one we found a few days ago too <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 438436111,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715629849
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"253990\">fitzgen (he/him)</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/438428615\">said</a>:</p>\n<blockquote>\n<p><a href=\"https://github.com/bytecodealliance/sightglass\">https://github.com/bytecodealliance/sightglass</a> is the usual suite of benchmarks we use for cranelift and wasmtime</p>\n<p>particularly the spidermonkey benchmark is important</p>\n</blockquote>\n<p>We thank you for your guidance</p>",
        "id": 438532036,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1715677376
    },
    {
        "content": "<p>thank <em>you</em> for digging into this stuff!</p>",
        "id": 438611345,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1715703784
    },
    {
        "content": "<p>A small update on the benchmarks from my PC (Ryzen 5700G, running Opensuse Tumbleweed), comparing our prototype program order retention optimization with main:</p>\n<h2>Compilation</h2>\n<ul>\n<li>spidermonkey is 1.00x to 1.01 <strong>slower</strong></li>\n<li>pulldown-cmark is 1.01x to 1.06x <strong>faster</strong></li>\n<li>bz2 has no measurable difference</li>\n<li>hex-simd has no measurable difference</li>\n<li>blake3-simd has no measurable difference</li>\n<li>intgemm-simd has no measurable difference</li>\n</ul>\n<h2>Instantiation</h2>\n<ul>\n<li>spidermonkey has no measurable difference</li>\n<li>pulldown-cmark is 1.00x to 1.04x <strong>faster</strong></li>\n<li>bz2 is 1.02x to 1.06x <strong>slower</strong></li>\n<li>hex-simd has no measurable difference</li>\n<li>blake3-simd has no measurable difference</li>\n<li>intgemm-simd is 1.00x to 1.05x <strong>slower</strong></li>\n</ul>\n<h2>Execution</h2>\n<ul>\n<li>spidermonkey is 1.03x <strong>slower</strong></li>\n<li>pulldown-cmark is 1.01x to 1.02x <strong>faster</strong></li>\n<li>bz2 has no measurable difference</li>\n<li>hex-simd is 1.03x to 1.11x <strong>slower</strong></li>\n<li>blake3-simd has no measurable difference</li>\n<li>intgemm-simd has no measurable difference</li>\n</ul>",
        "id": 438726510,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715750599
    },
    {
        "content": "<p>We're trying to tackle the heuristics-approach implementation since yesterday, but if you have any comments on the proposed implementation for the program-order-retention approach tell us.</p>\n<p>If you exclude some comment-notes, the diff for our prototype program-order-retention implementation is quite small — should you want to look at the actual code.</p>",
        "id": 438726830,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715750846
    },
    {
        "content": "<p>One high-level note: it may be the case that you’ll need to run more benchmark iterations and/or tackle system noise; instantiation time should not change at all if you’re only changing codegen (it involves only data structure + memory setup performed by the runtime, not Cranelift-compiled code) so if it has deltas on the same order as your reported results that likely indicates noise</p>",
        "id": 438727737,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715751525
    },
    {
        "content": "<p>We have a document on precision benchmarking somewhere written up by Jamey (involving isolating a core and frequency-pinning etc) if you want to go that far; can’t find atm as I’m on phone</p>",
        "id": 438727818,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715751595
    },
    {
        "content": "<p>Yeah, I basically just closed everything else along with network access while running the benchmarks, but the instantiation differences did concern me a bit indeed...</p>",
        "id": 438728056,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715751735
    },
    {
        "content": "<p>I'll try to find that document, thanks!</p>",
        "id": 438728107,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715751764
    },
    {
        "content": "<p>Compilation being faster in <code>pulldown-cmark</code> was also a bit alarming...</p>",
        "id": 438728449,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715751974
    },
    {
        "content": "<p>Here we go, found it: <a href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\">https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/ae44921f1d9461264d282583444d786ba06b1d52/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f633535633063623830646465626163643965663763326130653764326631663862336562333061323732333437663166316632373961343632336631666662362f62797465636f6465616c6c69616e63652f7369676874676c617373&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\" title=\"sightglass/docs/cpu-isolation.md at main · bytecodealliance/sightglass\">sightglass/docs/cpu-isolation.md at main · bytecodealliance/sightglass</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - bytecodealliance/sightglass</div></div></div>",
        "id": 438729418,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715752725
    },
    {
        "content": "<p>I run the same set of benchmarks after cpu isolation and frequency pinning (to 400MHz <span aria-label=\"smiling face with tear\" class=\"emoji emoji-1f972\" role=\"img\" title=\"smiling face with tear\">:smiling_face_with_tear:</span>), and the results quite decisive, albeit with one unexpected instantiation result:</p>\n<ul>\n<li>1.02x to 1.07x <strong>slower execution</strong> in <code>pulldown-cmark</code></li>\n<li>1.00x to 1.07x <strong>faster instantiation</strong> in <code>hex-simd</code></li>\n<li>1.02x to 1.04x <strong>slower execution</strong> in <code>spidermonkey</code></li>\n<li>1.02x to 1.04x <strong>slower compilation</strong> in <code>pulldown-cmark</code></li>\n</ul>\n<p>All other results showed no difference in performance.</p>",
        "id": 438742402,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715758413
    },
    {
        "content": "<p>We might have missed something that makes our implementation incorrect from first principles.</p>\n<p>It might also be the case that our restriction of disallowing restructuring across new, egraph-generated instructions is important after all — any thoughts?</p>",
        "id": 438742935,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715758619
    },
    {
        "content": "<p>Actually, do we expect performance gains with program-order retention on any benchmark from sightglass at all? I mean, are there such carefully-pipelined simd examples there?</p>",
        "id": 438746168,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1715759929
    },
    {
        "content": "<p>The benchmark from the original \"instruction scheduling slowdowns\" issue might help?: <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\">https://github.com/bytecodealliance/wasmtime/issues/6159</a></p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/522684f2c3bf6d92e22ac2e4fd8bb21aa5585450/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f643932646430616365396434316464343131613037343263663332633564336239646534373534653665396564393137333132343134313963393861393439362f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36313539&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6159\" title=\"Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime\">Cranelift and suboptimal instruction scheduling · Issue #6159 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">I did a bit of work recently to get a build of XNNPACK working with Wasmtime. My original motivation for doing this was that XNNPACK has been used as a benchmark to evaluate a number of changes to ...</div></div></div>",
        "id": 438819743,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715784095
    },
    {
        "content": "<p>Is it possible to use the XNNPACK benchmark with the same method as sightglass benchmarks are used? The XNNPACK repository does not contain any instructions. Any thoughts?</p>",
        "id": 439041847,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1715871843
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"253994\">@Alex Crichton</span></p>",
        "id": 439041950,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1715871867
    },
    {
        "content": "<p>IIRC I had to apply quite a number of hacks at the time to get XNNPACK to build from source, that was a year or two ago now though so things may be different now. In any case I don't think building from source will be easy.</p>",
        "id": 439042114,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1715871916
    },
    {
        "content": "<p>the other \"weird thing\" is that I could only get it to build with wasi-threads, which makes it very different from all other benchmarks</p>",
        "id": 439042378,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1715871984
    },
    {
        "content": "<p>so... theoretically possible but will require a lot of elbow grease</p>",
        "id": 439042445,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1715872008
    },
    {
        "content": "<p>XNNPACK is also so big I couldn't figure out at the time what was actually a benchmark to run since there seemed to be hundreds of benchmarks</p>",
        "id": 439042571,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1715872042
    },
    {
        "content": "<p>Does anyone know how the macro named trace can be enabled? We have reached a point in our implementation that we need it.</p>",
        "id": 439464523,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1716150479
    },
    {
        "content": "<p>The Cargo feature <code>trace-log</code> on the <code>cranelift-codegen</code> crate controls that -- when I'm debugging I usually just throw the feature in the <code>default</code> list there (and make sure not to commit it/include it in PRs)</p>",
        "id": 439490786,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716176527
    },
    {
        "content": "<p>(the intent is to avoid even the cost of the dynamic check of log level in some performance-sensitive parts of the compiler by excluding all the logging stuff statically in ordinary builds)</p>",
        "id": 439490805,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716176552
    },
    {
        "content": "<p>Btw, he is talking about the heuristics implementation. We believe we have a complete implementation (along with rank pairing heaps), but now we are trying to tackle duplication of instructions and how this would affect us.</p>",
        "id": 439490982,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1716176758
    },
    {
        "content": "<p>We also have an open issue with rematerialization (should we leave it in the scoped elaboration walk, or should we integrate it in the ready queue pass), so we have currently just removed it altogether.</p>",
        "id": 439491074,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1716176839
    },
    {
        "content": "<p>I'll probably ask this more formally in the proposal issue actually...</p>",
        "id": 439491147,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1716176907
    },
    {
        "content": "<p>In elaborate.rs::elaborate_block::768:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"c1\">// Record the first branch we see in the block; all</span>\n<span class=\"c1\">// elaboration for args of *any* branch must be inserted</span>\n<span class=\"c1\">// before the *first* branch, because the branch group</span>\n<span class=\"c1\">// must remain contiguous at the end of the block.</span>\n</code></pre></div>\n<p>We have some questions about that.<br>\n1) Can we have multiple branches in one single block?<br>\n2) What is the meaning of the \" branch group must remain continuous\" ?</p>",
        "id": 440388961,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1716494169
    },
    {
        "content": "<p>Ah, this is left over from before a cleanup we made a while ago</p>",
        "id": 440389072,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494212
    },
    {
        "content": "<p>It used to be that Cranelift represented multiple-target terminators (e.g., a BB ending with a conditional branch) with multiple single-target branches</p>",
        "id": 440389106,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494229
    },
    {
        "content": "<p>in effect, the terminator was \"exploded\" into multiple pieces</p>",
        "id": 440389127,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494237
    },
    {
        "content": "<p>(which itself was left over from ancient history where Cranelift used Extended Basic Blocks / EBBs that could have side-exits mid-block)</p>",
        "id": 440389163,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494260
    },
    {
        "content": "<p>thankfully Trevor cleaned that up... last year sometime? certainly after that comment was written... so that we have proper single-branch-terminators now</p>",
        "id": 440389215,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494281
    },
    {
        "content": "<p>the comment is alluding to subtleties that could happen when a branch other than the first had an arg that required elaboration</p>",
        "id": 440389290,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494308
    },
    {
        "content": "<p>now it's safe to ignore it (and please feel free to submit a PR to remove that comment and associated logic too!)</p>",
        "id": 440389318,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1716494322
    },
    {
        "content": "<p>Hello <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> and <span class=\"user-mention\" data-user-id=\"504918\">@Jamey Sharp</span>,</p>\n<p>Just a small update for our project that me and <span class=\"user-mention\" data-user-id=\"709820\">@Dimitris Aspetakis</span> are working on.<br>\nWe are still fixing issues related to minor bugs. A few of them still remain.</p>\n<p>Hopefully next week we will run some benchmarks and see the results.</p>",
        "id": 443573013,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1717921854
    },
    {
        "content": "<p>Quick question: does register allocation in the lowering backend depend on rematerialization from the midend?</p>",
        "id": 444403538,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264524
    },
    {
        "content": "<p>We don't get any errors anymore from testing cranelift-tools, except from 6 files where the order changed or we got errors due to our missing licm or rematerialization optimizations</p>",
        "id": 444403748,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264623
    },
    {
        "content": "<p>I manually checked all 6 and the resulting IR seems valid, and changing manually the check tests to our output, we now pass everything in cranelift-tools</p>",
        "id": 444404008,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264712
    },
    {
        "content": "<p>Exciting!</p>\n<p>Register allocation can be impacted by any mid-end change including rematerialization, just because they perturb the input to the register allocator, but I don't think there's any specific dependency between them. I'm not sure I understood the question though?</p>",
        "id": 444404164,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718264771
    },
    {
        "content": "<p>When running spidermonkey from the sightglass suite we get an error like this:<br>\n<a href=\"/user_uploads/15107/kc-vWiu_Gxj8hnxOfhSG39WT/dbcb5903-d407-48b8-a004-a471a4e21c2f.jpg\">dbcb5903-d407-48b8-a004-a471a4e21c2f.jpg</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/kc-vWiu_Gxj8hnxOfhSG39WT/dbcb5903-d407-48b8-a004-a471a4e21c2f.jpg\" title=\"dbcb5903-d407-48b8-a004-a471a4e21c2f.jpg\"><img src=\"/user_uploads/15107/kc-vWiu_Gxj8hnxOfhSG39WT/dbcb5903-d407-48b8-a004-a471a4e21c2f.jpg\"></a></div>",
        "id": 444404280,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264837
    },
    {
        "content": "<p>That was my intuition behind a possible dependency <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 444404319,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264862
    },
    {
        "content": "<p>We just aren't sure where to go next if the tests in cranelift-tools pass, and we seem to have proper IR output in them...</p>",
        "id": 444404446,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718264909
    },
    {
        "content": "<p>I'd have to look up that assert in <code>compile.rs</code> line 76 and figure out what it's actually checking, because that failure message doesn't mean anything to me <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 444404779,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718265038
    },
    {
        "content": "<p>Yeah, I get it... What I meant earlier is if you know of the lowring stage having an explicit dependency on rematerialization from the midend. I figured it might expect a certain number of live SSA ranges at any point for example.</p>",
        "id": 444405079,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718265180
    },
    {
        "content": "<p>Lowering and register allocation have to work even when the egraph pass doesn't run because optimizations are disabled, so there \"shouldn't\" be any dependency like that. But of course there can always be bugs <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 444405409,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718265304
    },
    {
        "content": "<p>We'll try to look into the <code>compile.rs</code> errors now I guess then...</p>",
        "id": 444405497,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718265338
    },
    {
        "content": "<p>I would dig into it more with you but I can't today. If you're still having trouble next week I can hopefully take a look then!</p>",
        "id": 444405696,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718265417
    },
    {
        "content": "<p>+1 to all of Jamey's answers above re: independence of the two bits. Regalloc should be happy with any valid VCode, and we should get valid VCode from valid CLIF (ergo, one way to find this might be to explicitly run the CLIF validator at various points).</p>\n<p>Re: the assert: <code>compile.rs:76</code> is just where regalloc is invoked; this is propagating upward an error that regalloc2 detected. Specifically <code>EntryLivein</code> means that some register was used that was never defined (it was a live-in at entry, which isn't supposed to happen). Likely this means that an instruction is missing somewhere. Running the CLIF validator as above should find this at an earlier point and indicate exactly where in the CLIF the problem is.</p>\n<p>Re: this</p>\n<blockquote>\n<p>We just aren't sure where to go next if the tests in cranelift-tools pass, and we seem to have proper IR output in them...</p>\n</blockquote>\n<p>The test suite is fine but mostly has small functions, so especially for algorithmic tweaks that start to get interesting with more substantial block sizes (see: instruction scheduling!), I'd expect one to have to expand the test suite to fully cover its behavior. So it doesn't surprise me that it currently passes the suite but fails on a real program. The way I would go about this is resolving the bug as above -- add the validator, add as many debug prints as needed, extract the CLIF -- then when the bug is fixed, turn it into a regression test (new entry in the suite). In general I think we'd consider something like this feature well-tested when it passes (i) the suite, (ii) fuzzing, and (iii) reasonable real programs like spidermonkey.</p>",
        "id": 444493284,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718292443
    },
    {
        "content": "<p>Oh yeah, there's a Cranelift option to enable the verifier, right? I don't remember what the option is called. Also, this reminds me that a good step in between the small CLIF filetests and a large program like Spidermonkey might be the <code>disas</code> tests, which you can run with <code>cargo test --test disas</code>, if I remember correctly. They have a little bit more interesting control flow while still being pretty small.</p>",
        "id": 444495361,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718292892
    },
    {
        "content": "<p><code>enable_verifier</code>, indeed; one could also sprinkle manual calls to the verifier throughout the compilation pipeline (e.g. just before and after the egraph pass invocation) which may be easier when running tests etc</p>",
        "id": 444497082,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718293251
    },
    {
        "content": "<p>Thank you both! The pointers are very helpful!<br>\nWe pass ~1000 and we indeed fail 237 on the <code>disas</code> tests.</p>",
        "id": 444497203,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718293270
    },
    {
        "content": "<p>(I hesitate to give a \"thumbs-up\" reaction to that but at least you have more input to make progress! best of luck :-) )</p>",
        "id": 444497401,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718293307
    },
    {
        "content": "<p>It kinda seemed logical to me that our <code>disas</code> errors might be from checks using the previous ordering, so I gave them my blessing (with <code>WASMTIME_TEST_BLESS=1</code>), and the errors disappeared. We also put the following at the end of <code>egraph_pass()</code> (after our scheduling):</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"c1\">// self.verify_if(fisa)</span>\n<span class=\"c1\">// verify_function(&amp;self.func, fisa)?;</span>\n<span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">verify</span><span class=\"p\">(</span><span class=\"n\">fisa</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span>\n<span class=\"nb\">Ok</span><span class=\"p\">(())</span>\n</code></pre></div>\n<p>Was that what you were talking about when mentioning verification? — we tested using both <code>verify_function()</code> and <code>self.verify()</code>. The <code>disas</code> errors disappeared even with those verifications in place.</p>",
        "id": 444539118,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718305259
    },
    {
        "content": "<p>We then starting tackling <code>blake3-simd</code> from Sightglass (which we can see when compiling that it gives us a familiar error), but got stuck in trying to get it to emit egraph-optimized clif.</p>\n<p>We want the  optimized clif to diff it with the previous implementation, but the --emit-clif option from wasmtime probably gives us unoptimized clif (edit: we think that because it emits the same functions using our implementation, and using the previous one).</p>\n<p>Do you  know of a way to get optimized clif using the wasmtime binary (or another tool), or should we print it explicitly through changes in the code?</p>",
        "id": 444540158,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718305574
    },
    {
        "content": "<p>You're right that <code>--emit-clif</code> prints as soon as the first CLIF is generated, before any optimization passes. I haven't been very satisfied with the options we have for getting optimized CLIF from there. What I usually do is put the unoptimized CLIF in a file and add </p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">test</span><span class=\"w\"> </span><span class=\"n\">optimize</span><span class=\"w\"> </span><span class=\"n\">precise</span><span class=\"o\">-</span><span class=\"n\">output</span>\n<span class=\"n\">set</span><span class=\"w\"> </span><span class=\"n\">opt_level</span><span class=\"o\">=</span><span class=\"n\">speed</span>\n<span class=\"n\">target</span><span class=\"w\"> </span><span class=\"n\">x86_64</span>\n</code></pre></div>\n<p>at the top, then run <code>CRANELIFT_TEST_BLESS=1 cargo run -p cranelift-tools -- test &lt;filename&gt;</code>, and finally look at what it wrote into comments at the end of the file.</p>",
        "id": 444546485,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718307281
    },
    {
        "content": "<p>That's exactly what we did 20 minutes ago <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 444546677,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718307352
    },
    {
        "content": "<p>And I think <code>self.verify</code> was exactly what Chris was suggesting to do, although I'm not looking at the code right now to make sure.</p>",
        "id": 444546810,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718307387
    },
    {
        "content": "<p>We're actually passing now quite a few of the sightglass benchmarks! For now, only spidermonkey fails...</p>",
        "id": 444554090,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718310018
    },
    {
        "content": "<p>Expect benchmark numbers coming in a few hours <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 444554184,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718310058
    },
    {
        "content": "<p>We probably fixed all the errors. The error in Spidermonkey was due to the rank pairing heap implementation. After modifying it a bit we ran Spidermonkey with no problems. Tomorrow we will have benchmarks (without the remat and licm optimizations).</p>",
        "id": 444561169,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1718312611
    },
    {
        "content": "<p><a href=\"/user_uploads/15107/snXroGSR4E4rFJn6SbLn17wJ/summary.txt\">summary.txt</a></p>\n<p>So... we are quite bad on compilation (up to 194% worse), but out of the three default benchmarks, two have no difference in execution time, and spidermonkey has 2–4% better performance in cycles. I used the suggested method pinning a core, but with one difference: I didn't pin it to its min frequency. I hope that's still valid...</p>",
        "id": 444573635,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718317200
    },
    {
        "content": "<p>I should probably mention that it's our first time writing Rust, so we our implementation probably has a lot of room for improvements...</p>",
        "id": 444573788,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718317277
    },
    {
        "content": "<p>Nice to see a speedup in generated code!</p>\n<blockquote>\n<p>So... we are quite bad on compilation (up to 194% worse)</p>\n</blockquote>\n<p>That is what we call a, uh, \"growth opportunity\" :-) Worth profiling and seeing if there are simple improvements that could give quick speedups, paying attention to allocations, etc.</p>\n<p>FWIW, the alternative \"keep sequence numbers from original code\" idea I had proposed was made with exactly this worry, that a full recomputation of an instruction order would be too expensive; maybe it's worth trying that too</p>",
        "id": 444573875,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718317328
    },
    {
        "content": "<p>We kinda tried that, but we got up to the point of rearranging among new egraph-generated instructions, and not across them, with mixed results if I remember correctly. Now that we have a much better understanding of everything, we might try to remove that restriction (after we write the project report for our university course <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> ).</p>",
        "id": 444574540,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718317547
    },
    {
        "content": "<p>After a few optimizations following flamegraph sessions, we got compilation a bit closer (but it's still probably not good enough). Surprisingly, even though we didn't change anything that should affect execution performance, we are now worse (consistent with multiple runs, unlike last time). Keep in mind though that we still haven't re-applied LICM and rematerialization (currently working a bit on LICM). </p>\n<div class=\"spoiler-block\"><div class=\"spoiler-header\">\n<p>Spidermonkey Benchmark Results</p>\n</div><div class=\"spoiler-content\" aria-hidden=\"true\">\n<div class=\"codehilite\" data-code-language=\"Bash Session\"><pre><span></span><code><span class=\"gp\">dimitris_aspetakis@hourmas:~/.../wasmtime-instr_sched_opt/sightglass$ </span>taskset<span class=\"w\"> </span>--cpu-list<span class=\"w\"> </span><span class=\"m\">7</span><span class=\"w\"> </span>cargo<span class=\"w\"> </span>run<span class=\"w\"> </span>--<span class=\"w\"> </span>benchmark<span class=\"w\"> </span>--measure<span class=\"w\"> </span>cycles<span class=\"w\"> </span>--pin<span class=\"w\"> </span>--processes<span class=\"w\"> </span><span class=\"m\">1</span><span class=\"w\"> </span>--iterations-per-process<span class=\"w\"> </span><span class=\"m\">20</span><span class=\"w\"> </span>--engine<span class=\"w\"> </span>/tmp/wasmtime_main.so<span class=\"w\"> </span>--engine<span class=\"w\"> </span>/tmp/wasmtime_heuristics.so<span class=\"w\"> </span>--<span class=\"w\"> </span>benchmarks/spidermonkey/benchmark.wasm\n<span class=\"go\">    Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.09s</span>\n<span class=\"go\">     Running `target/debug/sightglass-cli benchmark --measure cycles --pin --processes 1 --iterations-per-process 20 --engine /tmp/wasmtime_main.so --engine /tmp/wasmtime_heuristics.so -- benchmarks/spidermonkey/benchmark.wasm`</span>\n\n<span class=\"go\">compilation :: cycles :: benchmarks/spidermonkey/benchmark.wasm</span>\n\n<span class=\"go\">  Δ = 9844247846.30 ± 56071233.34 (confidence = 99%)</span>\n\n<span class=\"go\">  main.so is 1.35x to 1.36x faster than heuristics.so!</span>\n\n<span class=\"go\">  [37470061310 37672977217.40 37781450866] heuristics.so</span>\n<span class=\"go\">  [27642976158 27828729371.10 27885085254] main.so</span>\n\n<span class=\"go\">execution :: cycles :: benchmarks/spidermonkey/benchmark.wasm</span>\n\n<span class=\"go\">  Δ = 106659806.00 ± 11041198.41 (confidence = 99%)</span>\n\n<span class=\"go\">  main.so is 1.07x to 1.09x faster than heuristics.so!</span>\n\n<span class=\"go\">  [1375717572 1390076390.70 1403583922] heuristics.so</span>\n<span class=\"go\">  [1217294356 1283416584.70 1302562366] main.so</span>\n\n<span class=\"go\">instantiation :: cycles :: benchmarks/spidermonkey/benchmark.wasm</span>\n\n<span class=\"go\">  No difference in performance.</span>\n\n<span class=\"go\">  [884146 910732.70 989558] heuristics.so</span>\n<span class=\"go\">  [849338 923529.20 1552376] main.so</span>\n</code></pre></div>\n</div></div>",
        "id": 444858303,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718453748
    },
    {
        "content": "<p>Ohh, I should probably do such updates on the issue from now on actually <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 444858539,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718453928
    },
    {
        "content": "<p>One thing you could try, just as a data point to isolate your core contribution, would be to compare to a baseline without remat or licm either (manually disabled with a hack of some sort)</p>",
        "id": 444884417,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718470907
    },
    {
        "content": "<p>iirc, remat in particular is pretty important on SM — hoisted constants create a lot of reg pressure otherwise</p>",
        "id": 444884514,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718470952
    },
    {
        "content": "<p>Hello, We just completed both licm and remat and we are currently running some benchmarks!<br>\nHere are some preliminary results<br>\nSpiderMonkey: 3-6% faster on execution time, 42-44% slower on compilation time. <br>\n<a href=\"/user_uploads/15107/Z1mB9CsAReWbJ-lPo47jVB7p/image.png\">image.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/Z1mB9CsAReWbJ-lPo47jVB7p/image.png\" title=\"image.png\"><img src=\"/user_uploads/15107/Z1mB9CsAReWbJ-lPo47jVB7p/image.png\"></a></div><p>Bz2: no difference in performance,<br>\npulldown-cmark 2-11% worse on execution time,  </p>\n<p>While we are following all the instructions from <br>\n<a href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\">https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md</a></p>\n<p>We get a big variance on the sightglass execution time Δs. Any tips for that problem?<br>\nFrom now on we will use Vtune to optimize the compilation time and possibly lookout for the reasons that the execution time of some benchmarks is worse.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/820699f83a410ed17d110fd6af1b0ccd4cd88317/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f646161313039323836326535313538613034326133326137393666643531646633396638343933646665633639316138396135336335653931323431313838392f62797465636f6465616c6c69616e63652f7369676874676c617373&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/sightglass/blob/main/docs/cpu-isolation.md\" title=\"sightglass/docs/cpu-isolation.md at main · bytecodealliance/sightglass\">sightglass/docs/cpu-isolation.md at main · bytecodealliance/sightglass</a></div><div class=\"message_embed_description\">A benchmark suite and tool to compare different implementations of the same primitives. - bytecodealliance/sightglass</div></div></div>",
        "id": 445029433,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1718578270
    },
    {
        "content": "<p>Oh, did anyone suggest the Sightglass option <code>--measure=perf-counters</code> yet? (I might have the name wrong, but it's something like that.)</p>",
        "id": 445029730,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718578565
    },
    {
        "content": "<p>I think instructions retired is probably best</p>",
        "id": 445180365,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1718643406
    },
    {
        "content": "<p>Instruction scheduling is supposed to help with ipc, which instructions retired explicitly doesn't account for. Looking at the cycles counter would be more reliable for this.</p>",
        "id": 445222798,
        "sender_full_name": "bjorn3",
        "timestamp": 1718657471
    },
    {
        "content": "<p>true, but we're talking about the compile time overhead here, not the codegen quality</p>",
        "id": 445229535,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1718660098
    },
    {
        "content": "<p>So, compared to cycles, the motivation for using retired instructions for compilation performance would be to get more stable results, or is there something else you have in mind?</p>",
        "id": 445229820,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718660238
    },
    {
        "content": "<p>yes exactly</p>",
        "id": 445231167,
        "sender_full_name": "fitzgen (he/him)",
        "timestamp": 1718660894
    },
    {
        "content": "<p>For the compilation overhead, we managed to reduce it from 200% to 44% in a couple of hours using vtune. I am optimistic that we can lower it even more.<br>\nI am more concerned about getting accurate results on cpu cycles.</p>",
        "id": 445260494,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1718679023
    },
    {
        "content": "<p>You're making fantastic progress. This is very cool!</p>",
        "id": 445264115,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718681369
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"709820\">@Dimitris Aspetakis</span> is wondering what compilation time cost is acceptable in our implementation that results in 3-6% performance gain in cycles in Spidermonkey.<br>\nI am thinking less than 2%, what do you think?</p>",
        "id": 445704736,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1718831755
    },
    {
        "content": "<p>That's a complicated question and I think different people would answer it different ways. Personally, I'm more concerned about whether the implementation is clear and easy to maintain; I feel it's okay to have some room for improvement in compile time if we're comfortable with our ability to work on it more later. Unfortunately I still haven't had a chance to carefully review your code.</p>\n<p>One thing I'm curious about is whether the heuristics are separable. Hypothetically, could you add options that allow someone to enable or disable the critical path heuristic, or the last-use count heuristic, independently of each other? If so, does one have more impact than the other on either compile time or execution time?</p>\n<p>There are downsides to adding options like this (more configurations to test and more confusion for users, for example) but one option I am considering is merging your changes under an off-by-default option. I would really like to have your work upstream! We just need to be confident that we can maintain it and also manage our other goals, such as compile speed.</p>",
        "id": 445707170,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718833049
    },
    {
        "content": "<p>In my mind they are quite separable, as we just use the metrics in the ordering traits implementations of the ready queue.</p>",
        "id": 445708218,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718833610
    },
    {
        "content": "<p>Nice. Does computing either metric take a significant amount of time, or does switching to the ready queue make a big difference in compile time?</p>",
        "id": 445708714,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718833852
    },
    {
        "content": "<p>I wanted to read a bit more documentation in sightglass before I asked the question that Panagiotis mentioned...</p>\n<p>But since he did, the question would be on the significance of compilation vs execution time in the Sightglass benchmarks. I remember seeing compilation taking a lot more cycles in e.g. Spidermonkey. Is that conforming with real-world expectations, or would a slightly better execution time amortize an e.g. 30% worse compilation time?</p>",
        "id": 445708884,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718833931
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"504918\">Jamey Sharp</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/445708714\">said</a>:</p>\n<blockquote>\n<p>Nice. Does computing either metric take a significant amount of time, or does switching to the ready queue make a big difference in compile time?</p>\n</blockquote>\n<p>I believe the use of the rank pairing heap takes ~30% of the elaboration function's time. If I'm not mistaken, we only use it due to LUC needing dynamic updates.</p>",
        "id": 445709136,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718834057
    },
    {
        "content": "<p>We can probably create a branch using only the Critical Paths and a simpler sorted queue.</p>",
        "id": 445709245,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718834123
    },
    {
        "content": "<p>The reason that's a complicated question is that it depends on how people are using Cranelift, and that varies a lot. I believe originally Cranelift was intended for use in JIT compilers, so compilation time was extremely important. It's still important, especially for uses like the Rust compiler's Cranelift backend as an alternative to LLVM, where the goal is to get debug builds quickly. But then for example at Fastly where we use Cranelift via Wasmtime, we'll compile a module once and invoke it many times, so compile time is less important there than execution time. When we maintainers make decisions about Cranelift, we're trying to keep all these different uses in mind.</p>",
        "id": 445709623,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1718834326
    },
    {
        "content": "<p>Really cool to hear about this progress!</p>\n<p>I think at a high level we should consider upstreaming this under a default-off option at least -- the bar for that is much lower. \"Try this option if you want to optimize further\", something like an <code>-O3</code> setting (whereas by analogy today's Cranelift is something like <code>-O2</code>).</p>\n<p>I was about to say more but Jamey beat me to it re: compile-time :-) The only thing I'd add is that we've had a fairly high standard of \"grind on the thing for weeks/months to squeeze out more performance\" (at least, I've personally done this on RA2 and the original aegraphs impl) so going back the other way with say 30% regressions in compile time feels like a huge loss :-) Ideally we'd optimize to a local maximum as much as possible and see how low we can get it before turning it on by default. Again, can definitely happen in-tree as long as it doesn't affect the default build!</p>",
        "id": 445709986,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718834510
    },
    {
        "content": "<p>Oh, one other thing, decisions/discussions like this are often good to have in the context of the Cranelift weekly; would you be interested in attending and talking about your work here? (Wednesdays at 15:30 UTC)</p>",
        "id": 445710248,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718834627
    },
    {
        "content": "<p>Yeah, I'm certainly interested!</p>",
        "id": 445710355,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718834673
    },
    {
        "content": "<p>(and Panagiotis too I believe)</p>",
        "id": 445710427,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1718834711
    },
    {
        "content": "<p>OK cool, I can add you (both?) to the calendar invite with details -- DM me good email addresses for that?</p>",
        "id": 445710448,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718834721
    },
    {
        "content": "<p>(fwiw next few weeks probably quiet as a bunch of us will be out next week, following week is just before US holiday and folks will be out too; maybe later July is good if you want to put something on the agenda for Jul 17, 24 or 31 in bytecodealliance/meetings with a PR)</p>",
        "id": 445710679,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1718834815
    },
    {
        "content": "<p>Hello <span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> and <span class=\"user-mention\" data-user-id=\"504918\">@Jamey Sharp</span> </p>\n<p>I am afraid I have bad news to share today.</p>\n<p>Me and <span class=\"user-mention\" data-user-id=\"709820\">@Dimitris Aspetakis</span>  are a bit disappointed because since we completed the implementation,<br>\nwe got no speedup almost on all the benchmarks except in some of the benchmarks in XNNPACK. We ran the benchmarks many times and we verified this.<br>\nWe verified also that the implementation works correctly by taking a complex function out of Spidermonkey and executing separately to see the new order of instructions.</p>\n<p>Also we are a bit stuck on improving the compilation time with overhead 20-25%. Seems the priority queue has too much overhead that we cannot find a way to avoid, especially the delete/pop operation that we do on every (pure) Instruction that we insert into the layout. <br>\nWe don't want this work to go to waste so we would like to know if our implementation is close to some other heuristic we can try. Personally, I am thinking that instruction scheduling across blocks might be more beneficial, but can be more expensive also.</p>",
        "id": 450565708,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1720645947
    },
    {
        "content": "<p>It's always disappointing when that happens! We've certainly had plenty of other Cranelift changes we were excited about that didn't turn out to be helpful so I feel your pain here. If you're not ready to give up though then I'm not either!</p>\n<p>I'm not sure from your description which things you've already tried. Did you test a version with only the LUC heuristic and not the CP heuristic? You'd previously thought that perhaps you only needed a priority queue because of the CP heuristic. It would be great to keep the critical path heuristic to improve instruction-level parallelism. But of the two I actually expect bigger wins from the last-use count heuristic reducing register pressure, and therefore reducing the number of stack spills and reloads needed.</p>",
        "id": 450572436,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1720647949
    },
    {
        "content": "<p>In addition to Jamey's thoughts I wanted to add a bit of meta-encouragement / a snapshot of my own philosophy on these things, if it helps:</p>\n<ul>\n<li>\n<p>First off, this exploration <em>is</em> extremely valuable, even if it turns out not to have the perf characteristics that would let us put it in by default. All of the work we're doing is basically research, a kind of \"hill-climbing\" trying to find ways to move toward better perf (or maintainability or correctness or ...). Finding out that in a certain direction the slope is actually downward gives us a lot of information -- it means others don't spend time on it later, or perhaps we've learned which specific parts were expensive, or are inspired to think about certain aspects of the problem more, etc.</p>\n<p>So in that sense I almost think of the current state of the tree -- what's in, what's out, what's on by default, which approach we've taken -- as the sum of all approaches we've tried, and whichever one \"wins\" for our current metrics is incidental.</p>\n</li>\n<li>\n<p>Secondly, conditions change over time; maybe we find new benchmarks where good scheduling matters more, or maybe we try something more exotic with our elab pass that requires active scheduling more urgently, or ... basically it's useful to know that we <em>can</em> do this if we need to and that it addressed the one case (xnnpack) where we saw the issue. That doesn't mean we merge it now necessarily but does mean it's useful to keep the branch and notes on its final state and conclusions around.</p>\n</li>\n</ul>\n<p>Basically, to echo Jamey, please feel free to keep going if you want; but we've already gotten value from this so I hope you don't feel like it \"failed\" in any really substantial way!</p>",
        "id": 450574747,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1720649092
    },
    {
        "content": "<p>Hello from me too!</p>\n<p>I just wrote in <a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\">issue6260</a> a summary of our progress. Yesterday I also experimented with different implementations (using only LUC, only CP, only sequences), and I put the results in a text file in the end of that summary. The outcomes don't showcase any particular pattern from what I can tell.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/a2883eb2cd3dc983cabc5470fee86bf8edf73c2f/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f393331633738633237376637643066343838613738663139333232643239353763323238336438333164353963336438313930313061373432616339393433382f62797465636f6465616c6c69616e63652f7761736d74696d652f6973737565732f36323630&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/issues/6260\" title=\"cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime\">cranelift: Better heuristics for instruction scheduling · Issue #6260 · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Feature When any optimization level is enabled, Cranelift runs e-graph equality saturation, which removes all pure instructions from the function layout and leaves only a data-flow graph representa...</div></div></div>",
        "id": 450708044,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720703842
    },
    {
        "content": "<p>The best case is that we have logical errors in our implementation <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> — something that should surface after creating explicit testfiles checking for expected instruction scheduling.</p>\n<p>Other than that, the only way I can think of that might get us closer to an ideal scheduling (using the current heuristics) is using weights for the critical path metric according to how \"heavy\" an opcode is...</p>",
        "id": 450709485,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720704163
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/450574747\">said</a>:</p>\n<blockquote>\n<p>In addition to Jamey's thoughts I wanted to add a bit of meta-encouragement / a snapshot of my own philosophy on these things, if it helps:</p>\n<ul>\n<li>\n<p>First off, this exploration <em>is</em> extremely valuable, even if it turns out not to have the perf characteristics that would let us put it in by default. All of the work we're doing is basically research, a kind of \"hill-climbing\" trying to find ways to move toward better perf (or maintainability or correctness or ...). Finding out that in a certain direction the slope is actually downward gives us a lot of information -- it means others don't spend time on it later, or perhaps we've learned which specific parts were expensive, or are inspired to think about certain aspects of the problem more, etc.</p>\n<p>So in that sense I almost think of the current state of the tree -- what's in, what's out, what's on by default, which approach we've taken -- as the sum of all approaches we've tried, and whichever one \"wins\" for our current metrics is incidental.</p>\n</li>\n<li>\n<p>Secondly, conditions change over time; maybe we find new benchmarks where good scheduling matters more, or maybe we try something more exotic with our elab pass that requires active scheduling more urgently, or ... basically it's useful to know that we <em>can</em> do this if we need to and that it addressed the one case (xnnpack) where we saw the issue. That doesn't mean we merge it now necessarily but does mean it's useful to keep the branch and notes on its final state and conclusions around.</p>\n</li>\n</ul>\n<p>Basically, to echo Jamey, please feel free to keep going if you want; but we've already gotten value from this so I hope you don't feel like it \"failed\" in any really substantial way!</p>\n</blockquote>\n<p>Please find the time to think and propose ideas. Maybe we can try something in the near future. <br>\nPersonally I am thinking that the heuristics don't work well because the CPU can do optimal instruction scheduling almost in every single block except inside loops, this is why some of the benchmarks in XNNPACK are better with our heuristics. <br>\nMaybe moving instructions from hot paths to other basic blocks may improve performance, this my basic idea, but I don't think we have enough information to identify a hot path</p>",
        "id": 450796935,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1720727441
    },
    {
        "content": "<p>An out-of-order CPU should be able to do well with loops too, as long as it predicts the branches well enough. It will just keep looking forward and finding more instructions to run from future loop iterations until it runs out of buffer, which may be hundreds of instructions on a modern CPU.</p>\n<p>I think CPUs are less good at dealing with registers getting spilled to the stack and reloaded later. They may be able to optimize away the load if the store is still in the store buffer, but they still have to execute the store, eventually writing all the way to main memory. So anything we can do that reduces register pressure ought to be good, I think.</p>\n<p>We do loop-invariant code motion (LICM) already, which is the only form of \"moving instructions from hot paths\" that I can think of right now, but perhaps we could do it better somehow?</p>",
        "id": 450806202,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1720729874
    },
    {
        "content": "<p>I watched the <a href=\"https://www.youtube.com/watch?v=kx64V74Mba0&amp;\">Unison</a> video from EuroLLVM2017 that combines Instruction Selection and Register Allocation into a single combinatorial problem. Obviously that is too slow but it showcases examples where LLVM does poor job and then you can implement something better based on this observation. If we had something like this on cranelift we could do the same. Perhaps we don't need it at all, if we can use Unison and compare it with the output of Cranelift to simple test programs to identify where cranelift does poor job. This could be a good plan in my opinion.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"kx64V74Mba0\" href=\"https://www.youtube.com/watch?v=kx64V74Mba0&amp;\"><img src=\"https://uploads.zulipusercontent.net/26fdda7dab92e93ea5429f63116d3d3b5e7a4ff8/68747470733a2f2f692e7974696d672e636f6d2f76692f6b7836345637344d6261302f64656661756c742e6a7067\"></a></div><p><span class=\"user-mention\" data-user-id=\"254389\">@Chris Fallin</span> and <span class=\"user-mention\" data-user-id=\"504918\">@Jamey Sharp</span>  Please give your feedback.</p>",
        "id": 450810431,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1720731660
    },
    {
        "content": "<p>If you can't find the time to elaborate on the video above/further ideas (totally understandable), keep in mind that I'll probably reserve a \"slot\" in one of the next few meetings to summarize everything and give a few possible directions. I don't know if Panagiotis will be able to join since he's working, but I think I can adequately cover his proposals as well given that we usually talk them through together.</p>",
        "id": 450831054,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720738882
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"709823\">Panagiotis Karouzakis</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/450565708\">said</a>:</p>\n<blockquote>\n<p>we got no speedup almost on all the benchmarks except in some of the benchmarks in XNNPACK. We ran the benchmarks many times and we verified this.</p>\n</blockquote>\n<p>have you tried running the benchmarks on an in-order processor like the Arm Cortex A53 in the Raspberry Pi 3? I expect scheduling to have a much greater benefit on in-order cpus since they don't have the out-of-order architecture that basically does scheduling again in hardware.</p>",
        "id": 450836446,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1720742029
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"254389\">Chris Fallin</span> ... Please give your feedback.</p>\n</blockquote>\n<p>I'm on vacation this week (I jumped in above to give encouragement but my \"work brain\" is solidly shut down right now!); I'll think more about this next week. I do agree at a high level that starting with examples where we know we could do better seems like a reasonable approach.</p>",
        "id": 450836499,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1720742052
    },
    {
        "content": "<blockquote>\n<p>have you tried running the benchmarks on an in-order processor like the Arm Cortex A53 in the Raspberry Pi 3?</p>\n</blockquote>\n<p>Not yet, but it certainly was in the back of my mind! The only such CPU I believe I have available is in a rpi zero w, but I have literally no idea how to run Sightglass on it (I have never touched it before <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> ). I'll do my best to run it, and if I fail, I might try with a core 2 duo I have lying around for fun and (possibly) profit — although I'm not sure how less reordering range those had (if any).</p>",
        "id": 450838411,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720743291
    },
    {
        "content": "<p>for x86, basically everything after the pentium pro has out-of-order execution, so the core 2 duo isn't too likely to be substantially different than modern x86 processors</p>",
        "id": 450841798,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1720744575
    },
    {
        "content": "<p>Actually, the rpi zero w I have has an older 32-bit arm processor (the rpi zero 2 has a quad core A53)...</p>\n<p>So no luck on that side, given that wasmtine (as far as I can tell) supports only 64-bit arm.</p>",
        "id": 450962605,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720788107
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"315881\">Jacob Lifshay</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/450836446\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"709823\">Panagiotis Karouzakis</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/450565708\">said</a>:</p>\n<blockquote>\n<p>we got no speedup almost on all the benchmarks except in some of the benchmarks in XNNPACK. We ran the benchmarks many times and we verified this.</p>\n</blockquote>\n<p>have you tried running the benchmarks on an in-order processor like the Arm Cortex A53 in the Raspberry Pi 3? I expect scheduling to have a much greater benefit on in-order cpus since they don't have the out-of-order architecture that basically does scheduling again in hardware.</p>\n</blockquote>\n<p>I think the point is to do better on out-of-order cpus, simply because those are currently in a lot of use. Probably with older in-order cpus we maybe see improvement but this isn't the objective here.</p>",
        "id": 451042815,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1720807986
    },
    {
        "content": "<p>Well there are quite a few SBCs still in use that use in-order CPUs, and although it might not be in wasmtime's main targets, I believe cranelift itself does cast a wider net for deployment targets. It would at the very least be interesting to see if the critical path metric gives us anything in ILP. Of course, our main target should probably still be LUC for register spilling — something that (as Jamey Sharp mentioned) we expect to give more universal improvements.</p>",
        "id": 451044214,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1720808391
    },
    {
        "content": "<p>I do think the question of whether the CP heuristic helps on in-order CPUs is interesting, and relevant for Cranelift, so if you can find a system to test that on, feel free! If we can make that heuristic off-by-default and have no impact on compile time when it's disabled, we could certainly merge it.</p>\n<p>It's tricky because Cranelift currently only supports 64-bit targets, and so many 64-bit CPUs are out-of-order. I did a little research and as far as I can tell the only Intel CPU that was both in-order and 64-bit was the second-generation Atom, codenamed Pineview, from 2010. I guess ARM has more to choose from here though.</p>",
        "id": 451055852,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1720811980
    },
    {
        "content": "<p>quite a lot of riscv cpus are in-order, maybe try on one of those?</p>",
        "id": 451084545,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1720822276
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"504918\">Jamey Sharp</span> <a href=\"#narrow/stream/217117-cranelift/topic/Better.20Heuristics.20for.20Instruction.20Scheduling/near/451055852\">said</a>:</p>\n<blockquote>\n<p>I do think the question of whether the CP heuristic helps on in-order CPUs is interesting, and relevant for Cranelift, so if you can find a system to test that on, feel free! If we can make that heuristic off-by-default and have no impact on compile time when it's disabled, we could certainly merge it.</p>\n<p>It's tricky because Cranelift currently only supports 64-bit targets, and so many 64-bit CPUs are out-of-order. I did a little research and as far as I can tell the only Intel CPU that was both in-order and 64-bit was the second-generation Atom, codenamed Pineview, from 2010. I guess ARM has more to choose from here though.</p>\n</blockquote>\n<p>For that to work, we need to test at compile time if the current CPU is in-order or out of order. Does cranelift supports this? I think LLVM supports this with SchedModel, SubTargetInfo and other Classes.</p>",
        "id": 451150331,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1720864272
    },
    {
        "content": "<p>No, I'm suggesting making it an option that someone can manually enable. Later we could automate it but that's not necessary to get it merged.</p>",
        "id": 451194204,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1720887699
    },
    {
        "content": "<p>I just looked again at the paper that proposed LUC+CP for instruction scheduling. <br>\nThey used SPEC2006 for their benchmarks. Most of the INT2006 benchmarks didn't show any improvement. In FP2006 they did very well in some benchmarks.</p>\n<p>They said that the FP benchmarks have more workload than INT benchmarks and this is why the performance was increased there. </p>\n<p>They also counted the number of spills by LLVM's regalloc.</p>\n<p>So I'm wondering does Sightglass has large FP programs for benchmarking?</p>",
        "id": 451552601,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1721062844
    },
    {
        "content": "<p>afaict not really, maybe try adding ngspice? (useful since it's a decently large fp program, compiles on just about anything, and could reasonably be used in web-based circuit design software)</p>",
        "id": 451641240,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1721082260
    },
    {
        "content": "<p>turns out ngspice wants dup2, which isn't supported, so i gave up trying to compile it to wasi for now</p>",
        "id": 451648615,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1721085779
    },
    {
        "content": "<p>I have 2,5 years of experience with LLVM, but I don't know much about webAssembly benchmarks like Sightglass and stuff so please help us.. We did a lot of work to reach this point.</p>",
        "id": 451835817,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1721155828
    },
    {
        "content": "<p>You did do a lot of work to reach this point! Let's talk about it at the Cranelift meeting tomorrow.</p>",
        "id": 451835926,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1721155877
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"504918\">@Jamey Sharp</span> My Calendar says that in my local timezone is at 16:30 noon. I just need to make sure that I don't get the time wrong and miss it.</p>",
        "id": 451836381,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1721156079
    },
    {
        "content": "<p>I like to let Zulip do timezone conversions for me: It's at <time datetime=\"2024-07-17T15:30:00Z\">2024-07-17T08:30:00-07:00</time></p>",
        "id": 451836502,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1721156141
    },
    {
        "content": "<p>It still shows it at 16:30 for me! Thank you</p>",
        "id": 451836618,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1721156193
    },
    {
        "content": "<p>Hello, after a while!</p>\n<p>While we have somewhat stagnated with progress, for our convenience I tried adding an <code>--emit-opt-clif</code> option that follows <code>--emit-clif</code>, but prints functions after a (possible?) egraph optimization. It can be currently found in the latest commits of our main branch from <a href=\"http://github.com/karouzakisp/wasmtime\">github.com/karouzakisp/wasmtime</a>.</p>\n<p>I find my solution a bit hacky in a specific place, probably due to my inexperience with the borrow checker. I didn't yet bother with possible cli checks (like whether the paths for <code>--emit-clif</code> and <code>--emit-opt-clif</code> are the same) because I'm not sure how you would like the cli to behave anyway. Also, I believe the <code>--emit-clif</code> option is supported by a wasmtime/cranelift \"explorer\"? — I have not done anything there...</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"http://github.com/karouzakisp/wasmtime\" style=\"background-image: url(&quot;https://uploads.zulipusercontent.net/2765fadd95a0dd6242024a4582be7e358772bd63/68747470733a2f2f6f70656e67726170682e6769746875626173736574732e636f6d2f386636333839393364356230343765353266336334393838623231323565313337376566643731663561623063393966303961613764643237313938346333662f6b61726f757a616b6973702f7761736d74696d65&quot;)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"http://github.com/karouzakisp/wasmtime\" title=\"GitHub - karouzakisp/wasmtime: Investigating better instruction scheduling using heuristics on cranelift\">GitHub - karouzakisp/wasmtime: Investigating better instruction scheduling using heuristics on cranelift</a></div><div class=\"message_embed_description\">Investigating better instruction scheduling using heuristics on cranelift - karouzakisp/wasmtime</div></div></div>",
        "id": 463392629,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1724071430
    },
    {
        "content": "<p>I'm not familiar with github contributions in general, that's why I'm asking here first — should I search/create an issue for that, should I bother with a pull request already?</p>",
        "id": 463393134,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1724071517
    },
    {
        "content": "<p>I feel like its state is not ready for a pull request, and I also don't know where improvements to the branch should happen.</p>",
        "id": 463394024,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1724071624
    },
    {
        "content": "<p>Cool, and good questions! The general reason that projects like this ask people to open an issue first is so that we're aware of what people are working on and can offer advice before you get too far into a project. It can be disappointing to write a bunch of code and then find out that it might not make sense to merge it, as you know, so when we can help avoid that outcome it's nice. But when you already have code written, there's no need to open an issue, at least in my opinion. I would suggest opening a pull request that contains only your changes for <code>--emit-opt-clif</code>; it sounds like a useful bit of work by itself. If there are things you feel are important to improve before merging it, feel free to mention those in your pull request, but I wouldn't worry about integrating this mode with <code>wasmtime explore</code> or anything; that can be done in later work if necessary.</p>",
        "id": 463471393,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1724090222
    },
    {
        "content": "<p>We should also mention, that while we took some time off regarding this project, cause of vacations, etc. We are still thinking of ways and implementing some features to get some performance! When we have news we will make an update!</p>",
        "id": 463486381,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1724094167
    },
    {
        "content": "<p>Using <a href=\"#narrow/stream/217117-cranelift/topic/Public.20release.20of.20regalloc3/near/467986562\">this approximation</a>, we found that our implementation of the LUC+CP heuristic results in ~17% more spills in Spidermonkey...</p>",
        "id": 468599952,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725814652
    },
    {
        "content": "<p>I believe the paper we draw from also notes an increase in spills — with an increase in execution time. Although for their spills, it might be that they compare with a more traditional scheduler as a baseline.</p>",
        "id": 468600308,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725814806
    },
    {
        "content": "<p>Considering we prioritize LUC, these results seem a bit counter-intuitive to me. We might have issues with the implementation, or maybe the Critical Path heuristic is at fault.</p>",
        "id": 468601434,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725815281
    },
    {
        "content": "<p>We will probably check out what's going on with spills separately for LUC+sequenc and CP+sequence next...</p>",
        "id": 468601823,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725815408
    },
    {
        "content": "<p>I agree, that's not intuitive to me. Sounds like you have a good plan. Also I want to note that the approximation that Chris suggested is not measuring how many values got spilled but rather how many times spilled values got moved around, which is subtly different. It's a useful measure because it probably correlates better with execution time, but it might be confusing depending on what you're trying to figure out.</p>",
        "id": 468602805,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725816009
    },
    {
        "content": "<p>Hmm yes, noted. We just tested it, and we still find we're worse in that metric with LUC+original_sequence...</p>",
        "id": 468603216,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725816258
    },
    {
        "content": "<p>I dunno, at this point we probably have to check manually some examples <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 468603260,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725816296
    },
    {
        "content": "<p>Yeah, that's what I would suggest! Something small where you know what outcome you want the heuristic to produce.</p>",
        "id": 468603326,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725816346
    },
    {
        "content": "<p>The other thing you can try, if you come up with any guesses about specific situations where the heuristic might be making choices you don't want, is to add tracing that helps you find examples of those situations, and then run the compiler with that tracing enabled on a reasonably large input like Spidermonkey.</p>",
        "id": 468604267,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725816997
    },
    {
        "content": "<p>We kinda already have some respectable tracing from our \"debugging days\" — that was the only way we got some feedback on the correctness of our implementation too. But we surely have to check some examples more extensively.</p>",
        "id": 468605558,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725817605
    },
    {
        "content": "<p>I'm not sure about this, but maybe the dependency driven approach is already approaching spill optimality.</p>",
        "id": 468606273,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725817939
    },
    {
        "content": "<p>Heh, I don't have any reason to believe it is, but I don't have evidence that it isn't, either.</p>",
        "id": 468606390,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725818005
    },
    {
        "content": "<p>If I remember correctly, the elaboration stack is a backward, depth-first pass. So it schedules graph \"paths\" in a sequence.</p>",
        "id": 468606401,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725818010
    },
    {
        "content": "<p>If the average graph approaches an upside-down tree, wouldn't this depth-first scheduling avoid scheduling parallel tree paths, which I think mostly hurt spilling?</p>",
        "id": 468606996,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725818274
    },
    {
        "content": "<p>Ehh, I should have thought on it a bit more before I wrote it down...<br>\nThe sure thing is that we will examine examples more thoroughly (with the heuristics).</p>",
        "id": 468607223,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725818383
    },
    {
        "content": "<p>It's often helpful to write things out like this, especially when you're not sure whether you have it right, and I think it's an interesting thought! I guess the situation where the heuristics should matter is when the same value is used multiple times, so it isn't a tree, right? I don't know.</p>",
        "id": 468610245,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725820221
    },
    {
        "content": "<p>Yeah, that's kinda what I had in mind.<br>\nThinking prematurely ahead of time, it might be interesting to see if we could apply the heuristics depending on some summarizing descriptors for basic blocks...</p>",
        "id": 468610480,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725820360
    },
    {
        "content": "<p>If there exist patterns strong enough to separate basic blocks into groups that would benefit from different scheduling polices, that is.</p>",
        "id": 468610609,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1725820443
    },
    {
        "content": "<p>That kind of approach can be great, especially if some heuristics are slow to evaluate but you can quickly prove they won't help sometimes.</p>",
        "id": 468614162,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1725822186
    },
    {
        "content": "<p>I think we need to check how many LUC collisions we have, since LUC is supposed to help with spilling. Then one approach is to revert back to the data-driven scheduling. Another approach is employ a more sophisticated algorithm only to some blocks.</p>",
        "id": 468625348,
        "sender_full_name": "Panagiotis Karouzakis",
        "timestamp": 1725828878
    },
    {
        "content": "<p>Following the discussion above, I drew a small example to gain stronger intuition on it:<br>\n<a href=\"/user_uploads/15107/AphtGeRINJLut02WPQUlusaD/22bf9c11-1eca-446e-afe5-9f1b4a092439.jpg\">Example of the LUC-CP heuristic VS a dependency-driven scheduling</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/15107/AphtGeRINJLut02WPQUlusaD/22bf9c11-1eca-446e-afe5-9f1b4a092439.jpg\" title=\"Example of the LUC-CP heuristic VS a dependency-driven scheduling\"><img data-original-dimensions=\"8000x6000\" src=\"/user_uploads/thumbnail/15107/AphtGeRINJLut02WPQUlusaD/22bf9c11-1eca-446e-afe5-9f1b4a092439.jpg/840x560.webp\"></a></div><p>Although small and possibly not representative, we can see that the dep-driven scheduling is better in terms of live values (given that my application of the algorithms is indeed correct <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> ).</p>\n<p>Obviously, I don't really consider it a strong indication of any pattern — but it did give an idea: we probably should initialize the LUC heuristic with negative values depending on how many new values an instruction generates. Isolating the choice between (e) and (h) in the example, I believe this would result in a preference for scheduling (e) -&gt; (g) -&gt; (h), which would at least save us from an increase back to 5 live values from 4.</p>",
        "id": 471454912,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1726741670
    },
    {
        "content": "<p>It makes sense to me intuitively. While we like removing live values by scheduling last users, we should also probably consider how many values those last users generate. The heuristic might also need a new name if we decide to make this modification...</p>\n<p>I'll probably implement this and report back if we gain anything.</p>",
        "id": 471457346,
        "sender_full_name": "Dimitris Aspetakis",
        "timestamp": 1726742550
    },
    {
        "content": "<p>Ooh, yeah, I bet the paper authors didn't consider instructions with multiple results.</p>",
        "id": 471537966,
        "sender_full_name": "Jamey Sharp",
        "timestamp": 1726768717
    },
    {
        "content": "<p>Haven't read the paper yet, but would <a href=\"https://dl.acm.org/doi/10.1109/WCSE.2009.39\">https://dl.acm.org/doi/10.1109/WCSE.2009.39</a> (A Novel Lightweight Instruction Scheduling Algorithm for Just-in-Time Compiler) be useful here?</p>",
        "id": 481583737,
        "sender_full_name": "bjorn3",
        "timestamp": 1731261863
    },
    {
        "content": "<p>Note that the paper specifically targets an in-order CPU. IMO with a OoO CPU you're better off scheduling to minimize register pressure instead.</p>",
        "id": 481585997,
        "sender_full_name": "Amanieu",
        "timestamp": 1731263860
    }
]