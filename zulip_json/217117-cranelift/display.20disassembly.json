[
    {
        "content": "<p>Is there a convenient way to see the disassembly of a function generated using cranelift-jit and craneleft-frontend? I can easily see the Cranelift IR using <code>FunctionBuilder::display</code>, but I would like to see what instructions come out after optimization and compilation.</p>",
        "id": 257780676,
        "sender_full_name": "Veverak",
        "timestamp": 1634340506
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"451107\">@Veverak</span> there's no API to do this programmatically, but (i) <code>clif-util -D</code> uses <code>capstone</code> to show disassemblies of compilations of either .clif or .wasm inputs, and (ii) if you set your log level to 'trace' (<code>RUST_LOG=trace</code>) with a binary that has log output set up (<code>wasmtime</code> does, for example), you'll see a bunch of info fly by, including final <code>VCode</code> for functions</p>",
        "id": 257781185,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634340921
    },
    {
        "content": "<p>also, if you're building your own JIT on top of Cranelift then it might be worthwhile to hook up capstone to show disassemblies, imho, so that you can get just that without all the other debug spew</p>",
        "id": 257781317,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634341009
    },
    {
        "content": "<p>(happy to take suggestions on ways we could improve the API here to provide something better!)</p>",
        "id": 257781350,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634341048
    },
    {
        "content": "<p>Can you provide a link to clif-util?</p>",
        "id": 257781495,
        "sender_full_name": "Veverak",
        "timestamp": 1634341142
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"451107\">@Veverak</span> it's a utility binary that is built with Cranelift; <code>cargo build --release -p cranelift-tools</code> should give you <code>target/release/clif-util</code></p>",
        "id": 257781867,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634341413
    },
    {
        "content": "<p>if you have a .clif file, you can run <code>clif-util compile --target x86_64 -D file.clif</code> (or s/x86_64/aarch64/ if desired)</p>",
        "id": 257781948,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634341478
    },
    {
        "content": "<p>Using a powerful disassembler like Capstone seems a bit odd. I suppose Cranelift already has internal state that could be used to pretty-print the generated instructions with little effort without having to use reverse-engineering techniques.</p>",
        "id": 257782245,
        "sender_full_name": "Veverak",
        "timestamp": 1634341699
    },
    {
        "content": "<p>Indeed, that's the VCode option I mentioned above</p>",
        "id": 257782959,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634342239
    },
    {
        "content": "<p>Currently the pretty-printing for that isn't exposed in the external API but I'm happy to look at a PR that does so!</p>",
        "id": 257782981,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634342260
    },
    {
        "content": "<p>the reason I didn't mention it as the first option is that it is not <em>exactly</em> 1:1 with the final machine code; for example there is late editing that happens in <code>MachBuffer</code> to resolve control-flow and simplify branches. The only state that fully represents the final result is the machine code itself, so starting from that is truly the best option if you want the precise disassembly</p>",
        "id": 257783138,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634342396
    },
    {
        "content": "<p>I guess it doesn't matter to me whether it exactly represents the final machine code. I just like to get an idea of what optimizations are applied. Is there a way I can set up log output in my own JIT?</p>",
        "id": 257783486,
        "sender_full_name": "Veverak",
        "timestamp": 1634342596
    },
    {
        "content": "<p>Yep, if you want to log all the code that is generated via the VCode pretty-printer, <a href=\"https://github.com/bytecodealliance/wasmtime/blob/3ba9e5865a8171d1b4547bcabe525666d030c18b/cranelift/codegen/src/machinst/compile.rs#L106-L109\">this <code>log::trace!()</code> call</a> is printing the output that you want; so, probably the best way to expose that is to either pass in a Cranelift option to emit at a higher log-level (so you don't have to see all the trace-level output, which is extremely verbose), or add an API to return a <code>String</code> given the final compiled function</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"https://github.com/bytecodealliance/wasmtime/blob/3ba9e5865a8171d1b4547bcabe525666d030c18b/cranelift/codegen/src/machinst/compile.rs#L106-L109\" style=\"background-image: url(https://opengraph.githubassets.com/32d782ee11b5726fc6ba221f8f8065a3961c6c81a6717bf2f69f02f88e8dcdd7/bytecodealliance/wasmtime)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"https://github.com/bytecodealliance/wasmtime/blob/3ba9e5865a8171d1b4547bcabe525666d030c18b/cranelift/codegen/src/machinst/compile.rs#L106-L109\" title=\"wasmtime/compile.rs at 3ba9e5865a8171d1b4547bcabe525666d030c18b · bytecodealliance/wasmtime\">wasmtime/compile.rs at 3ba9e5865a8171d1b4547bcabe525666d030c18b · bytecodealliance/wasmtime</a></div><div class=\"message_embed_description\">Standalone JIT-style runtime for WebAssembly, using Cranelift - wasmtime/compile.rs at 3ba9e5865a8171d1b4547bcabe525666d030c18b · bytecodealliance/wasmtime</div></div></div>",
        "id": 257783684,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634342750
    },
    {
        "content": "<p>... and with that I am disappearing for now but I'm happy to review a PR to do one of the above if you decide to go that way!</p>",
        "id": 257783833,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634342877
    },
    {
        "content": "<p>I guess the part about simplifying branches is important after all. The VCode contains a lot of blocks that only contain one instruction that jumps to the next block. It would be nice to have some API to get the final optimized code but as structured data rather than a blob, and with a source map, allowing to make a tool like <a href=\"http://godbolt.org\">godbolt.org</a>. I'm still getting used to Cranelift, so don't expect a PR from me, yet.</p>\n<div class=\"message_embed\"><a class=\"message_embed_image\" href=\"http://godbolt.org\" style=\"background-image: url(https://github.com/compiler-explorer/infra/blob/main/logo/favicon.png?raw=true)\"></a><div class=\"data-container\"><div class=\"message_embed_title\"><a href=\"http://godbolt.org\" title=\"Compiler Explorer\">Compiler Explorer</a></div><div class=\"message_embed_description\">Compiler Explorer is an interactive online compiler which shows the assembly output of compiled C++, Rust, Go (and many more) code.</div></div></div>",
        "id": 257788558,
        "sender_full_name": "Veverak",
        "timestamp": 1634347107
    },
    {
        "content": "<p>I agree that that would be a very nice facility to have! Unfortunately providing a \"structured data\" view of the final assembly is a bit beyond the design of the compiler backend: the final code emission intentionally does <em>not</em> build a data structure in memory that represents the (post-branch-simplification) code before emitting machine code, because it's not necessary and not doing so reduces the cost of emission.</p>\n<p>This is why I recommended hooking up Capstone above if one wants the final disassembly -- to come back to what you said earlier:</p>\n<blockquote>\n<p>Using a powerful disassembler like Capstone seems a bit odd. I suppose Cranelift already has internal state that could be used to pretty-print the generated instructions with little effort</p>\n</blockquote>\n<p>it's exactly because we <em>don't</em> have this internal state that we're faster than otherwise at emitting code, but the tradeoff is that one has to pay more cost to build that internal state post-hoc if one wants it.</p>\n<p>In theory one could use the debug location info we emit to make a Godbolt-like UI with correspondences to original source lines; that actually sounds like a really useful tool, if someone were to build it. Happy to help answer questions and/or work out ways to expose additional information as needed if you're hoping to do so!</p>",
        "id": 257804738,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634363315
    },
    {
        "content": "<p>It's interesting to hear that Cranelift has been made faster by not maintaining enough detail about the generated code to allow pretty-printing it. I obviously don't know all the details, but I suspect that in any case, there may be a clever way around this. Maybe instead of making the main state more descriptive, a layer of annotations could be kept besides it, and this layer can be turned off when not needed. I guess this is already how debug location info works, and that the format of this could be adjusted to allow listing the instructions at each byte without having to disassemble them. What's the API to get the debug location info?</p>",
        "id": 257811531,
        "sender_full_name": "Veverak",
        "timestamp": 1634370371
    },
    {
        "content": "<p>Hi @Veverak, yes, it's possible we could do something like that!</p>\n<p>I'll note that such a project would need some careful design in the way that it interacts with <code>MachBuffer</code> (which is the code that mutates branches and removes redundant ones during binary emission), and would need some careful consideration in the way that it keeps in sync with the emitted binary code. I'd be happy to talk more design details with anyone who's interested in taking this up...</p>\n<p>Some history might be useful context too. The original intent of <code>MachInst</code> was to be more-or-less exactly the assembler-input data structure that you're requesting: one <code>MachInst</code> for one machine instruction, with passes before final emission to get all the instructions into emittable shape. (Then the VCode pretty-printed output was exactly the final assembly.) In fact in the original aarch64 backend I was testing the VCode-emitted bytes by comparing to the <code>gas</code> assembly of the VCode pretty-printing.</p>\n<p>But two issues came up that caused the divergence:</p>\n<ul>\n<li>There are some instruction sequences that need to be emitted atomically w.r.t. any regalloc-inserted moves/reloads/spills, either because of embedded instruction offsets in branches, or because of the way they use registers. It was simplest to turn these into \"macroinstructions\" of a sort rather than to invent a way to tell the regalloc about safe insertion places. It also turns out to improve efficiency if the regalloc has fewer instructions to consider.</li>\n<li>The original scheme to lower the control-flow graph to machine branches (taken/fallthrough-style) was less efficient than it might otherwise be, requiring an extra pass and sometimes not completely removing redundant branches in order to avoid deep alias-chasing. I came up with the <code>MachBuffer</code> instead, which edits code in-place in a way that doesn't require an extra pass and is guaranteed to collapse long branch-chains. The impact of this though is that each <code>MachInst</code> that is a branch is always an N-successor branch, and the conversion to a machine-style taken/fallthrough is only visible in the machine code.</li>\n</ul>\n<p>So, both efficiency and correctness concerns led us to this design; in other words, there are good reasons why we don't build intermediate data structures that exactly represent the final instructions before we emit them. (I'll note that \"emit the bytes directly while traversing something\" is not an uncommon design choice in JITs in general, too, for speed reasons.)</p>\n<p>The last thing I would say is regarding software-maintenance overhead: if we guarantee we can pretty-print in a way that exactly corresponds to machine code, that's another thing we have to test, and get right whenever we add instructions or instruction sequences. Not the end of the world, but a cost nonetheless. Sometimes saying \"just use Capstone if you need that\" is actually the right decision from an overall cost perspective -- it significantly simplifies the overall design (the compiler just outputs bytes; pretty-printing is a separate bytes-to-text pipeline). \"Speed of pretty-printing\" was not a top-level goal when we designed the current backend; that probably helps illuminate some of the tradeoffs we have made :-)</p>\n<p>Anyway, that's more-or-less my complete braindump on the topic; anyone who wants to suggest an improved design is very welcome to do so and I'd be happy to point to the relevant bits of code that would be involved in implementation!</p>",
        "id": 257849949,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634407764
    },
    {
        "content": "<p>It's an interesting potential improvement to keep in mind for the future, but for now, as you say, “just use Capstone if you need that”. When I try to do that however, I run into the same problem of not being able to access internal state. <code>JITModule</code> has internal state telling the size of each function, but the public methods only allow getting the pointer to each function, not the size. Maybe there needs to be another form of <code>get_finalized_function</code> which similarly to <code>get_finalized_data</code> includes the size of the data in the return value?</p>",
        "id": 258263396,
        "sender_full_name": "Veverak",
        "timestamp": 1634674123
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"451107\">@Veverak</span> yes, that sounds like a reasonable API addition for <code>JITModule</code></p>",
        "id": 258276772,
        "sender_full_name": "Chris Fallin",
        "timestamp": 1634679640
    }
]